---
format:
  revealjs:
    slide-number: true
    chalkboard: true
    fig-width: 6
    fig-asp: 0.618
    template-partials:
      - "../title-slide.html"
css: "../slides_quarto.css"
standalone: false
include-in-header: "../header_quarto.html"
logo: "../Intro2DS_logo_white.jpg"
pagetitle: "Inference - Part B"
callout-appearance: simple
smaller: true
execute:
  eval: true
  echo: true
code-line-numbers: false
code-block-border-left: true
highlight-style: github
footer: "[Intro to Data Science](https://intro2ds2023.github.io/mooc/){target='_blank'}"
---

## {.logo-slide}

## Introduction to Data Science {.title-slide}

### Inference - Part B - Class 8

### Giora Simchoni

#### `gsimchoni@gmail.com` and add `#intro2ds` in subject

### Stat. and OR Department, TAU

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

## Last time on Hypothesis Testing {.title-slide}

```{python}
#| echo: false

import sys
import warnings
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from skimage import transform, color, img_as_ubyte

def check_mem():
    # These are the usual ipython objects, including this one you are creating
    ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']

    # Get a sorted list of the objects and their sizes
    print(sorted([(x, sys.getsizeof(globals().get(x))) for x in globals() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True))

def get_file_list(df, folder, n_sample = None, seed = None):
    if n_sample is None:
        file_ids_list = df.title.values
    else:
        file_ids_list = df.sample(n = n_sample, random_state = seed).title.values
    files_list = [folder + '/' + file_id for file_id in file_ids_list]
    return files_list

def read_image_and_resize(f, w = 100, h = 100):
    img = plt.imread(f)
    img = transform.resize(img, (w, h), mode='constant', anti_aliasing=True)
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        img = img_as_ubyte(img)
    if img.shape != (100, 100, 3):
        img = color.gray2rgb(img)
    img = img[np.newaxis, :, :, :3]
    if img.shape != (1, 100, 100, 3):
        raise ValueError(f + str(img.shape))
    return img

def read_images_4d_array(files_list):
    images_list = [read_image_and_resize(file) for file in files_list]
    images_array = np.concatenate(images_list)
    return images_array

def get_images_matrix(csv_file, folder, n = None, seed = 1976):
    df = pd.read_csv(csv_file)
    files_list = get_file_list(df, folder, n, seed)
    images = read_images_4d_array(files_list)
    return images

def get_all_pixels(x):
    return x.reshape(-1, np.prod(x.shape[1:]))

folder = 'C:/Users/gsimchoni/Downloads/wikiart2/wikiart/'

real_all = get_images_matrix(folder + 'realism_train.csv', folder + 'realism')
impr_all = get_images_matrix(folder + 'impressionism_train.csv', folder + 'impressionism')

real_red_all = real_all[:, :, :, 0].mean(axis = (1, 2))
impr_red_all = impr_all[:, :, :, 0].mean(axis = (1, 2))

population = np.concatenate([real_red_all, impr_red_all])

real_sample = get_images_matrix(folder + 'realism_train.csv', folder + 'realism', n = 30, seed = 1976)
impr_sample = get_images_matrix(folder + 'impressionism_train.csv', folder + 'impressionism', n = 30, seed = 1976)

real_red = real_sample[:, :, :, 0].mean(axis = (1, 2))
impr_red = impr_sample[:, :, :, 0].mean(axis = (1, 2))
```

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

### Last time on Hypothesis Testing...

- Either calculate a **p-value** under $H_0$ (simulation, analytical calculation) and reject if too small (surprising)

- Or decide beforehand on a **rejection area** under $H_0$ for some statistic of the sample $T(X)$ and reject if $T(X)$ is in rejection area

| Reality\\Decision | Not Reject $H_0$    | Reject $H_0$   |
|---|------|-----|
| $H_0$ | Confidence: $1 - \alpha$ | Type I Error: $\alpha$ |
| $H_1$ |  Type I Error: $\beta$    | Power: $1 - \beta$    |


::: {.fragment}
- We did both for only very simple scenarios.

- We need a way of computing these probabilities without having the population at the palm of our hand.
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
ביחידה האחרונה התחלנו ללמוד על בדיקת השערות. ניסינו לתת אינטואיציה למושגים השונים באמצעות סימולציה של אוכלוסיה ומדגם, או כאשר התפלגות הסטטיסטי שלנו פשוטה וידועה.

ראינו שיש שתי גישות עיקריות לבדיקת השערות, או שאנחנו מחשבים את ערך הpvalue תחת השערת האפס, שמבטא עד כמה סביר תחת עולם ברירת המחדל המוכר, לקבל תוצאה קיצונית כמו שקיבלנו במדגם או יותר. ואם הpvalue היה קטן מאיזשהו ערך סף, דחינו את השערת האפס.

הדרך השניה היתה לבנות מראש איזור דחיה של סטטיסטי המדגם שבו אנחנו מתמקדים, באמצעות קיבוע הסף לסיכוי של טעות מסוג ראשון: הטעות שעושים כאשר העשרת האפס נכונה ודוחים אותה. אם ניפול באיזור הדחיה, נדחה את השערת האפס, ואם לא - לא נדחה.

עצרנו בטבלה הזאת שמבטאת מה קיים בעולם ומה אנחנו מחליטים בסופו של דבר לעשות: או שהשערת האפס נכונה, או שהשערה אלטרנטיבית נכונה. או שנחליט לדחות את H0 או שנחליט לא לדחות אותה. נשים לב שוב לז'רגון, בפרדיגמה שלנו לרוב אין סימטריה בין שתי ההשערות, H0 היא ברירת מחדל, והשאלה היא אם יש מספיק עדות לצאת מברירת המחדל.

יכולנו לחשב את ההסתברויות האלה או במצבים פשוטים כמו סימולציה שבה כל האוכלוסיה נתונה לנו או הטלת מטבע שדי ברורה מהי ההתפלגות של התוצאה, היא היתה בינומית.

והגענו למסקנה אנחנו צריכים לדעת לחשב את כל האלמנטים האלה, בלי שאנחנו יודעים בדיוק את ההתפלגות שממנה נלקחו הנתונים.
:::
:::

---

### Back to Red Paintings

- Recall:
    - We hypothesize there is "more red" in impressionist paintings
    - The null hypothesis about the mean in differences: $H_0: \mu = 0$
    - We only have capacity to get red pixel levels for 30 impressionist and 30 realist paintings
    - We computed the mean for our samples: impressionist paintings had ~15 points more red
    - We compared our specific difference of 15 points to a **simulated** null distribution of **means differences**

```{python}
#| code-line-numbers: "|1-4|6|"
def sample_null_mean_diff(n = 30):
    real_red_null = np.random.choice(population, n, replace=False)
    impr_red_null = np.random.choice(population, n, replace=False)
    return impr_red_null.mean() - real_red_null.mean()

null_mean_diffs = np.array([sample_null_mean_diff() for i in range(10000)])
```

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
בואו נחזור לדוגמה שמלווה אותנו: אנחנו משערים שיש יותר אדום בציורים בסגנון אימפרסיוניסטי, כי התרשמנו שהם עליזים ומתארים סיטואציות יומיומיות כמו גידול ילדים, ונופים פסטורליים.
אם נסמן את תוחלת ההפרשים של צבע אדום בציורים אימפרסיוניסטיים פחות צבע אדום בציורים ריאליסטיים באות מיו, השערת האפס, ברירת המחדל, היא שאין הבדלים, מיו שווה אפס.
היה לנו תקציב דמיוני לקחת רק 60 ציורים, 30 ריאליסטיים ו-30 אימפרסיוניסטיים, לכל ציור נתנו רמת אדום ממוצעת וחישבנו את ההפרש בין הממוצעים -- יצא לנו שאכן לציורים אימפרסיוניסטים היתה רמת אדום גבוהה יותר ב15 נקודות.
בשלב הזה עשינו סימולציה של התפלגות הייחוס שלנו, של השערת האפס. כתבנו בפונקציה כיצד אנחנו דוגמים שני מדגמים אקראיים מתוך האוכלוסיה של 16 אלף ציורים, ומחשבים את הפרש הממוצעים של אדם בין שני המדגמים. ועל הפוקנציה הזאת חזרנו 10000 פעמים ליצירת התפלגות האפס, התפלגות הייחוס.
:::
:::

---

```{python}
plt.hist(null_mean_diffs, bins=np.arange(-45, 45, 5))
plt.show()
```

::: {.incremental}
- We saw 15 points wasn't that surprising (simulated p-value = 7%) -- we didn't reject $H_0$

- This distribution amazingly is bell shaped, "normal"

- If we could somehow trust this would always be the case we could easily calculate p-value, critical $C$, whatever.
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
ראינו, שההבדל של 15 נקודות הפרש ממוצעים שאנחנו קיבלנו לא היה כל כך מרשים בהשוואה להתפלגות הייחוס המסומלצת, הסיכוי לקבל אותו או הפרש גדול יותר, הpvalue, היה בערך 7 אחוז, ולא דחינו את השערת האפס.

נשים לב שההתפלגות של הפרשי ממוצעים שסימלצנו, היא סימטרית באופן מחשיד ובצורת פעמון -- במילים אחרות היא נראית נורמלית.

אם יכולנו איכשהו לדעת שהתפלגות כזאת תיראה תמיד נורמלית בקירוב -- זה היה עוזר לנו מאוד, לחישוב כל ההסתברויות שראינו, איזור דחייה, ערך קריטי, עוצמת המבחן. למזלנו, מסתבר שהדבר אכן כך. ובזה אנחנו מתחילים את היחידה הזאת.
:::
:::

---

## The Normal Distribution {.title-slide}

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
אני מקווה שכולם זוכרים את תכונות ההתפלגות הנורמלית מלימודי ההסתברות שלהם. ההתפלגות הנורמלית היא מהותית לנושא בדיקת ההשערות ולכן אם אתם לא בטוחים שאתם מתמצאים בנושא הזה - מומלץ מאוד לחזור עליו. כאן נעשה רק רענון.
:::
:::
---

### The Normal Distribution: Refresher

- With Discrete RVs we usually talk about "Probability Mass Function" (PMF).

- With Continuous RVs we talk about "Probability Density Function" (PDF).

- If $X \sim N(\mu, \sigma^2)$ its density function is defined as:
$$f(x) = \frac{1}{{\sigma \sqrt{2\pi}}}e^{\frac{-({x - \mu})^2}{2\sigma^2}}$$

::: {.fragment}
- If $\mu = 0$ and $\sigma = 1$ (a.k.a the Standard Normal Distribution $N(0, 1)$) it has the familiar form:
$$f(x) = \frac{1}{{\sqrt {2\pi}}}\exp(-\frac{x^2}{2})$$

and the familiar bell shape around 0:
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
ניזכר שבמשתנים בדידים ההתפלגות שדיברנו עליה היא של הסתברויות, ערכים בין 0 ל-1.

עבור משתנים רציפים אנחנו מדברים פונקצית צפיפות.

לדוגמא, משתנה נורמלי עם תוחלת מיו ושונות סיגמא בריבוע, זוהי הנוסחה לפונקצית הצפיפות שלו, שמסומנת ב-f קטן.

מקרה פרטי של התפלגות נורמלית שמעניין אותנו הוא כאשר התוחלת מיו היא באפס, והשונות היא 1, ואז מקבלית את ההתפלגות הנורמלית-סטנדרטית, N(0,1). אם תציבו בפונקצית הצפיפות אפס למיו ו-1 לסיגמה בריבוע תקבלו את הנוסחה הבאה. וכשנצייר את הצפיפות נקבל את עקומת הפעמון המוכרת:
:::
:::

---

```{python}
import scipy.stats as stats

x = np.arange(-3, 3, 0.01)
plt.plot(x, stats.norm.pdf(x, 0, 1))
plt.show()
```

::: {.incremental}
The density function $f(x)$ is a positive real function, the area under which is 1.
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
כאן אנחנו משתמשים במודול stats.norm של ספרית scipy ובמתודה pdf - probability density function שלו, כדי לצייר את פונקצית הצפיפות.

ניתן לראות שהיא בצורת פעמון, המרכז שלה הוא התוחלת, כאן 0, ויש לה אסימפטוטה בצד ימין ובצד שמאל אל אפס. כמו-כן נזכיר שפונקצית צפיפות היא תמיד ממשית, חיובית, והשטח בינה לבין ציר הX צריך להסתכם ב-1.
:::
:::

---

- But notice that $f(x)$ values are NOT probabilities but densities.

- Probabilities are *areas*. And to get those areas (probabilities) we *integrate*:
$$P(X \leq a) = \int_{-\infty}^a f(x) \;dx.$$

::: {.fragment}
- That last function is known as the Cumulative Distribution Function (CDF), $F_X(a)$.

- It is used so much in the Standard Normal Distribution that we denote it $\Phi(a) = P(X \leq a)$ when $X\sim N(0,1)$:
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
ושוב נזהיר: מדובר בצפיפות, לא הסתברות! כדי לחלץ הסתברות לטווח ערכים מסוים מפונקצית הצפיפות צריך לחשב שטח תחתיה, מה שאומר מבחינתנו לעשות אינטגרציה. לדוגמא ההסתברות שX יהיה קטן או שווה לאיזשהו ערך A היא האינטגרל ממינוס אינסוף עד A של פונקצית הצפיפות.

האינטגרל הזה ידוע גם כפונקצית ההתפלגות המצטברת, cumulative distribution function או CDF בקיצור.

הוא מאוד מאוד חשוב לנו אבל אין לו פתרון סגור, רק מקורב. כשאנחנו מדברים על ההתפלגות הנורמלית הסטדנרטית מגדירים אותו פעמים רבות כפונקציה של הערך A ומסמנים באות פי. פי של A הוא שטח ההתפלגות הנורמלית סטנדרטית עד הנקודה A. בואו נראה את הפונקציה פי
:::
:::

---

```{python}
plt.plot(x, stats.norm.cdf(x, 0, 1))
plt.xlabel('a')
plt.ylabel('$\Phi(a)$')
plt.show()
```

::: {.fragment}
If $X\sim N(\mu, \sigma^2)$ then you can create $Z\sim N(0, 1)$ by *standardizing*: $Z = \frac{X - \mu}{\sigma} \sim N(0, 1)$
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
כדי לקבל את פי אני משתמש במתודה cdf של המודול stats.norm. אנחנו יכולים לראות שהיא מתחילה בערך במינוס 3 בערך אפס, כי הסיכוי לקבל ערך פחות ממינוס 3 הוא אפסי, והיא עולה מונוטונית עד אסימפטוטה בערך 1 בערך בערך A=3, כי הסיכוי לקבל ערכים קטנים או שווים ל3 כבר שואף ל1.

איך אנחנו מקבלים מכל משתנה נורמלי עם תוחלת מיו ושונות סיגמא בריבוע את ההתפלגות הנורמלית הסטנדרטית? על-ידי תקנון: אנחנו מחסרים מאיקס את התוחלת שלו ומחלקים בשורש השונות, היא סטיית התקן. ומשתנה נורמלי סטנדרטי שכזה נסמן פעמים רבות באות Z.
:::
:::

---

### $\mu$ and $\sigma$

- The pair of parameters $\mu$ and $\sigma$ are enough to define a Normal distribution.
The expectation is $\mu$ and standard deviation is $\sigma$.

- Morever, once a RV distributes Normal, we know roughly what percentage of the distribution is within one, two, three standard deviations off the mean, e.g. ~95% of the distribution is within 2 $\sigma$s off the mean:

![](images/normal_dist.png)

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
בואו נדבר עוד קצת על התוחלת והשונות של ההתפלגות הנורמלית. שני הפרמטרים האלה מספיקים כדי להגדיר באופן חד משמעי את ההתפלגות, אפשר לראות את זה בנוסחת פונקצית הצפיפות.

יותר מזה, ראינו שעבור התפלגות נורמלית סטנדרטית הערכים יהיו כמעט כולם בין מינוס לפלוס שלוש, ואפשר להכליל את התופעה: בכל התפלגות נורמלית כמעט מאה אחוז מהערכים יהיו בין מינוס לפלוס 3 סטיות תקן מהתוחלת מיו, כ95 אחוז יהיו בין מינוס לפלוס 2 סטיות תקן מהתוחלת. וכ-68 אחוזים יהיו במרחק עד סטיית תקן אחת מהתוחלת.
:::
:::

---

- For example, in our null distribution of mean differences, which had a bell shape to it:

```{python}
mu = np.mean(null_mean_diffs)
sigma = np.std(null_mean_diffs)

print(f'Mean of mean differences: {mu: .2f}')
print(f'SD of mean differences: {sigma: .2f}')
```

- We could fit the Normal distribution with these parameters over the (normalized) histogram, and see if the fit is "good":

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
לדוגמא, באוכלוסית הפרשי הממוצעים שלנו, אם אנחנו טוענים שהיא מתנהגת כמו התפלגות נורמלית, אנחנו אמורים להיות מסוגלים להלביש עליה במרכאות התפלגות כזאת ולראות התאמה לא רעה.

נאמוד את התוחלת מיו עם ממוצע ההתפלגות, יוצא בערך אפס באופן לא מפתיע. נאמוד את סטיית התקן סיגמא עם סטיית התקן של ההתפלגות, יוצא בערך 10.
:::
:::

---

```{python}
plt.hist(null_mean_diffs, bins = np.arange(-45, 45, 5), density = True)
x = np.arange(-45, 45, 0.01)

plt.plot(x, stats.norm.pdf(x, mu, sigma), color = 'red')
plt.show()
```

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
וכשאנחנו מלבישים פונקצית צפיפות עם הערכים האלה על היסטוגרמה מנורמלת של האוכלוסיה שלנו, ההתאמה נראית טובה.
:::
:::

---

- The fit looks "good", and so we could say that 95% of the distribution is within 2 standard deviations off the mean:

```{python}
print(f'({mu - 2 * sigma: .2f}, {mu + 2 * sigma: .2f})')
```

- Our original samples means difference of 15 points is well within these boundaries.

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
אם ההתאמה טובה, ואפשר לקרב את התפלגות ההפרשים המסומלצת שלנו באמצעות התפלגות נורמלית, אפשר למשל להגיד אמירה כמו 95 אחוזים מהערכים יהיו במרחק שתי סטיות תקן מהתוחלת. לחשב ולראות שזה יוצא בערך מינוס עד פלוס 20, ולחזור אל הפרדיגמה של בדיקת השערות, להגיד שהתוצאה של הפרש 15 בין שני מדגמים אמיתיים שקיבלנו, היא בהחלט בתחום הזה של פלוס מינוס 20 ולכן היא לא נראית חריגה!

אז אנחנו מבינים למה היינו רוצים שהתפלגויות ייחוס כאלה יתנהגו נורמלית, זאת התפלגות שנוחה לנו מאוד. אבל עדיין לא אמרנו למה שזה יקרה. נראה שיש לנו משפט שאומר בדיוק את זה: משפט הגבול המרכזי.
:::
:::

---

## Central Limit Theorem (CLT) {.title-slide}

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

### Central Limit Theorem (CLT)

The CLT states that for a random sample ${X_1, \dots, X_n}$ from a population with mean $E(X) = \mu$ and finite variance $V(X) = \sigma^2$, for large enough sample size $n$:

$$\frac{\sum_i X_i}{n} = \overline{X} \dot{\sim} N(\mu, \frac{\sigma^2}{n})$$

Or in other words:

$$\frac{\overline{X} - \mu}{\sigma / \sqrt{n}} \dot{\sim} N(0, 1)$$

::: {.fragment}
- $\frac{\sigma}{\sqrt{n}}$ is called the Standard Error (SE) of the mean

- $Z = \frac{\overline{X} - \mu}{\sigma / \sqrt{n}}$ is the Z statistic
:::

::: {.fragment}
**This has far reaching implications.**
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
משפט הגבול המרכזי, או הcentral limit theorem, טוען שעבור כל מדגם בגודל n תצפיות בלתי תלויות, שבא מהתפלגות עם תוחלת מיו ושונות סופית סיגמא בריבוע, אם n גודל המדגם גדול מספיק, ממוצע המדגם יתפלג בקירוב נורמלית, עם התוחלת המקורית מיו, ושונות קטנה פי n.

הרבה פעמים נשתמש בגירסה המתוקננת של המשפט, אם נחסר מממוצע המדגם את התוחלת ונחלק בסטיית התקן כלומר סיגמא חלקי שורש n, הכמות הזאת מתפלגת נורמלית סטנדרטית.

יש לנו שם לסטיית התקן של ממוצע המדגם, standard error או טעות התקן,
וכאמור לכמות המתוקננת הזאת אנחנו קוראים סטטיסטי Z.

אני לא יודע אם סטודנטים ששומעים לראשונה על משפט הגבול המרכזי מתרשמים ממנו כמו שראוי לו. התוצאה הזאת היא בעלת השלכות אדירות, כי תשימו לב שהמשפט נכון לכל התפלגות מקורית של X, תהא צורתה אשר תהא, ובלבד שהשונות שלה סופית.

הגירסא הראשונה של משפט הגבול המרכזי הוכחה כבר במאה ה18 על-ידי דה-מואבר, ואחר כך במאה ה19 על-ידי לפלאס. המילה מרכזי בשם המשפט הוכנסה שם במאה העשרים כשכבר הבינו כמה הוא מהותי לבדיקת השערות והתקדמות המדע.
:::
:::

---

### Bernoulli Example

- Assume $X_1,\dots,X_n$ are a random sample, with $X_i\sim Ber(p=0.5)$.

- Then $E(X_i) = p= 0.5$ and $Var(X_i) = p(1-p) = 0.25$. 

::: {.incremental}
- We know: $\sum_i X_i \sim Bin(n,p=0.5).$

- The CLT tells us:
$$ \frac{\sum_i X_i}{n} =  \overline{X} \stackrel{\cdot}{\sim} N(0.5,\frac{0.25}{n}),$$

- or: 
$$ \sum_i X_i =  n\overline{X} \stackrel{\cdot}{\sim} N(0.5n,0.25n),$$
if $n$ is big enough.

- So: $N(0.5n,0.25n) \approx Bin(n,0.5)$
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
נראה את משפט הגבול המרכזי קודם על התפלגויות ידועות, למשל התפלגות ברנולי.

יש לנו מדגם בעל n תצפיות X1 עד Xn, שכל אחת תוצאה של ניסוי ברנולי שיכול להצליח כלומר לקבל את הערך 1 בהסתברות p, ונניח שהיא חצי.

לפי חוקי ההתפלגות התוחלת ידועה והיא p עצמו כלומר חצי, והשונות היא p(1-p) כלומר רבע.

אנחנו יודעים כבר, שסכום התצפיות הוא התפלגות אחרת מוכרת לנו, התפלגות בינומית עם n ניסויים וסיכוי להצלחה  חצי.

והנה, לפי משפט הגבול המרכזי, סכום התצפיות חלקי n שזה הממוצע, מתפלג בקירוב נורמלית עם תוחלת חצי, ושונות רבע חלקי n.

אם נכפול את התוצאה הזאת בn נקבל שסכום התצפיות מתפלג נורמלית עם תוחלת חצי n ושנות רבע n. בדקו שאתם מבינים מדוע.

אבל זה אומר, שמצאנו את מה שקרוי הקירוב לנורמלי של משתנה בינומי! משתנה בינומי עם סיכוי חצי, מתפלג נורמלית עם תוחלת חצי n ושונות רבע n, אם מספר הניסויים גדול מספיק!
:::
:::

---

```{python}
#| code-line-numbers: "|1|3-4|8|"
null_res = np.random.binomial(20, 0.5, size=10000)

bin_mean = 20 * 0.5
bin_sd = np.sqrt(20 * 0.5 * 0.5)

N, bins, patches = plt.hist(null_res, bins=np.arange(-0.5, 20.5, 1),density = True)
x = np.arange(-10, 30, 0.01)
plt.plot(x, stats.norm.pdf(x, bin_mean, bin_sd), color = 'red')
plt.show()
```

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
לאברהם דה-מואבר שגילה את התופעה הזאת במאה ה18 לא היה מחשב. לנו, יש פייתון ובאמצעות כמה שורות של קוד אפשר להדגים את התוצאה הזאת, גם אם אנחנו לא מוכיחים אותה באופן פורמלי.

כאן אנחנו דוגמים את התוצאה של משתנה בינומי עם n = 20 לדוגמא וסיכוי חצי, אנחנו עושים את זה עשרת אלפים פעמים ומציירים את ההיסטוגרמה של התוצאות לראות את ההתפלגות.

ההתפלגות נראית כמו התפלגות נורמלית, ואכן, אם נחשב לפי משפט הגבול המרכזי את התוחלת וסטיית התקן שלה ונצייר את התוצאה מעליה, נראה התאמה מרשימה
:::
:::

---

### Exponential Distribution Example

- The Exponential Distribution is another well researched continuous distribution. $X \sim Exp(\lambda)$:

::: {.fragment}
$Supp(X) = [0, \infty)$ (also $\lambda > 0$)

$f(X) = \lambda e^{-\lambda x}$

$F_x(k) = P(X \leq k) = 1 - e^{-\lambda x}$

$E(X) = \frac{1}{\lambda}$

$Var(X) = \frac{1}{\lambda^2}$
:::

::: {.fragment}
- Example: X is the time between two trains from Tel-Aviv to Haifa which come on average every 20 minutes (1/3 hour). So: $X \sim Exp(3)$
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
נראה דוגמא נוספת, הפעם מהתפלגות רציפה ומאוד מאוד לא נורמלית - התפלגות אקספוננציאלית.

אם איקס מתפלג אקספוננציאלית עם פרמטר למדא חיובי זה אומר:
שאיקס יכול לקבל ערכים מאפס עד אינסוף,
יש לנו נוסחה לפונקצית הצפיפות שלו ואפילו נוסחה סגורה לפונקצית ההתפלגות המצטברת.
התוחלת שלו היא 1 חלקי למדא והשונות 1 חלקי למדא בריבוע.

לדוגמא, נהוג הרבה פעמים למדל זמן עד שיקרה אירוע מסוים כמשתנה אקספוננציאלי.  כאן הזמן בין שתי רכבות מתל אביב לחיפה מתפלג אקספוננציאלית. בממוצע אנחנו יודעים שאנחנו ממתינים כעשרים דקות בין שתי רכבות. לכן התוחלת היא שליש והפרמטר למדא של ההתפלגות הוא ההופכי של שליש, שלוש.
:::
:::

---

How it looks (definitely not normal):

```{python}
x = np.arange(0, 10, 0.01)
plt.plot(x, stats.expon.pdf(x, scale = 1/3))
plt.show()
```

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
וכך נראית פונקצית הצפיפות של התפלגות אקספוננציאלית עם פרמטר למדא שווה 3. נשים לב שאני מצייר אותה עם המתודה pdf של המודול stats.expon מספריית scipy. ונשים לב שהפרמטריזציה של המתודה הזאת מעט מבלבלת, כדי לקבל למדא 3 צריך להזין לתוכה דווקא את התוחלת, 1 חלקי למדא, או שליש.

לבסוף נשים לב שההתפלגות הזאת מאוד לא סימטרית, מאוד לא נורמלית!
:::
:::

---

### Exponential Distribution Demo

A demo where $X \sim Exp(3)$, sampling distribution of the mean with $n = 30$:

![](images/clt_exp3_n30.gif)

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
והנה לפנינו סימולציה שלוקחת עוד ועוד מדגם בגדול n = 30 מהתפלגות אקספוננציאלית עם למדא שווה 3, ומציירת את התפלגות ממוצעי המדגם.

תזכרו שההתפלגות המקורית האקספוננציאלית היא לא נורמלית בכלל. אבל התפלגות הממוצעים כן! היא נורמלית סביב התוחלת המקורית שליש.
:::
:::

---

### Exponential Distribution Demo

A demo where $X \sim Exp(3)$, sampling distribution of the mean with $n = 5$:

![](images/clt_exp3_n5.gif)

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
כאן אנחנו רואים סימולציה זהה רק הפעם גודל המדגם הוא n = 5. באופן מדהים, גם כאן היא די סימטרית, אבל לוקח לה הרבה יותר זמן או מדגמים כדי להיראות ממש נורמלית, ואם תבדקו תגלו שהפיזור שלה גדול יותר סביב התוחלת וזה הגיוני, הרי טעות התקן, היא סטיית התקן של הממוצע, היא סיגמא חלקי שורש n, וככל שn גדול יותר כך טעות התקן קטנה יותר. כאן n ממש קטן ונצפה לראות פיזור גדול.

נכון שמשפט הגבול המרכזי הוא תוצאה מרשימה? נראה כעת איך להשתמש בו בבדיקת השערות.
:::
:::

---

## Z-Test {.title-slide}

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
היישום המיידי של משפט הגבול המרכזי בבדיקת השערות הוא מבחן Z.
:::
:::

---

### Z-Test

- The trains from Tel-Aviv to Haifa come every 20 minutes? (null  hypothesis)

- Lately it seems like a lot more (one-sided alternative hypothesis)

::: {.incremental}
- I randomly sampled 30 waiting times between two trains, and got an average $\overline{X} = 4/9$ or 26 minutes and 40 seconds.

- Under the null hypothesis, according to CLT: $\overline{X} \dot{\sim} N(\frac{1}{3}, \frac{1/9}{30})$

- Or: $\frac{\overline{X} - 1/3}{1/\sqrt{270}} \dot{\sim } N(0, 1)$

- We got: $\overline{X} = 4/9$, or $Z = \frac{4/9 - 1/3}{1/\sqrt{270}} = 1.8257$

- We can compute a p-value!
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
נחזור שוב לדוגמא של הזמן ביו שתי רכבות מתל-אביב לחיפה. האם הוא באמת בתוחלת 20 דקות? לאחרונה זה נראה לי יותר. כלומר יש כאן מצב של בדיקת השערות: השערת האפס, ברירת המחדל, מה שמספרים לנו, היא תוחלת של 20 דקות. וההשערה האלטרנטיבית היא חד צדדית, יותר מ20 דקות.

אני דוגם בצורה אקראית 30 זמני המתנה, מחשב ממוצא ומקבל: ארבע תשיעיות השעה, או 26 דקות ו-40 שניות. נשים לב שזה די גבוה, הרי אמרו לנו 20 דקות, ואנחנו הגענו ל26 דקות בממוצע! אבל אולי זה קרה במקרה? זה בדיוק מה שאנחנו מנסים להעריך, אבל בשביל להעריך את זה אנחנו צריכים לדעת איך מתפלג ממוצע המדגם?

לפי משפט הגבול המרכזי ממוצע המדגם מתקרב בקירוב נורמלית תחת השערת האפס עם התוחלת המקורית של ההתפלגות האקספוננציאלית שליש, ושונות קטנה פי 30 מהשונות המקורית, או תשיעית חלקי 30.

או בצורה המתקוננת, אני מחסר מהממוצע שליש ומחלק בטעות התקן, והכמות הזאת כבר מתפלגת בקירוב נורמלי סטנדרטי.

כעת אני מציב ממוצע 4 תשיעיות, ומקבל ערך Z של 1.825.

הערך הזה מתקבל מהתפלגות נורמלית סטנדרטית ואין לי שום בעיה לחשב לו pvalue. הpvalue יהיה הסיכוי לקבל ערך קיצוני כמו 1.82 או יותר תחת ההתפלגות הנורמלית הסטנדרטית. לכל התהליך הזה, קוראים מבין Z, ואפשר לעשות אותו אם השונות ידועה.
:::
:::

---

```{python}
one_sided_p_value = 1 - stats.norm.cdf(4/9, 1/3, np.sqrt(1/270))
#or
one_sided_p_value = 1 - stats.norm.cdf(1.8257, 0, 1)

print(f'P(X_bar >= 4/9 | H0) = {one_sided_p_value: .2f}')
```

::: {.fragment}
- And this looks pretty extreme (lower than 5%), and we "reject the null hypothesis" and conclude that indeed it seems like the waiting time has increased.
:::

::: {.fragment}
**Important question**: what if $\overline{X} = 2/9$?
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
בפייתון, אפשר להשתמש במתודה cdf שראינו שבעצם מחזירה את פי, האינטגרל שאנחנו רוצים. אבל בפייתון לא חייבים לתקנן את המשתנה. אפשר לשאול מה ההסתברות לקבל 4 תשיעיות או יותר במשתנה נורמלי סטנדרטי שזו התוחלת שלו וזו סטיית התקן. ואפשר לשאול מה הסיכוי לקבל את ערך הZ שקיבלנו, 1.82 או יותר, תחת ההתפלגות הנורמלית סטנדרטית.

בכל מקרה הכמות שאנחנו מחפשים, תחת השערת האפס, היא כ3 אחוז. זה הpvalue החד צדדי, והוא נראה קטן מאוד, בודאי קטן מרמת מובהקות אלפא של 5 אחוז, ואנחנו דוחים את השערת האפס, אכן ממוצע של 30 זמני המתנה שעומד על 26 דקות, זה עדות מספקת שזמני ההמתנה הם בתוחלת יותר מ20 דקות.

לפני שנמשיך, מה היה קורה אם זמן ההמתנה הממוצע שהיינו מקבלים היה 2 תשיעיות או בערך 13 דקות, כלומר פחות מ20 דקות? אפשר היה להמשיך כרגיל ולחשב pvalue. אבל אם תחשבו על זה, התוצאה הזאת היא בכלל לא בכיוון ההשערה האלטרנטיבית, של זמן המתנה יותר מ20 דקות. ברור שהpvalue יצא גדול מאוד ולא נדחה את השערת האפס ולכן אין טעם לחשב אותו במקרה כזה. שימו לב שאחרי כל העבודה הקשה של איסוף נתונים למדגם, התקבלה תוצאה שעוצרת את המחקר על הסף. אם הממוצע עצמו לא גדול מ20 דקות, אין סיבה להמשיך, ההשערה נדחית על הסף.
:::
:::

---

### Back to Red Paintings

- Let $X$ be the red pixel level of impressionist paintings images.

- Let $Y$ be the red pixel level of realist paintings images.

- (They don't have a normal distribution, which is fine). 

- Under $H_0$ they both come from the same distribution with $E(X) = E(Y) = \mu$ and $Var(X) = Var(Y) = \sigma^2$.

- Sample size was $n = 30$ for both independent samples.

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
בחזרה לציורים שלנו, הפעם בלי סימולציה של התפלגות האפס.

X יהיה רמת האדום בציורים אימפרסיוניסטיים. Y יהיה רמת האדום בציורים ריאליסטיים. אנחנו ממש לא מניחים שX או Y או שניהם הם בעלי התפלגות נורמלית - יותר מזה, אם תחזרו לשיעור הראשון תראו שכבר סרטטנו את ההתפלגות הזאת והיא ממש לא היתה נורמלית, אפילו לא סימטרית. אבל זה בסדר, כי יש לנו את משפט הגבול המרכזי.

תחת השערת האפס התוחלות של X ושל Y זהות לאיזשהו מיו, ואנחנו נניח שהשוניות גם זהות לאיזשהו סיגמא בריבוע.

גודל המדגם שלנו הוא 30 לשני המדגמים.
:::
:::

---

### Null distribution of the difference in means

::: {.incremental}
- So under $H_0$, according to CLT, the sampling distribution for both samples means is Normal: $\overline{X} \stackrel{\cdot}{\sim} N(\mu, \frac{\sigma^2}{n})$, $\overline{Y} \stackrel{\cdot}{\sim} N(\mu, \frac{\sigma^2}{n})$

- We were interested in the distribution of the means differences, which we now know should be approximately Normal:
$$\overline{X} - \overline{Y} \stackrel{\cdot}{\sim}  N(0, \frac{\sigma^2}{n} + \frac{\sigma^2}{n})$$ (make sure you understand why!)

- In other words, under $H_0$:
$$\frac{(\overline{X} - \overline{Y}) - 0}{\sqrt{\frac{2 \sigma^2}{n}}} \stackrel{\cdot}{\sim} N(0, 1)$$

- Only one thing is missing: we do not know what $\sigma$ is (Do we know what $\mu$ is? Why is that not a problem?)
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
כעת בלי סימולציה נטען לפי משפט הגבול המרכזי שממוצע כל אחד מהמדגמים מתפלג בקירוב נורמלית עם התוחלת הזה מיו והשונות הזהה סיגמא בריבוע חלקי n.

אנחנו מעונינים בהתפלגות הסטטיסטי ממוצע X פחות ממוצע Y. לפי חוקי ההתפלגות הנורמלית סכום או הפרש שני משתנים נורמליים בלתי תלויים מתפלג גם הוא נורמלית עם סכום או הפרש התוחלות, וסכום השונויות. במקרה שלנו הפרש התוחלות תחת השערה האפס הוא מיו פחות מיו, אפס.

לכן תחת השערת האפס נסכם שהסטטיסטי שלנו חלקי שורש של שני סיגמא בריבוע חלקי n מתפלג נורמלית סטנדרטית.

רק בעיה אחת קטנה: אנחנו לא יודעים מה זה סיגמא. שימו לב שאנחנו גם לא יודעים מהו מיו אבל תחת השערת האפס הוא נעלם בהפרש.
:::
:::

---

### Impressionist and Realist Paintings - Z-Test

- Let's assume for now we estimate it from the population: $\sigma$ = `np.std(population) = 39.3`.

- So under $H_0$: $\overline{X} - \overline{Y} \stackrel{\cdot}{\sim}  N(0, \frac{2\cdot 39.3^2}{30} = 10.15^2)$

- Or: $\frac{(\overline{X} - \overline{Y}) - 0}{10.15} \stackrel{\cdot}{\sim}  N(0, 1)$

::: {.fragment}
- And we got: $\overline{X} - \overline{Y} = 15$, or $Z = \frac{15}{10.15} = 1.48$
:::

::: {.fragment}
- And we can perform a Z-Test and compute the p-value:

```{python}
one_sided_p_value = 1 - stats.norm.cdf(15, 0, 10.15)
#or
one_sided_p_value = 1 - stats.norm.cdf(1.48, 0, 1)

print(f'P(mean_diff >= 15 | H0) = {one_sided_p_value: .2f}')
```
:::

::: {.fragment}
- Which is similar to the result we got using our "known population".
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
אז נניח לעת עתה שאנחנו כן יודעים מהי סיגמא, ובמקרה שלנו אפשר פשוט לחשב אותה על סמך 16 אלף ציורים, זה יוצא 39.3. נציב את זה ונראה שתחת השערת האפס הפרש הממוצעים מתפלג נורמלית עם תוחלת אפס וסטיית תקן 10.15. או בצורה המתוקננת, הפרש הממוצעים חלקי 10.15 מתפלג נורמלית סטנדרטית.

הפרש הממוצעים שהתקבל הוא בערך 15 נקודות, מחולק ב15 זה אומר שסטטיסטי Z במבחן Z שלנו הוא קצת פחות מ1.5.

בפייתון אפשר או להשתמש בערך המקורי של 15 או בערך המתוקנן 1.48 כדי לקבל את הpvalue, ואנחנו מקבלים בערך 7 אחוזים pvalue. זה מאוד דומה לערך שקיבלנו בסימולציה, ובכל מקרה לא מספיק קטן ומרשים ולא נדחה את השערת האפס.

אבל זה לא סביר שנדע את סטיית התקן של ההתפלגות המקורית, נכון? במקרה כזה אנחנו עושים התאמות ובמקום מבחן Z מקבלים את מבחן T.
:::
:::

---

## T-Test(s) {.title-slide}

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

### From Z-Test to T-Test

But $\sigma^2$ isn't known!

::: {.incremental}
- Solution: replace the unknwon $\sigma^2$ by the unbiased estimator $S^2 = \frac{1}{n - 1}\sum{(X_i - \overline{X})^2}$

- For a Standard Normal RV $Z=\frac{\overline{X} - \mu}{\sigma / \sqrt{n}}$, if we replace the unknown $\sigma$  by $S$, we get a new distribution called **Student's t** distribution:
$$T = Z \frac{\sigma}{S} = \frac{\overline{X} - \mu}{S / \sqrt{n}} \sim t_{n - 1}$$

- This statistic distributes "$t$ with $n - 1$ degrees of freedoms (df)", hence called the T statistic.
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
אז מה עושים כשההתפלגות המקורית והשונות שלה לא באמת ידועות?

במקרה הזה נהוג להחליף את סיגמא בריבוע בנוסחאות שלנו באמצעות האומד לשונות שהתקבל מהמדגם שמסומן בS בריבוע. והוא סכום המרחקים הריבועיים של X מממוצע המדגם חלקי n פחות 1. למה n פחות 1? מי שירצה ללמוד על הדברים האלה לעומק יוכיח שבמקרה כזה האומד שלנו לסיגמא ריבוע הוא אומד חסר הטיה, כלומר התוחלת של הסטטיסטי הזה שווה לסיגמא בריבוע.

אבל, כשאנחנו מחליפים את סיגמא בסטטיסטי Z שלנו באמצעות S, הוא כבר לא מתפלג נורמלית סטנדרטית, אלא הוא מתפלג T, עם פרמטר שנקרא דרגות חופש והוא n פחות 1. מי שירצה להרחיב בקורס מתקדם יראה שלהתפלגות הזאת גם יש פונקצית צפיפות מעניינת, אנחנו פשוט קוראים לה student's T או T בקיצור על שום החוקר שניסח אותה לראשונה william Gosset.

:::
:::

---

The t distribution has "longer tails" than the Standard Normal distribution for small $n$, reflecting the added uncertainty once $\sigma$ isn't known but estimated by $S$.

But for $n \geq 120$ it is similar to the Standard Normal:

```{python}
x = np.arange(-4, 4, 0.01)
plt.figure(figsize=(4, 4))
plt.plot(x, stats.norm.pdf(x, 0, 1), color = 'red')
plt.plot(x, stats.t.pdf(x, 5), color = 'blue')
plt.plot(x, stats.t.pdf(x, 120), color = 'green')
plt.gca().legend(('N(0,1)','t(5)', 't(120)'))
plt.show()
```

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
לפונקצית הצפיפות של T עם n - 1 דרגות חופש יש צורה שמזכירה מאוד את ההתפלגות הנורמלית, היא פשוט רחבה יותר, או הזנבות שלה עבים יותר. אפשר לראות את זה כתוצאה של עוד אי-ודאות שנכנסה לתהליך ההסתברותי, הרי אנחנו אומדים כעת את סטיית התקן S והיא לא נתונה לנו כמקודם.

כאן, אני מצייר את ההפתגות T עם 5 דרגות חופש בכחול, ולידה את ההתפלגות T עם 120 דרגות חופש בירוק. אני מצייר גם את ההתפלגות הנורמלית הסטנדרטית באדום אבל היא ממש בלתי מובחן מההתפלגות T עם 120 דרגות חופש בירוק. הסיבה היא שככל שגודל המדגם או דרגות החופש גדלות, כך ההתפלגות T נעשית רזה ורזה יותר ושואפת להתפלגות הנורמלית סטנדרטית. כך שעבור מדגמים גדולים מספיק זה כבר לא משנה כל כך אם משתמשים במבחן Z עם הנחה שסטיית התקן ידועה או משתמשים במבחן T.
:::
:::

---

### One Sample T-Test

- Again: Under $H_0$, with a large sample $n$, according to CLT: $\frac{\overline{X} - \mu}{\sigma / \sqrt{n}} \sim N(0, 1)$ 

- Now the $\sigma$ is unknown. $\mu$ is known under the null hypothesis, often $H_0 : \mu = 0$

- We replace $\sigma$ by its estimator: $S = \sqrt{\frac{1}{n_x - 1}\sum{(X_i - \overline{X})^2}}$

- We get:
$$T=\frac{\overline{X} - \mu_{H0}}{\sqrt{\frac{S^2}{n}}} \sim_{H_0} t_{n - 1}$$

- And you can perform a t-test using e.g. `stats.ttest_1samp(x, 0)`.

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
אז מהו מבחן T?

הסטטיסטי T מתקבל כאשר מחסרים מהממוצע את התוחלת תחת השערת האפס, ומחלקים בטעות התקן הנאמדת, S בריבוע חלקי N. תחת השערת האפס הסטטיסטי T מתפלג T עם n - 1 דרגות חופש, ואם רוצים לקבל אותו ואת הp-value שמקושר אליו אפשר להשתמש במתודה ttest_1samp מספריית statsmodels.

לדוגמא אם תחת השערת האפס התוחלת היא אפס, והמדגם שלנו נמצא באוביקט x, כך נבצע מבחן t לראות אם התוחלת שונה מאפס.
:::
:::

---

### Two Independent Samples T-Test

- In our kind of problems we have two samples: $X_1,\dots,X_{n_x}$ and $Y_1,\dots,Y_{n_y}$. In our case also $n_x=n_y=30$. 

- Our null hypothesis of interest is $H_0: \mu_x = \mu_y$. We will also assume $\sigma^2_X = \sigma^2_Y$. 

::: {.incremental}
- Now, **assuming the variances are equal** we can use the CLT and write that under $H_0$: 
$$\frac{(\overline{X} - \overline{Y}) - (\mu_x - \mu_y)}{\sqrt{\sigma^2(\frac{1}{n_x}+\frac{1}{n_y})}} \sim N(0, 1)$$

- Since we do no know $\sigma^2$, but we assume it is equal for both groups under the null, we estimate it: $S^2_p = \frac{(n_x - 1)S^2_x + (n_y - 1)S^2_y}{n_x + n_y - 2}$

- And the distribution is $t$ with $n_x + n_y - 2$ degrees of freedom:
$T = \frac{\overline{X} - \overline{Y} - (\mu_x - \mu_y)}{\sqrt{\frac{S_p^2}{n_x} +\frac{S_p^2}{n_y}}} \sim t_{n_x+n_y -2}$
 
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
אם יש לנו שני מדגמים, המבחן הראוי הוא מבחן T למדגמים בלתי תלויים. יש לנו מדגם X או רמת האדום בציורים אימפרסיוניסטיים בגודל n_x, ומדגם Y בגודל n_y, במקרה שלנו שני הn-ים זהים והם 30 אבל זה לא חייה להיות כך.
השערת האפס היא שתוחלת איקס שווה לתוחלת וואי. נניח גם שוויון שונויות, סיגמא בריבוע של X שווה לסיגמא בריבוע של Y.

תחת הנחת שוויון שונויות, הסטטיסטי שלנו מתקונן הוא הפרש הממוצעים, פחות הפרש התוחלות, חלקי טעות התקן שמקבלת כאן צורה שכזאת. זה היה מתפלג בקירוב נורמלית סטנדרטית תחת משפט הגבול המרכזי.

אבל אנחנו לא יודעים מהי השונות המשותפת ומחליפי אותה באומד שנקרא S pooled, שהוא בעצם ממוצע משוקלל של האומד לשונות של מדגם X ושל מדגם Y.

הסטטיסטי הסופי שלנו הוא הפרש הממוצעים פחות הפרש התוחלות תחת השערת האפס, מחולק באומד לטעות התקן. הדבר הזה תחת השערת האפס מתפלג T עם n_x + n_y -2 דרגות חופש. נשים לב שהרבה פעמים השערת האפס היא שמיו איקס שווה למיו וואי, ולכן בפועל הפרש התוחלות יהיה אפס, וזה יפשט קצת את המונה.
:::
:::

---

### Unequal Variances Assumed (extra credit)

Can still use the CLT and write that under $H_0$: 

$\frac{(\overline{X} - \overline{Y})- (\mu_x - \mu_y)}{\sqrt{\frac{\sigma^2_X}{n_x}+\frac{\sigma^2_Y}{n_y}}} \sim N(0, 1)$ 

We replace $\sigma_x$ by its estimator: $S_x = \sqrt{\frac{1}{n_x - 1}\sum{(X_i - \overline{X})^2}}$ and the same for $\sigma_y$.

We keep the SE estimator of $\sqrt{\frac{S_x^2}{n_x} +\frac{S_y^2}{n_y}}$:

$\frac{\overline{X} - \overline{Y} - (\mu_x- \mu_y)}{\sqrt{\frac{S_x^2}{n_x} +\frac{S_y^2}{n_y}}} \sim t_{df'}$

Where: $df'=\frac{\left(\frac{S_x^2}{n_x}+\frac{S_y^2}{n_y}\right)^{2}}{\frac{\left(S_x^2/n_x\right)^2}{n_x-1}+\frac{\left(S_y^2/n_{2}\right)^{2}}{n_y-1}}$


::: {.notes}
::: {style="direction:rtl; font-size:16px"}
מה קורה אם אנחנו לא מניחים שוויון שונויות?

אם אנחנו לא מניחים שוויון שונויות אז האומד לטעות התקן שלנו משתנה מעט, אנחנו כבר לא מחשבים את s-pooled. ואז מקובל לבצע תיקון בחישוב דרגות החופש שמסומנות כאן כdf, degrees of freedom. יש נוסחה לא מאוד סימפטית לזה, לא תצטרכו בקורס שלנו לחשב אותה ידנית כי בכל מקרה נחשב בפייתון.
:::
:::

---

### Impressionist and Realist Paintings - T-Test

- Recall the null hypothesis: $H_0: \mu_x = \mu_y$

- Recall our samples:

```{python}
print(real_red[:10])
print(impr_red[:10])
```

::: {.fragment}
- First manually:

```{python}
S2_x = np.var(impr_red, ddof = 1) # for getting the "n - 1" unbiased estimator of sigma
S2_y = np.var(real_red, ddof = 1)
n_x = n_y = 30
S2_p = ((n_x - 1)*S2_x + (n_y - 1)*S2_y) / (n_x + n_y - 2)

t_statistic = (np.mean(impr_red) - np.mean(real_red))/np.sqrt(S2_p/n_x + S2_p/n_y)
print(f'T statistic: {t_statistic: .4f}')

one_sided_p_value = 1 - stats.t.cdf(t_statistic, n_x + n_y - 2)
print(f'P(mean_diff >= 15 | H0) = {one_sided_p_value: .3f}')
```
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
בחזרה לציורים שלנו: השערת האפס שלנו היא אכן שהתוחלות של רמת האדום בציורים אימפרסיוניסטיים וריאליסטיים הן זהות או במילים אחרות הפרש התוחלות הוא אפס. הנה עשר התצפיות הראשונות מכל מדגם:

בצורה ידנית, כדי לראות שהנוסחאות עובדות, ניתן לחשב את סטטיסטי טי: הפרש הממוצעים, חלקי האומד לטעות התקן בדיוק כפי שכתבנו. הסטטיסטי יוצא בערך 1.38, ובאמצעות המתודה cdf במודול stats.t, אנחנו מחשבים את הp-value  החד-צדדי, כלומר הסיכוי לקבל בהתפלגות T עם 58 דרגות חופש 1.38 או יותר --

וזה יוצא כשמונה וחצי אחוזים.
:::
:::

---

- Now with Python's built-in function:

```{python}
stats.ttest_ind(impr_red, real_red, alternative='greater')
```

::: {.fragment}
- Anyway, p-value of 8.5% isn't convincing and we do not reject the null hypothesis.
:::

::: {.fragment}
- Notice the T-test p-value of 8.5% is greater than the Z-test p-value of 7%, which makes sense:

- **We gave up the known variance assumption, added uncertainty (the SD estimate S is a RV), got the $t$ distribution with "heavier" tails, need more extreme values to impress.**
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
את כל החישוב המסורבל הזה אפשר לבצע בשורה אחת עם הפונקציה ttest_ind גם היא מהמודול stats של ספריית scipy.

אבל כדי לבצע מבחן חד-צדדי צריך לפרט alternative = 'greater'. בכל מקרה קיבלנו בדיוק את התוצאה של המבחן הידני.

וpvalue של 8.5 אחוזים הוא לא מרשים במיוחד ואנחנו לא דוחים את השערת האפס.

נשים לב שהpvalue שקיבלנו של 8.5 אחוזים גדול יותר מהpvalue של המבחן Z המדויק שיצא כ7 אחוזים. זה לא במקרה. ויתרנו על הנחת השונות הידועה, זה בא לידי ביטוי בתיאוריה שלנו שהובילה אותה להתפלגות t שיש לה זנבות עבים יותר, כלומר הסיכוי לקבל בה תוצאות קיצוניות יותר גדול יותר. מה שאומר שכדי לדחות השערות בהתפלגות T צריך תוצאות קיצוניות יותר.
:::
:::

---

## Confidence Intervals (CI) {.title-slide}

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

### Confidence Intervals (CI)

- One (of a few) problem with p-value: it is not informative.

- With large enough sample size any result can become "significant" (why?).

- Statistical significance is not scientific significance.

::: {.incremental}
- Often we would prefer reporting what the actual mean $\mu$ (or means difference $\mu_x - \mu_y$) was, to show it was "interesting".

- But since our sample mean $\overline{X}$ (or sample means difference $\overline{X} - \overline{Y}$) is most probably WRONG, it comes with uncertainty, we report a Confidence Interval:

- "$\mu$ is within $\left[\overline{X}-\epsilon, \overline{X}+\epsilon\right]$ with 95% level of confidence"
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
ביחידה זו נדבר על רווחי סמך. אחת הבעיות עם חישובי pvalue או איזורי דחייה, היא שעדיין בסופו של דבר מדובר במבחן החלטה בינארי שאיננו אינפורמטיבי. אם מגדילים את מרחב המדגם, גם אפקטים קטנים מאוד יכולים להיות "מובהקים סטטיסטית" - תראו לזה דוגמאות בהמשך ובתרגול. וזה שאפקט הוא מובהק סטטיסטית, לא אומר שהוא אכן מעניין מדעית, מה שמביא הרבה פעמים מדענים לעשות רדוקציה למחקר המדעי שלהם, למעבר של הערך הזה, ותו לא.

אולי עדיף לתאר איזשהו אומד לפרמטר עליו מתבצע המבחן. זה יכולה להיות תוחלת של משתנה או הפרש התוחלות כמו במקרה של הציורים שלנו. ולא דיווח רק על הpvalue והאם הוא קטן יותר מרמת המובהקות אלפא או לא.

הבעיה היא שממוצע המדגם או הפרש ממוצעי המדגם הם אומד נקודתי שהוא בסבירות גבוהה לא נכון!, ולכן היינו רוצים לדווח טווח, שנקרא רווח סמך:

האמירה תהיה התוחלת מיו נמצאת בטווח X גג פלוס-מינוס איזשהו אפסילון, ברמת ביטחון של 95% או 90%. איך אנחנו מוצאים טווח כזה?
:::
:::

---

### Building the CI: Z-Test

- In general: for a random sample $X$ from distribution with unknown parameter $\theta$, $[LB(X), UB(X)]$ is a $100(1-\alpha)\%$ CI for $\theta$ if $P(LB(X) < \theta < UB(X)) = 1 - \alpha$

- Usually: $\alpha = 0.05$ and we would build a *symmetric* CI around some $\hat{X}$ estimator of $\theta$, like $\overline{X}$

::: {.fragment}
- For the Z-test:

$P(Z_{0.025} < \frac{\overline{X} - \mu}{\sigma/\sqrt{n}} < Z_{0.975}) = P(\overline{X} + Z_{0.025}\frac{\sigma}{\sqrt{n}} < \mu < \overline{X} + Z_{0.975}\frac{\sigma}{\sqrt{n}}) = 0.95$ 

where $Z_q$ is the $q$th quantile (100$q$ precentile) of the $N(0, 1)$ distribution
:::

::: {.fragment}
$\implies \left[\overline{X} + Z_{0.025}\frac{\sigma}{\sqrt{n}}\;,\; \overline{X} + Z_{0.975}\frac{\sigma}{\sqrt{n}}\right]$ or $\overline{X} \pm 1.96\frac{\sigma}{\sqrt{n}}$ is a 95% CI for $\mu$
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
לדוגמא במבחן Z, נרצה ערכים lower bound ו-upper bound, שמבוססים על המדגם X, שאנחנו נטען שבהסתברות 1 מינוס אלפא, מכסים איזשהו פרמטר אמיתי תטא אותו אנחנו מנסים להעריך. טווח כזה ייקרא רווח סמך ברמת ביטחון 100 כפול 1 מינוס אלפא אחוז.

בדרך כלל אלפא יהיה 0.05 או 0.1, ורווח הסמך שלנו יהיה סימטרי סביב איזשהו אומד X האט לתטא שמבוסס על המדגם, למשל ממוצע המדגם.

עבור מבחן Z, אנחנו יודעים ממשפט הגבול המרכזי שהממוצע המתוקנן נמצא בין האחוזון ה-2.5 לבין האחוזון ה97.5 בהסתברות 0.95. אחרי קצת משחק אלגברי והעברת אגפים תקבלו שני ערכים lower ו-upper bounds, שעונים בדיוק על ההגדרה המבוקשת: הם מכסים את הפרמטר מיו בהסתברות 0.95.

וזה אומר שהם מהווים רווח סמך ברמת בטחון 0.95 עבור התוחלת מיו. מאחר שהאחוזונים של ההתפלגות הנורמלית סטנדרטית הם סימטריים, הקטן הוא מינוס 1.96 והגדול הוא פלוס 1.96, וכך אנו מגיעים לרווח סמך שציפינו להגיע אליו לפרמטר התוחלת: ממוצע המדגם פלוס מינוס איזשהו אפסילון.
:::
:::

---

### CI for Waiting Time for Train

- Recall: Under $H_0$ $X \sim Exp(3)$ so: $\sigma = \frac{1}{3}$

- We got: $\overline{X} = \frac{4}{9}; \space n = 30;$

- 95% CI for $\mu$:

```{python}
LB = 4/9 - stats.norm.ppf(0.975) * (1/3)/np.sqrt(30)
UB = 4/9 + stats.norm.ppf(0.975) * (1/3)/np.sqrt(30)
print(f'[{LB: .3f}, {UB: .3f}]')
```

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
בדוגמת זמני ההמתנה של הרכבת, תחת השערת האפס זמן ההמתנה מתפלג אקספוננציאלית עם איזשהו פרמטר למדא, והממוצע מתפלג נורמלית בקירוב ממשפט הגבול המרכזי. נניח גם שסטיית התקן נשארת כפי שהיא והיא ידועה, שליש. ממוצע המדגם שהתקבל הוא ארבע תשיעיות, גודל המדגם היה 30, מציבים בנוסחת רווח הסמך, ומקבלים שתוחלת זמן ההמתנה בין 0.32 שעה, לבין 0.56, שזה אומר בערך בין 19.5 דקות לבין לכמעט 34 דקות.

חדי העין ביניכם ודאי שמים לב שהזמן מהשערת האפס -- 20 דקות -- נמצא ברווח הסמך הזה, כלומר בסיכוי 0.95 אנחנו לא פוסלים את האפשרות הזאת. אבל אם אתם זוכרים דחינו את השערת האפס כשביצענו בדיקת השערות לנתונים האלה במבחן Z. אבל, אנחנו ביצענו בדיקת השערות חד-צדדית, כלומר שיערנו מראש שמני ההמתנה ארוכים יותר. ואם היינו עודים בדיקת השערות דו-צדדית, שזמן ההמתנה פשוט השתנה, אכן לא היינו דוחים את השערת האפס, גם בגישת הpvalue. יש קשר הדוק בין בדיקת השערות דו-צדדית לבין הימצאות או אי-הימצאות הפרמטר מהשערת האפס ברווח הסמך. תדברו על זה עוד בתרגול.

בינתיים נסכים שאמירה כמו זמן ההמתנה הממוצע הוא בין 19.5 ל34 דקות ברמת ביטחון 95 אחוז היא אמירה מעניינת יותר מדחינו או לא דחינו את השערת האפס.
:::
:::

---

### Meaning of CI

- Most common misconception of CI: "The probability that $\mu$ is within [0.33, 0.56] is 95%"
    
- **The number** $\mu$ is either within the CI or not, $\mu$ is a parameter, not a RV!

- But what *does* it mean?

::: {.fragment}
A demo where $X \sim Exp(3)$, confidence interval for the mean with $n = 30$:

![](images/ci_exp3_n30.gif){width="40%"}
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
טעות נפוצה שעושים כולם בתחום, מסטודנטים ועד מדענים היא להגיד: ההסתברות שמיו נמצא בין 0.33 ל-0.56 היא 95 אחוז.

מבחינה הסתברותית זו אמירה בעייתית ביותר וחשוב לי שתימנעו ממנה. מיו, התוחלת, היא פרמטר. היא או נמצאת ברווח הסמך או שלא. היא לא משתנה מקרי! זה כמו להגיד 2 נמצא בהסתברות 0.95 בין 3 ל-4 -- הוא או נמצא שם או לא.

אז למה כן אנחנו מתכוונים כשאנחנו אומרים "רווח סמך ברמת ביטחון 95%" אנחנו אומרים שאם היינו עורכים הרבה מדגמים בצורה דומה, ב95% מהם הרווח סמך שאנחנו בונים עם הערך העליון והתחתון שלנו, היו מכסים את הפרמטר האמיתי מיו. כך שהאמירה ההסתברות היא על גבולות רווח הסמך, הם (!) המשתנים המקריים, לא הפרמטר.

נדגים: לפנינו הרבה הרבה ניסויים חוזרים של המדגם שלנו, לקחת 30 תצפיות מהתפלגות אקספוננציאלית עם פרמטר למדא שווה 3, ולבנות מממוצע המדגם רווח סמך לתוחלת, שאנחנו יודעים שהיא שליש, כי ככה הגרלנו את הנתונים. אפשר לראות, שלמרות שהנתונים מגיעים מהתפלגות ידועה רווח הסמך מכסה את התוחלת רק ב95% מהמקרים בקירוב. ולזה אנחנו מתכוונים כשאנחנו מדברים על רמת סמך או רמת ביטחון.
:::
:::

---

### Building the CI: T-Test

- For One-Sample T-Test:

$\left[\overline{X} + t_{n-1;0.025}\;\frac{S}{\sqrt{n}}, \overline{X} + t_{n-1;0.975}\;\frac{S}{\sqrt{n}}\right]\;$ or<br> $\;\overline{X} \pm t_{n-1,0.975}\cdot\frac{S}{\sqrt{n}}$<br> is a 95% CI for $\mu$

::: {.fragment}
- For Two-Samples T-Test, equal variances assumed:

$\left[(\overline{X} - \overline{Y}) + t_{n_x+n_y-2;0.025}\;\sqrt{\frac{S_p^2}{n_x} +\frac{S_p^2}{n_y}}\;,\; (\overline{X} - \overline{Y}) + t_{n_x+n_y-2;0.975}\;\sqrt{\frac{S_p^2}{n_x} +\frac{S_p^2}{n_y}}\right]$ or<br> $(\overline{X} - \overline{Y}) \pm t_{n_x+n_y-2,0.975}\;\sqrt{\frac{S_p^2}{n_x} +\frac{S_p^2}{n_y}}$<br> is a 95% CI for $\mu_x - \mu_y$
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
עבור מבחן T למדגם בודד יש לנו נוסחה לרווח הסמך לתוחלת מיו. אפשר לראות שעדיין הצורה היא ממוצע המדגם פלוס מינוס איזשהו אפסילון רק שהפעם סטיית התקן לא ידועה והיא נאמדת באמצעות S, והאחוזונים מגיעים מהתפלגות T עם n - 1 דרגות חופש ולא Z.

אותו דבר למבחן T למדגמים בלתי תלויים, ואנחנו רוצים לבנות רווח סמך להפרש התוחלות. עדיין יש לנו איזשהו סטטיסטי כאן הפרש הממוצעים פלוס מינוס איזשהו טווח.
:::
:::

---

#### Impressionist and Realist Paintings - CI for Means Difference

Recall we got: $\overline{X} - \overline{Y} = 15; \space n_x = 30; \space n_y = 30; S^2_p = 1824$

95% CI for $\mu_x - \mu_y$:

```{python}
LB = (np.mean(impr_red) - np.mean(real_red)) - stats.t.ppf(0.975, n_x + n_y - 2) * np.sqrt(S2_p/n_x + S2_p/n_y)
UB = (np.mean(impr_red) - np.mean(real_red)) + stats.t.ppf(0.975, n_x + n_y - 2) * np.sqrt(S2_p/n_x + S2_p/n_y)

print(f'[{LB: .1f}, {UB: .1f}]')
```

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
במקרה של הציורים שלנו נותר רק להציב בנוסחה כדי לתת רווח סמך להפרש רמת האדום בין הסגנון האימפרסיוניסטי לריאליסטי.

ניזכר שהפרש ממוצעי המדגמים היה 15 נקודות, גודל שני המדגמים היה 30 (והם לא חייבים להיות זהים!), וגם חישבנו כבר את S-pooled ויצא 1824. לכן רווח סמך להפרש התוחלות אימפרסיוניסטי פחות ריאליסטי יהיה בין -6.8 לבין 37.4.

ושוב נשים לב רווח הסמך כולל את האפשרות 0 בתוכו, האפשרות שמשמעותה היא שאין הבדל ברמת האדום בין שני הסגנונות ציור, ואפשר להגיד שמכאן לא היינו דוחים השערת אפס דוצדדית שהתוחלות שוות. אבל האמירה הכרוכה ברווח סמך, מדעית, היא מעניינת יותר.
:::
:::

---

## Power {.title-slide}

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
הנושא האחרון שנעסוק בו בבדיקת השערות הוא עוצמת המבחן. הבנה של העוצמה הסטטיסטית של מבחן מדעי היא אקוטית לכל חוקרת שרוצה לבצע ניסויים, ורצוי לדעת מהי עוצמת המבחן של הניסוי שאת מבצעת לפני שאת מבצעת אותו, ולא כשהוא עובדה מוגמרת! הרבה פעמים מדענים מערבים אינטואיציה לא נכונה בחישוב עוצמת המבחן, לא מבצעים חישובים מדויקים, ומסתבר להם רק בדיעבד שהשקיעו הרבה זמן ומשאבים במבחן בעל עוצמה נמוכה.
:::
:::

---

### Power

- If we take the "true" means difference of the red level pixel in impressionst paintings "population" vs. realist:

```{python}
#| output-location: fragment

true_mean_diff = np.mean(impr_red_all) - np.mean(real_red_all)
print(f'True means difference: {true_mean_diff: .2f}')
```

::: {.incremental}
- Surprise: it *is* in fact higher, by 15 points.

- Let's assume for the time being that this is "interesting" (is it, though?)

- It turns out the null hypothesis, which we have not rejected, was wrong, impressionist paintings *are* "redder"

- Why did we fail to reject the null hypothesis, and would likely fail again?

- We lacked **Statistical Power**: the probability of correctly rejecting the null hypothesis when the null is false, when the alternative is actually the case.
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
ניזכר מהי עוצמת המבחן באמצעות הדוגמא של הציורים. זכרו שכאן כל האוכלוסיה היא בעצם בכף ידנו, ושורה אחת של קוד בפייתון תגלה לנו מהו באמת ההבדל ברמת האדום בין ציורים אימפרסיוניסטים לריאליסטיים. אני לוקח כאן את רמת האדום של כל הציורים האימפרסיוניסטיים פחות רמת האדום של כל הציורים הריאליסטיים, וראו זה פלא:
יש אכן הבדל, של קצת יותר מ15 נקודות, בין רמת האדום של שני הסגנונות. זאת האמת.

נניח לרגע שזה הבדל מעניין מבחינה מדעית, למראות שבסקאלת אדום של 0 עד 255 -- לא כל כך בטוח.

זה אומר שהשערת האפס שלנו, אותה לא דחינו, היתה שגויה, וביצענו טעות מסוג ראשון.

למה טעינו? ואם היינו עורכים את הניסוי שוב - האם סביר שהיינו טועים שוב?

התשובה נעוצה בעוצמת המבחן: ההסתברות לדחות את השערת האפס כשזו באמת לא נכונה. כאן, תיכף נראה, ההסתברות הזאת -- עוצמת המבחן -- היתה קטנה. ואם היינו אומדים אותה מראש אולי יכולנו לתכנן ניסוי טוב יותר.
:::
:::

---

#### Impressionist and Realist Paintings - Power Analysis - Simulation

$\pi = P(\text{reject} H_0 | H_1 \text{ true}) = ?$

Let's simulate before we compute. We have the "population", we can just take many impressionist and realist $n=30$ samples, perform a T-test and see the percentage of times we reject the null hypothesis, i.e. p-value $< \alpha$:

::: {.fragment}
```{python}
#| output-location: fragment

def random_sample_t_test(alpha, n):
    real_red_sample = np.random.choice(real_red_all, n, replace=False)
    impr_red_sample = np.random.choice(impr_red_all, n, replace=False)
    t_test = stats.ttest_ind(impr_red_sample, real_red_sample, alternative='greater')
    return (impr_red_sample.mean() > real_red_sample.mean() and t_test[1] < alpha)

n_simulations = 10000
n = 30
alpha = 0.05

rejections = [random_sample_t_test(alpha, n) for i in range(n_simulations)]

print(f'Power = P(reject H0 | H1 ) = {np.mean(rejections): .2f}')
```
:::

::: {.fragment}
With 45% power, it seems only about 1 in 2 samples would have caught our 15 points difference and reject $H_0$!
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
אז עוצמת המבחן שמסומנת כאן בפאי, היא ההסתברות לדחות את H0 כשהיא באמת לא נכונה, כלומר תחת H1, המצב האלטרנטיבי.

במקרה שלנו אפשר קודם לראות את זה עם סימולציה: הרעיון הוא לבצע את הניסוי שכולל לקיחת שני מדגמים בגודל של התקציב שלנו, שוב ושוב, לבצע כל פעם מבחן T למדגמים בלתי תלויים, ולראות באיזה אחוז מהפעמים נדחה בצדק את השערת האפס:

כאן אנחנו מדגימים פונקציה שעושה דגימה ומבצעת מבחן T חד-צדדי כמו שעשינו ומחזירה האם יש דחייה או לא, ערך בינארי, בבת אחת. ואנחנו עושים את זה עשרת אלפים פעמים. ומחשבים כמה פעמים מתוך 10000 דחינו בצדק את השערת האפס.

אנחנו מקבלים סיכוי של 45 אחוז!

עוצמה של 45 אחוז פירושה שבערך באחד מכל שני מבחנים לא נדחה את H0 כשהמציאות היא H1, שצריך לדחות את H0. אם היינו יודעים שזאת עוצמת המבחן שלנו סביר להניח שהיינו רוצים לשנות את הניסוי כדי להגדיל אותה.
:::
:::

---

#### Impressionist and Realist Paintings - Power Analysis - Computation

- In a realistic situation we do not know that $H_0$ should be rejected. We do not know the 15 points "true" difference. And we cannot sample 10,000 times from the population.

- A common approach is to estimate statistical power for different "true" differences or "effect size".

- If we assume that $H_0$ should be rejected and the true difference is 15 points:

$\pi = P(\text{reject} H_0 | H_1 \text{ true}) = P(\text{ getting p-value }< \alpha |\text{ true mean difference is 15 points}) = ?$

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
בפועל אין לנו את כל האוכלוסיה, אנחנו לא יכולים לחזור על הניסוי 10000 פעמים, והכי מאתגר זה שאנחנו לא באמת יודעים את הפרש התוחלות באוכלוסיה גם אם נניח שהוא חיובי.

גישה נפוצה במקרה כזה היא לחשב את עוצמת המבחן לפי פרמטר שנקרא גודל אפקט. ולנסות להתחשב בכמה גדלי אפקט כאלה. גודל האפקט הוא הפרש התוחלות כשמקובל לעשות לו סטנדרטיזציה, לחלק אותו בסטיית התקן או אומדן לסטיית התקן.

נניח למשל שהפרש התוחלות הוא 15 נקודות, ונשאל מה הסיכוי לדחות את H0 תחת האפקט הזה, כלומר לקבל pvalue קטן מאלפא רמת המובהקות כשהפרש התוחלות הוא 15.
:::
:::

---

$P \left(\frac{\overline{X} - \overline{Y} - 0}{\sqrt{\frac{S_p^2}{n_x} +\frac{S_p^2}{n_y}}} > t_{n_x+n_y-2;0.95}| \mu_x -\mu_y = 15\right) =$

$P \left(\frac{\overline{X} - \overline{Y} - (\mu_x - \mu_y) + (\mu_x - \mu_y)}{\sqrt{\frac{S_p^2}{n_x} +\frac{S_p^2}{n_y}}} > t_{n_x+n_y-2;0.95}| \mu_x -\mu_y = 15\right) =$

$P \left(\frac{\overline{X} - \overline{Y} - (\mu_x - \mu_y)}{\sqrt{\frac{S_p^2}{n_x} +\frac{S_p^2}{n_y}}} > t_{n_x+n_y-2;0.95} - \frac{(\mu_x - \mu_y)}{\sqrt{\frac{S_p^2}{n_x} +\frac{S_p^2}{n_y}}}| \mu_x -\mu_y = 15\right) =$

$1 - P \left(\frac{\overline{X} - \overline{Y} - (\mu_x - \mu_y)}{\sqrt{\frac{S_p^2}{n_x} +\frac{S_p^2}{n_y}}} < t_{n_x+n_y-2;0.95} - \frac{(\mu_x - \mu_y)}{\sqrt{\frac{S_p^2}{n_x} +\frac{S_p^2}{n_y}}}| \mu_x -\mu_y = 15\right) =$

```{python}
t_c = stats.t.ppf(0.95, n_x + n_y - 2)
power = 1 - stats.t.cdf(t_c - 15/np.sqrt(S2_p/n_x + S2_p/n_y), n_x + n_y - 2)
print(f'Power = P(reject H0 | H1) = {power: .2f}')
```

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
אפשר להגיע לנוסחה סופית במקרה של מבחן T למדגמים בלתי תלויים עם קצת מאמץ, ורשמתי כאן את הפיתוח למי שרוצה להתעמק. נשים לב שההסתברות מתחילה בדיוק בכלל של מבחן T למדגמים בלתי תלויים: האם הסטטיסטי של הפרש ממוצעי המדגמים, מחולק באומד לטעות התקן, גדול הערך T הקריטי של מבחן T, אם הפרש התוחלות האמיתי הוא 15 נקודות.

בסופו של דבר זה למצוא הסתברות תחת התפלגות T עם כך וכך דרגות חופש, שהססטיסטי שלנו קטן מאיזשהו ביטוי שמסומן כאן.

מציבים אותו בביטוי בפייתון ומקבלים שהעוצמה היא 0.38, דומה למה שקיבלנו, כלומר רק בכ40 אחוז מהניסויים, תחת האפקט הזה של 15 נקודות, היינו דוחים בצדק את השערת האפס.
:::
:::

---

```{python}
# with Python's built-in method:
from statsmodels.stats.power import TTestIndPower

effect = 15/np.sqrt(S2_p) # true means difference divided by S_p
power = TTestIndPower().power(effect_size = effect, nobs1 = 30, alpha = 0.05, ratio = 1, alternative = 'larger')

print(f'Effect size = {effect : .2f}  Power = P(reject H0 | H1) = {power: .2f}')
```

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
ברור שיש לנו פונקציה שעושה את זה, יש לנו קלאס מספריית statsmodels שנקרא TTestIndPower, שאפשר להזין לתוכו את הנתונים שיש לנו ולבקש את הנתון החסר. במקרה הזה אנחנו יודעים שגודל האפקט הוא 15 נקודות, מחולק באומד לסטיית התקן, מספר התצפיות בשתי הקבוצות הוא 30, האלפא המבוקשת היא 0.05 וההשערה שלנו היא חד-צדדית. הערך החסר הוא העוצמה, ונקבל כמו בחישוב הידני 0.38.
:::
:::

---

### Reminder: Type I and Type II Errors


| Reality\\Decision | Not Reject $H_0$    | Reject $H_0$   |
|---|------|-----|
| $H_0$ | Confidence: $1 - \alpha$ | Type I Error: $\alpha$ |
| $H_1$ |  Type I Error: $\beta$    | Power: $1 - \beta$    |

::: {.fragment}
Or in a graph:

![](images/power_curves.png){width="65%"}

:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
איך אפשר להגדיל את עוצמת המבחן?

ניזכר בטבלה שמסכמת את הקשר בין ההסתברויות, וכעת כשאנחנו יודעים שההתפלגויות עצמן ניתן לצייר כהתפלגויות נורמלית, אפשר לייצג את הטבלה הזאת בעצם באמצעות גרף.

תחת השערת האפס הפרש התוחלות הוא אפס. תחת ההשערה האלטרנטיבית הערך הזה חיובי, איזשהו דלתא. אם נעבור בהפרש ממוצעי המדגם איזשהו ערך סף קריטי C נדחה את השערת האפס ונגיד שאנחנו בעצם באיזור ההשערה האלטרנטיבית שמימין. אם אנחנו טועים, הרי שביצענו טעות מסוג ראשון, אנחנו עדיין תחת השערת האפס אבל אנחנו בשטח האלפא שהוא בדרך כלל 1 או 5 אחוזים.
אם לא עברנו את הערך הקריטי, לא מדחה את השערת האפס. אם אנחנו טועים, אנחנו עושים טעות מסוג שני. אנחנו בעצם תחת ההשערה האלטרנטיבית אבל בקצה השמאלי שלה תחת השטח המסומן בבטא. ואם צדקנו, זה מצוין, אנחנו בשטח עוצמת המבחן.

מהגרף הזה קל יותר לראות מה יגדיל את עוצמת המבחן:
אם ההתפלגויות היו רחוקות יותר זו מזו, כלומר גודל אפקט גדול ככל הניתן.
אם ההתפלגויות היו רזות יותר, כלומר עם סטיית תקן קטנה ככל האפשר.
ואם אלפא היתה גדולה ככל הניתן, כלומר להקטין את הערך הקריטי ובכך להגדיל את הסיכוי לטעות מסדר ראשון.
:::
:::

---

### What affects Power?

From our final calculation:

$1 - P \left(\frac{\overline{X} - \overline{Y} - (\mu_x - \mu_y)}{\sqrt{\frac{S_p^2}{n_x} +\frac{S_p^2}{n_y}}} < t_{n_x+n_y-2;1-\alpha} - \frac{(\mu_x - \mu_y)}{\sqrt{\frac{S_p^2}{n_x} +\frac{S_p^2}{n_y}}} | \mu_x -\mu_y = 15 \right)$

::: {.incremental}
- True Difference $\mu_x - \mu_y = \delta$

- Standard deviation $\sigma$, as estimated by $S_p$ (usually combined with true difference to create a standardized effect size: $\frac{\mu_x - \mu_y}{\sigma}$). In our case: $15/S_p = 0.35$.

- Sample size $n_x, n_y$ (many times the go-to parameter for researchers to increase power)

- Type I Error $\alpha$ (usually untouched!)
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
אפשר לראות את זה גם חישובית מהנוסחה שהגענו אליה: יש כאן ביטוי, שאנחנו רוצים שההסתברות מעליו תהיה גדולה כמה שיותר, כלומר אנחנו רוצים שיהיה כמה שיותר קטן.

אני אשאיר לכם לראות את זה מתמטית ואסכם:

ככל שגודל האפקט גדול יותר כך גדלה העוצמה. במילים אחרות, ככל שהתופעה שאנחנו מודדים גדולה ברורה ומובחנת יותר, כך גדלה עוצמת המבחן.

ככל שסטיית התקן של התופעה קטנה או האומד לה קטן, כך גדלה עוצמת המבחן - וזה הגיוני ככל שאפשר להקטין את שונות התופעה בניסוי מתוכנן היטב כך יהיה קל יותר להבחין בהבדלים דקים יותר.

הדרך המקובלת ביותר להקטין את הפיזור זה באמצעות הגדלת גודל המדגם, זו הדרך הקלה ביותר של החוקר להגדיל את העוצמה אף על פי שהיא קשורה בקשר ישיר לתקציב הניסוי.

לבסוף כמו שאמרנו זה נכון שככל שנגדיל את אלפא, רמת המובהקות או הסיכוי לטעות מסוג ראשון כך תגדל העוצמה -- אבל זה נחשב למנהג פסול. את רוצה שהניסוי שלך יצליח בגלל מדע טוב, לא כי זה היה ניסוי שהיית מוכנה לטעות בו הרבה.
:::
:::

---

```{python}
effect_sizes = np.array([0.2, 0.5, 0.8])
sample_sizes = np.array(range(5, 500))
TTestIndPower().plot_power(dep_var = 'nobs', nobs = sample_sizes, effect_size = effect_sizes)
plt.show()
```

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
מקובל לעשות ניתוחי עוצמה לפני שעורכים את הניסוי כאמור. באמצעות המתודה plot_power ניתן לקבל עקומות עוצמה עבר ערכים שונים ולנסות להבין היכן אנחנו נמצאים. כאן למשל אני מבקש לדעת מה תהיה העוצמה עבור גדלי מדגם שונים וגודל אפקט שונה במונחים של סטיות תקן. אפשר לראות למשל שעבור גודל אפקט צנוע של חמישית סטיית תקן, אם אנחנו רוצים עוצמה של 80 אחוז לפחות, אנחנו צריכים גודל מדגם של 400 לפחות.
:::
:::

---

### Caution!

- Statistical significance is not scientific significance. The tiniest, uninteresting, effect size, can be "discovered" with a large enough sample size. 

- Example: Assume in our case study we have an overall difference of 0.5 in red value, instead of 15, so effect size is $0.5/S_p \approx 0.01$. 

```{python}
#| code-fold: true

effect_sizes = np.array([0.01])
sample_sizes = np.array(range(5, 200000))
fig, ax = plt.subplots(figsize=(4, 4))
TTestIndPower().plot_power(dep_var = 'nobs', nobs = sample_sizes,
    effect_size = effect_sizes, ax = ax)
plt.show()
```

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
לסיום, נזכיר שוב, שלמרות הכל מובהקות סטטיסטית היא לא מובהקות מדעית. זה שמאמר מדווח על מובהקות סטטיסטית לא פוטר אותנו מלקרוא אותו קריאה ביקורתית ולראות אם הממצא שהוא מתאר אכן מעניין מדעית.

בדוגמא עם הציורים, נניח שרמת האדום בציורים אימפרסיוניסטים היתה גדולה מרמת האדום של ציורים ריאליסטיים בחצי נקודה בלבד. כלומר גודל אפקט של 0.01 -- מאית סטיית תקן בלבד!

עדיין, אם נבצע ניתוח עוצמה, נראה שעבור מדגם גדול מספיק, אם n היה גדול למשל מ150 אלף, היינו מקבלים תוצאה מובהקת סטטיסטית בעוצמה של למעלה מ80 אחוז. הלקח הוא לא לרדוף רק אחרי מובהקות סטטיסטית, לתכנן ניסוי שהוא גם בעל ערך מדעי, ולדווח על גודל האפקט ורווח סמך לפרמטר, לא רק על הpvalue!
:::
:::
