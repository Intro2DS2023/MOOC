=== 1. איפה אנחנו בבדיקת השערות ===

ביחידה האחרונה התחלנו ללמוד על בדיקת השערות. ניסינו לתת אינטואיציה למושגים השונים באמצעות סימולציה של אוכלוסיה ומדגם, או כאשר התפלגות הסטטיסטי שלנו פשוטה וידועה.

ראינו שיש שתי גישות עיקריות לבדיקת השערות, או שאנחנו מחשבים את ערך הpvalue תחת השערת האפס, שמבטא עד כמה סביר תחת עולם ברירת המחדל המוכר, לקבל תוצאה קיצונית כמו שקיבלנו במדגם או יותר. ואם הpvalue היה קטן מאיזשהו ערך סף, דחינו את השערת האפס.

הדרך השניה היתה לבנות מראש איזור דחיה של סטטיסטי המדגם שבו אנחנו מתמקדים, באמצעות קיבוע הסף לסיכוי של טעות מסוג ראשון: הטעות שעושים כאשר השערת האפס נכונה ודוחים אותה. אם ניפול באיזור הדחיה, נדחה את השערת האפס, ואם לא - לא נדחה.

עצרנו בטבלה הזאת שמבטאת מה קיים בעולם ומה אנחנו מחליטים בסופו של דבר לעשות: או שהשערת האפס נכונה, או שהשערה אלטרנטיבית נכונה. או שנחליט לדחות את H0 או שנחליט לא לדחות אותה. נשים לב שוב לז'רגון, בפרדיגמה שלנו לרוב אין סימטריה בין שתי ההשערות, H0 היא ברירת מחדל, והשאלה היא אם יש מספיק עדות לצאת מברירת המחדל.

יכולנו לחשב את ההסתברויות האלה או במצבים פשוטים כמו סימולציה שבה כל האוכלוסיה נתונה לנו או הטלת מטבע שדי ברורה מהי ההתפלגות של התוצאה, היא היתה בינומית.

והגענו למסקנה אנחנו צריכים לדעת לחשב את כל האלמנטים האלה, בלי שאנחנו יודעים בדיוק את ההתפלגות שממנה נלקחו הנתונים.

:::

בואו נחזור לדוגמה שמלווה אותנו: אנחנו משערים שיש יותר אדום בציורים בסגנון אימפרסיוניסטי, כי התרשמנו שהם עליזים ומתארים סיטואציות יומיומיות כמו גידול ילדים, ונופים פסטורליים.
אם נסמן את תוחלת ההפרשים של צבע אדום בציורים אימפרסיוניסטיים פחות צבע אדום בציורים ריאליסטיים באות מיו, השערת האפס, ברירת המחדל, היא שאין הבדלים, מיו שווה אפס.
היה לנו תקציב דמיוני לקחת רק 60 ציורים, 30 ריאליסטיים ו-30 אימפרסיוניסטיים, לכל ציור נתנו רמת אדום ממוצעת וחישבנו את ההפרש בין הממוצעים -- יצא לנו שאכן לציורים אימפרסיוניסטים היתה רמת אדום גבוהה יותר ב15 נקודות.
בשלב הזה עשינו סימולציה של התפלגות הייחוס שלנו, של השערת האפס. כתבנו בפונקציה כיצד אנחנו דוגמים שני מדגמים אקראיים מתוך האוכלוסיה של 16 אלף ציורים, ומחשבים את הפרש הממוצעים של אדם בין שני המדגמים. ועל הפונקציה הזאת חזרנו 10000 פעמים ליצירת התפלגות האפס, התפלגות הייחוס.

:::

ראינו, שההבדל של 15 נקודות הפרש ממוצעים שאנחנו קיבלנו לא היה כל כך מרשים בהשוואה להתפלגות הייחוס המסומלצת, הסיכוי לקבל אותו או הפרש גדול יותר, הpvalue, היה בערך 7 אחוז, ולא דחינו את השערת האפס.

נשים לב שההתפלגות של הפרשי ממוצעים שסימלצנו, היא סימטרית באופן מחשיד ובצורת פעמון -- במילים אחרות היא נראית נורמלית.

אם יכולנו איכשהו לדעת שהתפלגות כזאת תיראה תמיד נורמלית בקירוב -- זה היה עוזר לנו מאוד, לחישוב כל ההסתברויות שראינו, איזור דחייה, ערך קריטי, עוצמת המבחן. למזלנו, מסתבר שהדבר אכן כך. ובזה אנחנו מתחילים את היחידה הזאת.

=== 2. ההתפלגות הנורמלית ===

אני מקווה שכולם זוכרים את תכונות ההתפלגות הנורמלית מלימודי ההסתברות שלהם. ההתפלגות הנורמלית היא מהותית לנושא בדיקת ההשערות ולכן אם אתם לא בטוחים שאתם מתמצאים בנושא הזה - מומלץ מאוד לחזור עליו. כאן נעשה רק רענון.

:::

ניזכר שבמשתנים בדידים ההתפלגות שדיברנו עליה היא של הסתברויות, ערכים בין 0 ל-1.

עבור משתנים רציפים אנחנו מדברים על פונקצית צפיפות, או probability density function.

לדוגמא, משתנה נורמלי עם תוחלת מיו ושונות סיגמא בריבוע, זוהי הנוסחה לפונקצית הצפיפות שלו, שמסומנת ב-f קטן.

מקרה פרטי של התפלגות נורמלית שמעניין אותנו הוא כאשר התוחלת מיו היא 0, והשונות היא 1, ואז מקבלים את ההתפלגות הנורמלית-סטנדרטית, N(0,1). אם תציבו בפונקצית הצפיפות אפס למיו ו-1 לסיגמה בריבוע תקבלו את הנוסחה הבאה. וכשנצייר את הצפיפות נקבל את עקומת הפעמון המוכרת:

:::

כאן אנחנו משתמשים במודול stats.norm של ספרית scipy ובמתודה pdf - probability density function שלו, כדי לצייר את פונקצית הצפיפות.

ניתן לראות שהיא בצורת פעמון, המרכז שלה הוא התוחלת, כאן 0, ויש לה אסימפטוטה בצד ימין ובצד שמאל אל אפס. כמו-כן נזכיר שפונקצית צפיפות היא תמיד ממשית, חיובית, והשטח בינה לבין ציר הX צריך להסתכם ב-1.

:::

ושוב נזהיר: מדובר בצפיפות, לא הסתברות! כדי לחלץ הסתברות לטווח ערכים מסוים מפונקצית הצפיפות צריך לחשב שטח תחתיה, מה שאומר מבחינתנו לעשות אינטגרציה. לדוגמא ההסתברות שX יהיה קטן או שווה לאיזשהו ערך A היא האינטגרל ממינוס אינסוף עד A של פונקצית הצפיפות.

האינטגרל הזה ידוע גם כפונקצית ההתפלגות המצטברת, cumulative distribution function או CDF בקיצור.

הוא מאוד מאוד חשוב לנו אבל אין לו פתרון סגור, רק מקורב. כשאנחנו מדברים על ההתפלגות הנורמלית הסטדנרטית מגדירים אותו פעמים רבות כפונקציה של הערך A ומסמנים באות פי. פי של A הוא שטח ההתפלגות הנורמלית סטנדרטית עד הנקודה A. בואו נראה את הפונקציה פי

:::

כדי לקבל את פי אני משתמש במתודה cdf של המודול stats.norm. אנחנו יכולים לראות שהיא מתחילה בערך במינוס 3 בערך אפס, כי הסיכוי לקבל ערך פחות ממינוס 3 הוא אפסי, והיא עולה מונוטונית עד אסימפטוטה 1 בערך A=3, כי הסיכוי לקבל ערכים קטנים או שווים ל3 כבר שואף ל1.

איך אנחנו מקבלים מכל משתנה נורמלי עם תוחלת מיו ושונות סיגמא בריבוע את ההתפלגות הנורמלית הסטנדרטית? על-ידי תקנון: אנחנו מחסרים מאיקס את התוחלת שלו ומחלקים בשורש השונות, היא סטיית התקן. ומשתנה נורמלי סטנדרטי שכזה נסמן פעמים רבות באות Z.

:::

בואו נדבר עוד קצת על התוחלת והשונות של ההתפלגות הנורמלית. שני הפרמטרים האלה מספיקים כדי להגדיר באופן חד משמעי את ההתפלגות, אפשר לראות את זה בנוסחת פונקצית הצפיפות.

יותר מזה, ראינו שעבור התפלגות נורמלית סטנדרטית הערכים יהיו כמעט כולם בין מינוס לפלוס שלוש, ואפשר להכליל את התופעה: בכל התפלגות נורמלית כמעט מאה אחוז מהערכים יהיו בין מינוס לפלוס 3 סטיות תקן מהתוחלת מיו, כ95 אחוז יהיו בין מינוס לפלוס 2 סטיות תקן מהתוחלת. וכ-68 אחוזים יהיו במרחק עד סטיית תקן אחת מהתוחלת.

:::

לדוגמא, באוכלוסית הפרשי הממוצעים שלנו, אם אנחנו טוענים שהיא מתנהגת כמו התפלגות נורמלית, אנחנו אמורים להיות מסוגלים להלביש עליה במרכאות התפלגות כזאת ולראות התאמה לא רעה.

נאמוד את התוחלת מיו עם ממוצע ההתפלגות, יוצא בערך אפס באופן לא מפתיע. נאמוד את סטיית התקן סיגמא עם סטיית התקן של ההתפלגות, יוצא בערך 10.

:::

וכשאנחנו מלבישים פונקצית צפיפות עם הערכים האלה על היסטוגרמה מנורמלת של האוכלוסיה שלנו, ההתאמה נראית טובה.

:::

אם ההתאמה טובה, ואפשר לקרב את התפלגות ההפרשים המסומלצת שלנו באמצעות התפלגות נורמלית, אפשר למשל להגיד אמירה כמו 95 אחוזים מהערכים יהיו במרחק שתי סטיות תקן מהתוחלת. לחשב ולראות שזה יוצא בערך מינוס עד פלוס 20, ולחזור אל הפרדיגמה של בדיקת השערות, להגיד שהתוצאה של הפרש 15 בין שני מדגמים אמיתיים שקיבלנו, היא בהחלט בתחום הזה של פלוס מינוס 20 ולכן היא לא נראית חריגה!

אז אנחנו מבינים למה היינו רוצים שהתפלגויות ייחוס כאלה יתנהגו נורמלית, זאת התפלגות שנוחה לנו מאוד. אבל עדיין לא אמרנו למה שזה יקרה. נראה שיש לנו משפט שאומר בדיוק את זה: משפט הגבול המרכזי.

=== 3. משפט הגבול המרכזי ===

משפט הגבול המרכזי, או הcentral limit theorem, טוען שעבור כל מדגם בגודל n תצפיות בלתי תלויות, שבא מהתפלגות עם תוחלת מיו ושונות סופית סיגמא בריבוע, אם n גודל המדגם גדול מספיק, ממוצע המדגם יתפלג בקירוב נורמלית, עם התוחלת המקורית מיו, ושונות קטנה פי n.

הרבה פעמים נשתמש בגירסה המתוקננת של המשפט, אם נחסר מממוצע המדגם את התוחלת ונחלק בסטיית התקן כלומר סיגמא חלקי שורש n, הכמות הזאת מתפלגת נורמלית סטנדרטית.

יש לנו שם לסטיית התקן של ממוצע המדגם, standard error או טעות התקן,
וכאמור לכמות המתוקננת הזאת אנחנו קוראים סטטיסטי Z.

אני לא יודע אם סטודנטים ששומעים לראשונה על משפט הגבול המרכזי מתרשמים ממנו כמו שראוי לו. התוצאה הזאת היא בעלת השלכות אדירות, כי תשימו לב שהמשפט נכון לכל התפלגות מקורית של X, תהא צורתה אשר תהא, ובלבד שהשונות שלה סופית.

הגירסא הראשונה של משפט הגבול המרכזי הוכחה כבר במאה ה18 על-ידי דה-מואבר, ואחר כך במאה ה19 על-ידי לפלאס. המילה מרכזי בשם המשפט הוכנסה שם במאה העשרים כשכבר הבינו כמה הוא מהותי לבדיקת השערות והתקדמות המדע.

:::

נראה את משפט הגבול המרכזי קודם על התפלגויות ידועות, למשל התפלגות ברנולי.

יש לנו מדגם בעל n תצפיות X1 עד Xn, שכל אחת תוצאה של ניסוי ברנולי שיכול להצליח כלומר לקבל את הערך 1 בהסתברות p, ונניח שהיא חצי.

לפי חוקי ההתפלגות התוחלת ידועה והיא p עצמו כלומר חצי, והשונות היא p(1-p) כלומר רבע.

אנחנו יודעים כבר, שסכום התצפיות הוא התפלגות אחרת מוכרת לנו, התפלגות בינומית עם n ניסויים וסיכוי להצלחה  חצי.

והנה, לפי משפט הגבול המרכזי, סכום התצפיות חלקי n שזה הממוצע, מתפלג בקירוב נורמלית עם תוחלת חצי, ושונות רבע חלקי n.

אם נכפול את התוצאה הזאת בn נקבל שסכום התצפיות מתפלג נורמלית עם תוחלת חצי n ושונות רבע n. בדקו שאתם מבינים מדוע.

אבל זה אומר, שמצאנו את מה שקרוי הקירוב לנורמלי של משתנה בינומי! משתנה בינומי עם סיכוי חצי, מתפלג נורמלית עם תוחלת חצי n ושונות רבע n, אם מספר הניסויים גדול מספיק!

:::

לאברהם דה-מואבר שגילה את התופעה הזאת במאה ה18 לא היה מחשב. לנו, יש פייתון ובאמצעות כמה שורות של קוד אפשר להדגים את התוצאה הזאת, גם אם אנחנו לא מוכיחים אותה באופן פורמלי.

כאן אנחנו דוגמים את התוצאה של משתנה בינומי עם n = 20 לדוגמא וסיכוי חצי, אנחנו עושים את זה עשרת אלפים פעמים ומציירים את ההיסטוגרמה של התוצאות לראות את ההתפלגות.

ההתפלגות נראית כמו התפלגות נורמלית, ואכן, אם נחשב לפי משפט הגבול המרכזי את התוחלת וסטיית התקן שלה ונצייר את התוצאה מעליה, נראה התאמה מרשימה

:::

נראה דוגמא נוספת, הפעם מהתפלגות רציפה ומאוד מאוד לא נורמלית - התפלגות אקספוננציאלית.

אם איקס מתפלג אקספוננציאלית עם פרמטר למדא חיובי זה אומר:
שאיקס יכול לקבל ערכים מאפס עד אינסוף,
יש לנו נוסחה לפונקצית הצפיפות שלו ואפילו נוסחה סגורה לפונקצית ההתפלגות המצטברת.
התוחלת שלו היא 1 חלקי למדא והשונות 1 חלקי למדא בריבוע.

לדוגמא, נהוג הרבה פעמים למדל זמן עד שיקרה אירוע מסוים כמשתנה אקספוננציאלי.  כאן הזמן בין שתי רכבות מתל אביב לחיפה מתפלג אקספוננציאלית. בממוצע אנחנו יודעים שאנחנו ממתינים כעשרים דקות בין שתי רכבות. לכן התוחלת היא שליש והפרמטר למדא של ההתפלגות הוא ההופכי של שליש, שלוש.

:::

וכך נראית פונקצית הצפיפות של התפלגות אקספוננציאלית עם פרמטר למדא שווה 3. נשים לב שאני מצייר אותה עם המתודה pdf של המודול stats.expon מספריית scipy. ונשים לב שהפרמטריזציה של המתודה הזאת מעט מבלבלת, כדי לקבל למדא 3 צריך להזין לתוכה דווקא את התוחלת, 1 חלקי למדא, או שליש.

לבסוף נשים לב שההתפלגות הזאת מאוד לא סימטרית, מאוד לא נורמלית!

:::

והנה לפנינו סימולציה שלוקחת עוד ועוד מדגמים בגדול n = 30 מהתפלגות אקספוננציאלית עם למדא שווה 3, ומציירת את התפלגות ממוצעי המדגם.

תזכרו שההתפלגות המקורית האקספוננציאלית היא לא נורמלית בכלל. אבל התפלגות הממוצעים כן! היא נורמלית סביב התוחלת המקורית שליש.

:::

כאן אנחנו רואים סימולציה זהה רק הפעם גודל המדגם הוא n = 5. באופן מדהים, גם כאן היא די סימטרית, אבל לוקח לה הרבה יותר זמן או מדגמים כדי להיראות ממש נורמלית, ואם תבדקו תגלו שהפיזור שלה גדול יותר סביב התוחלת וזה הגיוני, הרי טעות התקן, היא סטיית התקן של הממוצע, היא סיגמא חלקי שורש n, וככל שn קטן יותר כך טעות התקן גדולה יותר. כאן n ממש קטן ונצפה לראות פיזור גדול.

נכון שמשפט הגבול המרכזי הוא תוצאה מרשימה? נראה כעת איך להשתמש בו בבדיקת השערות.

=== 4. מבחן Z ===

היישום המיידי של משפט הגבול המרכזי בבדיקת השערות הוא מבחן Z.

:::

נחזור שוב לדוגמא של הזמן ביו שתי רכבות מתל-אביב לחיפה. האם הוא באמת בתוחלת 20 דקות? לאחרונה זה נראה לי יותר. כלומר יש כאן מצב של בדיקת השערות (לכתוב): השערת האפס, ברירת המחדל, מה שמספרים לנו, היא תוחלת של 20 דקות. וההשערה האלטרנטיבית היא חד צדדית, יותר מ20 דקות.

אני דוגם בצורה אקראית 30 זמני המתנה, מחשב ממוצע ומקבל: ארבע תשיעיות השעה, או 26 דקות ו-40 שניות. נשים לב שזה די גבוה, הרי אמרו לנו 20 דקות, ואנחנו הגענו ל26 דקות בממוצע! אבל אולי זה קרה במקרה? זה בדיוק מה שאנחנו מנסים להעריך, אבל בשביל להעריך את זה אנחנו צריכים לדעת איך מתפלג ממוצע המדגם?

לפי משפט הגבול המרכזי ממוצע המדגם מתקרב בקירוב נורמלית תחת השערת האפס עם התוחלת המקורית של ההתפלגות האקספוננציאלית שליש, ושונות קטנה פי 30 מהשונות המקורית, או תשיעית חלקי 30.

או בצורה המתוקננת, אני מחסר מהממוצע שליש ומחלק בטעות התקן, והכמות הזאת כבר מתפלגת בקירוב נורמלי סטנדרטי.

כעת אני מציב ממוצע 4 תשיעיות, ומקבל ערך Z של 1.825.

זה ערך של התפלגות נורמלית סטנדרטית ואין לי שום בעיה לחשב לו pvalue. הpvalue יהיה הסיכוי לקבל ערך קיצוני כמו 1.82 או יותר (להדגים) תחת ההתפלגות הנורמלית הסטנדרטית. 

לכל התהליך הזה, קוראים מבחן Z, ואפשר לעשות אותו אם השונות ידועה.

:::

בפייתון, אפשר להשתמש במתודה cdf שראינו שבעצם מחזירה את פי, האינטגרל שאנחנו רוצים. אבל בפייתון לא חייבים לתקנן את המשתנה. אפשר לשאול מה ההסתברות לקבל 4 תשיעיות או יותר במשתנה נורמלי סטנדרטי שזו התוחלת שלו וזו סטיית התקן. ואפשר לשאול מה הסיכוי לקבל את ערך הZ שקיבלנו, 1.82 או יותר, תחת ההתפלגות הנורמלית סטנדרטית.

בכל מקרה הכמות שאנחנו מחפשים, תחת השערת האפס, היא כ3 אחוז. זה הpvalue החד צדדי, והוא נראה קטן מאוד, בודאי קטן מרמת מובהקות אלפא של 5 אחוז, ואנחנו דוחים את השערת האפס, אכן ממוצע של 30 זמני המתנה שעומד על 26 דקות, זה עדות מספקת שזמני ההמתנה הם בתוחלת יותר מ20 דקות.

לפני שנמשיך, מה היה קורה אם זמן ההמתנה הממוצע שהיינו מקבלים היה 2 תשיעיות או בערך 13 דקות, כלומר פחות מ20 דקות? אפשר היה להמשיך כרגיל ולחשב pvalue. (להדגים) אבל אם תחשבו על זה, התוצאה הזאת היא בכלל לא בכיוון ההשערה האלטרנטיבית, של זמן המתנה יותר מ20 דקות. ברור שהpvalue יצא גדול מאוד ולא נדחה את השערת האפס ולכן אין טעם לחשב אותו במקרה כזה. שימו לב שאחרי כל העבודה הקשה של איסוף נתונים למדגם, התקבלה תוצאה שעוצרת את המחקר על הסף. אם הממוצע עצמו לא גדול מ20 דקות, אין סיבה להמשיך, ההשערה נדחית על הסף.

:::

בחזרה לציורים שלנו, הפעם בלי סימולציה של התפלגות האפס.

X יהיה רמת האדום בציורים אימפרסיוניסטיים. Y יהיה רמת האדום בציורים ריאליסטיים. אנחנו ממש לא מניחים שX או Y או שניהם הם בעלי התפלגות נורמלית - יותר מזה, אם תחזרו לשיעור הראשון תראו שכבר סרטטנו את ההתפלגות הזאת והיא ממש לא היתה נורמלית, אפילו לא סימטרית. אבל זה בסדר, כי יש לנו את משפט הגבול המרכזי.

תחת השערת האפס התוחלות של X ושל Y זהות לאיזשהו מיו, ואנחנו נניח שהשוניות גם זהות לאיזשהו סיגמא בריבוע.

גודל המדגם שלנו הוא 30 לשני המדגמים.

:::

כעת בלי סימולציה נטען לפי משפט הגבול המרכזי שממוצע כל אחד מהמדגמים מתפלג בקירוב נורמלית עם התוחלת הזאת מיו והשונות הזהה סיגמא בריבוע חלקי n.

אנחנו מעונינים בהתפלגות הסטטיסטי ממוצע X פחות ממוצע Y. לפי חוקי ההתפלגות הנורמלית סכום או הפרש שני משתנים נורמליים בלתי תלויים מתפלג גם הוא נורמלית עם סכום או הפרש התוחלות, וסכום השונויות. במקרה שלנו הפרש התוחלות תחת השערה האפס הוא מיו פחות מיו, אפס.

לכן תחת השערת האפס נסכם שהסטטיסטי שלנו פחות התוחלת שהיא 0 חלקי שורש של שני סיגמא בריבוע חלקי n מתפלג נורמלית סטנדרטית.

רק בעיה אחת קטנה: אנחנו לא יודעים מה זה סיגמא. שימו לב שאנחנו גם לא יודעים מהו מיו אבל תחת השערת האפס הוא נעלם בהפרש.

:::

אז נניח לעת עתה שאנחנו כן יודעים מהי סיגמא, ובמקרה שלנו אפשר פשוט לחשב אותה על סמך 16 אלף ציורים, זה יוצא 39.3. נציב את זה ונראה שתחת השערת האפס הפרש הממוצעים מתפלג נורמלית עם תוחלת אפס וסטיית תקן 10.15. או בצורה המתוקננת, הפרש הממוצעים חלקי 10.15 מתפלג נורמלית סטנדרטית.

הפרש הממוצעים שהתקבל הוא בערך 15 נקודות, מחולק ב10.15 זה אומר שסטטיסטי Z במבחן Z שלנו הוא קצת פחות מ1.5.

בפייתון אפשר או להשתמש בערך המקורי של 15 או בערך המתוקנן 1.48 כדי לקבל את הpvalue, ואנחנו מקבלים בערך 7 אחוזים pvalue. זה מאוד דומה לערך שקיבלנו בסימולציה, ובכל מקרה לא מספיק קטן ומרשים ולא נדחה את השערת האפס.

אבל זה לא סביר שנדע את סטיית התקן של ההתפלגות המקורית, נכון? במקרה כזה אנחנו עושים התאמות ובמקום מבחן Z מקבלים את מבחן T.

=== 5. מבחן T ===

אז מה עושים כשההתפלגות המקורית והשונות שלה לא באמת ידועות?

במקרה הזה נהוג להחליף את סיגמא בריבוע בנוסחאות שלנו באמצעות האומד לשונות שהתקבל מהמדגם שמסומן בS בריבוע. והוא סכום המרחקים הריבועיים של X מממוצע המדגם חלקי n פחות 1. למה n פחות 1? מי שירצה ללמוד על הדברים האלה לעומק יוכיח שבמקרה כזה האומד שלנו לסיגמא ריבוע הוא אומד חסר הטיה, כלומר התוחלת של הסטטיסטי הזה שווה לסיגמא בריבוע.

אבל, כשאנחנו מחליפים את סיגמא בסטטיסטי Z שלנו באמצעות S, הוא כבר לא מתפלג נורמלית סטנדרטית, אלא הוא מתפלג T, עם פרמטר שנקרא דרגות חופש והוא n פחות 1. מי שירצה להרחיב בקורס מתקדם יראה שלהתפלגות הזאת גם יש פונקצית צפיפות מעניינת, אנחנו פשוט קוראים לה student's T או T בקיצור על שום החוקר שניסח אותה לראשונה william Gosset.

:::

לפונקצית הצפיפות של T עם n - 1 דרגות חופש יש צורה שמזכירה מאוד את ההתפלגות הנורמלית, היא פשוט רחבה יותר, או הזנבות שלה עבים יותר. אפשר לראות את זה כתוצאה של עוד אי-ודאות שנכנסה לתהליך ההסתברותי, הרי אנחנו אומדים כעת את סטיית התקן S והיא לא נתונה לנו כמקודם.

כאן, אני מצייר את ההתפלגות T עם 5 דרגות חופש בכחול, ולידה את ההתפלגות T עם 120 דרגות חופש בירוק. אני מצייר גם את ההתפלגות הנורמלית הסטנדרטית באדום אבל היא ממש בלתי מובחנת מההתפלגות T עם 120 דרגות חופש בירוק. הסיבה היא שככל שגודל המדגם או דרגות החופש גדלות, כך ההתפלגות T נעשית רזה ורזה יותר ושואפת להתפלגות הנורמלית סטנדרטית. כך שעבור מדגמים גדולים מספיק זה כבר לא משנה כל כך אם משתמשים במבחן Z עם הנחה שסטיית התקן ידועה או משתמשים במבחן T עם אומד לסטיית התקן.

:::

אז מהו מבחן T?

הסטטיסטי T מתקבל כאשר מחסרים מהממוצע את התוחלת תחת השערת האפס, ומחלקים בטעות התקן הנאמדת שורש של,S בריבוע חלקי N. תחת השערת האפס הסטטיסטי T מתפלג T עם n - 1 דרגות חופש, ואם רוצים לקבל אותו ואת הp-value שמקושר אליו אפשר להשתמש במתודה ttest_1samp מספריית statsmodels.

לדוגמא אם תחת השערת האפס התוחלת היא אפס, והמדגם שלנו נמצא באוביקט x, כך נבצע מבחן t לראות אם התוחלת שונה מאפס.

:::

אם יש לנו שני מדגמים, המבחן הראוי הוא מבחן T למדגמים בלתי תלויים. יש לנו מדגם X או רמת האדום בציורים אימפרסיוניסטיים בגודל n_x, ומדגם Y בגודל n_y, במקרה שלנו שני הn-ים זהים והם 30 אבל זה לא חייב להיות כך.
השערת האפס היא שתוחלת איקס שווה לתוחלת וואי. נניח גם שוויון שונויות, סיגמא בריבוע של X שווה לסיגמא בריבוע של Y.

תחת הנחת שוויון שונויות, הסטטיסטי שלנו המתוקנן הוא הפרש הממוצעים, פחות הפרש התוחלות, חלקי טעות התקן שמקבלת כאן צורה שכזאת. זה היה מתפלג בקירוב נורמלית סטנדרטית תחת משפט הגבול המרכזי.

אבל אנחנו לא יודעים מהי השונות המשותפת ומחליפים אותה באומד שנקרא S pooled, שהוא בעצם ממוצע משוקלל של האומד לשונות של מדגם X ושל מדגם Y.

הסטטיסטי הסופי שלנו הוא הפרש הממוצעים פחות הפרש התוחלות תחת השערת האפס, מחולק באומד לטעות התקן. הדבר הזה תחת השערת האפס מתפלג T עם n_x + n_y -2 דרגות חופש. נשים לב שהרבה פעמים השערת האפס היא שמיו איקס שווה למיו וואי, ולכן בפועל הפרש התוחלות יהיה אפס, וזה יפשט קצת את המונה.

:::

מה קורה אם אנחנו לא מניחים שוויון שונויות?

אם אנחנו לא מניחים שוויון שונויות אז האומד לטעות התקן שלנו משתנה מעט, אנחנו כבר לא מחשבים את s-pooled. ואז מקובל לבצע תיקון בחישוב דרגות החופש שמסומנות כאן כdf, degrees of freedom. יש נוסחה לא מאוד סימפטית לזה, לא תצטרכו בקורס שלנו לחשב אותה ידנית כי בכל מקרה נחשב בפייתון.

:::

בחזרה לציורים שלנו: השערת האפס שלנו היא אכן שהתוחלות של רמת האדום בציורים אימפרסיוניסטיים וריאליסטיים הן זהות או במילים אחרות הפרש התוחלות הוא אפס. הנה עשר התצפיות הראשונות מכל מדגם:

בצורה ידנית, כדי לראות שהנוסחאות עובדות, ניתן לחשב את סטטיסטי טי: הפרש הממוצעים, חלקי האומד לטעות התקן בדיוק כפי שכתבנו. הסטטיסטי יוצא בערך 1.38, ובאמצעות המתודה cdf במודול stats.t, אנחנו מחשבים את הp-value  החד-צדדי, כלומר הסיכוי לקבל בהתפלגות T עם 58 דרגות חופש 1.38 או יותר --

וזה יוצא כשמונה וחצי אחוזים.

:::

את כל החישוב המסורבל הזה אפשר לבצע בשורה אחת עם הפונקציה ttest_ind גם היא מהמודול stats של ספריית scipy.

אבל כדי לבצע מבחן חד-צדדי צריך לפרט alternative = 'greater'. בכל מקרה קיבלנו בדיוק את התוצאה של המבחן הידני.

וpvalue של 8.5 אחוזים הוא לא מרשים במיוחד ואנחנו לא דוחים את השערת האפס.

נשים לב שהpvalue שקיבלנו של 8.5 אחוזים גדול יותר מהpvalue של המבחן Z המדויק שיצא כ7 אחוזים. זה לא במקרה. ויתרנו על הנחת השונות הידועה, זה בא לידי ביטוי בתיאוריה שלנו שהובילה אותנו להתפלגות t שיש לה זנבות עבים יותר, כלומר הסיכוי לקבל בה תוצאות קיצוניות יותר גדול יותר. מה שאומר שכדי לדחות השערות בהתפלגות T צריך תוצאות קיצוניות יותר.

=== 6. רווח סמך ===

בחלק זה נדבר על רווחי סמך. אחת הבעיות עם חישובי pvalue או איזורי דחייה, היא שעדיין בסופו של דבר מדובר במבחן החלטה בינארי שאיננו אינפורמטיבי. אם מגדילים את מרחב המדגם, גם אפקטים קטנים מאוד יכולים להיות "מובהקים סטטיסטית" - תראו לזה דוגמאות בהמשך ובתרגול. וזה שאפקט הוא מובהק סטטיסטית, לא אומר שהוא אכן מעניין מדעית, מה שמביא הרבה פעמים מדענים לעשות רדוקציה למחקר המדעי שלהם, למעבר של הערך הזה, ותו לא.

אולי עדיף לתאר איזשהו אומד לפרמטר עליו מתבצע המבחן. זה יכולה להיות תוחלת של משתנה או הפרש התוחלות כמו במקרה של הציורים שלנו. ולא דיווח רק על הpvalue והאם הוא קטן יותר מרמת המובהקות אלפא או לא.

הבעיה היא שממוצע המדגם או הפרש ממוצעי המדגם הם אומד נקודתי שהוא בסבירות גבוהה לא נכון!, ולכן היינו רוצים לדווח טווח, שנקרא רווח סמך:

האמירה תהיה התוחלת מיו נמצאת בטווח ממוצע המדגם פלוס-מינוס איזשהו אפסילון, ברמת ביטחון של 95% או 90%. איך אנחנו מוצאים טווח כזה?

:::

לדוגמא במבחן Z, נרצה ערכים lower bound ו-upper bound, שמבוססים על המדגם X, שאנחנו נטען שבהסתברות 1 מינוס אלפא, מכסים איזשהו פרמטר אמיתי תטא אותו אנחנו מנסים להעריך. טווח כזה ייקרא רווח סמך ברמת ביטחון 100 כפול 1 מינוס אלפא אחוז.

בדרך כלל אלפא יהיה 0.05 או 0.1, ורווח הסמך שלנו יהיה סימטרי סביב איזשהו אומד X האט לתטא שמבוסס על המדגם, למשל ממוצע המדגם.

עבור מבחן Z, אנחנו יודעים ממשפט הגבול המרכזי שהממוצע המתוקנן נמצא בין האחוזון ה-2.5 לבין האחוזון ה97.5 בהסתברות 0.95. אחרי קצת משחק אלגברי והעברת אגפים תקבלו שני ערכים lower ו-upper bounds, שעונים בדיוק על ההגדרה המבוקשת: הם מכסים את הפרמטר מיו בהסתברות 0.95.

וזה אומר שהם מהווים רווח סמך ברמת בטחון 0.95 עבור התוחלת מיו. מאחר שהאחוזונים של ההתפלגות הנורמלית סטנדרטית הם סימטריים, הקטן הוא מינוס 1.96 והגדול הוא פלוס 1.96, וכך אנו מגיעים לרווח סמך שציפינו להגיע אליו לפרמטר התוחלת: ממוצע המדגם פלוס מינוס איזשהו אפסילון.

:::

בדוגמת זמני ההמתנה של הרכבת, תחת השערת האפס זמן ההמתנה מתפלג אקספוננציאלית עם איזשהו פרמטר למדא, והממוצע מתפלג נורמלית בקירוב ממשפט הגבול המרכזי. נניח גם שסטיית התקן נשארת כפי שהיא והיא ידועה, שליש. ממוצע המדגם שהתקבל הוא ארבע תשיעיות, גודל המדגם היה 30, מציבים בנוסחת רווח הסמך, ומקבלים שתוחלת זמן ההמתנה בין 0.32 שעה, לבין 0.56, שזה אומר בערך בין 19.5 דקות לבין כמעט 34 דקות.

חדי העין ביניכם ודאי שמים לב שתוחלת הזמן מהשערת האפס -- 20 דקות -- נמצאת ברווח הסמך הזה, כלומר בסיכוי 0.95 אנחנו לא פוסלים את האפשרות הזאת. אבל אם אתם זוכרים דחינו את השערת האפס כשביצענו בדיקת השערות לנתונים האלה במבחן Z. אבל, אנחנו ביצענו בדיקת השערות חד-צדדית, כלומר שיערנו מראש שזמני ההמתנה ארוכים יותר. ואם היינו מבצעים בדיקת השערות דו-צדדית, שזמן ההמתנה פשוט השתנה, אכן לא היינו דוחים את השערת האפס, גם בגישת הpvalue. יש קשר הדוק בין בדיקת השערות דו-צדדית לבין הימצאות או אי-הימצאות הפרמטר מהשערת האפס ברווח הסמך. תדברו על זה עוד בתרגול.

בינתיים נסכים שאמירה כמו זמן ההמתנה הממוצע הוא בין 19.5 ל34 דקות ברמת ביטחון 95 אחוז היא אמירה מעניינת יותר מדחינו או לא דחינו את השערת האפס.

:::

טעות נפוצה שעושים כולם בתחום, מסטודנטים ועד מדענים היא להגיד: ההסתברות שמיו נמצא בין 0.33 ל-0.56 היא 95 אחוז.

מבחינה הסתברותית זו אמירה בעייתית ביותר וחשוב לי שתימנעו ממנה. מיו, התוחלת, היא פרמטר. היא או נמצאת ברווח הסמך או שלא. היא לא משתנה מקרי! זה כמו להגיד 2 נמצא בהסתברות 0.95 בין 3 ל-4 -- הוא או נמצא שם או לא.

אז למה כן אנחנו מתכוונים כשאנחנו אומרים "רווח סמך ברמת ביטחון 95%"? אנחנו אומרים שאם היינו עורכים הרבה מדגמים בצורה דומה, ב95% מהם הרווח סמך שאנחנו בונים עם הערך העליון והתחתון שלו, היה מכסה את הפרמטר האמיתי מיו. כך שהאמירה ההסתברות היא על גבולות רווח הסמך, הם (!) המשתנים המקריים, לא הפרמטר.

נדגים: לפנינו הרבה הרבה ניסויים חוזרים של המדגם שלנו, לקחת 30 תצפיות מהתפלגות אקספוננציאלית עם פרמטר למדא שווה 3, ולבנות מממוצע המדגם רווח סמך לתוחלת, שאנחנו יודעים שהיא שליש, כי ככה הגרלנו את הנתונים. אפשר לראות, שלמרות שהנתונים מגיעים מהתפלגות ידועה רווח הסמך מכסה את התוחלת רק ב95% מהמקרים בקירוב. ולזה אנחנו מתכוונים כשאנחנו מדברים על רמת סמך או רמת ביטחון.

:::

עבור מבחן T למדגם בודד יש לנו נוסחה לרווח הסמך לתוחלת מיו. אפשר לראות שעדיין הצורה היא ממוצע המדגם פלוס מינוס איזשהו אפסילון רק שהפעם סטיית התקן לא ידועה והיא נאמדת באמצעות S, והאחוזונים מגיעים מהתפלגות T עם n - 1 דרגות חופש ולא Z.

אותו דבר למבחן T למדגמים בלתי תלויים, ואנחנו רוצים לבנות רווח סמך להפרש התוחלות. עדיין יש לנו איזשהו סטטיסטי כאן הפרש הממוצעים פלוס מינוס איזשהו טווח.

:::

במקרה של הציורים שלנו נותר רק להציב בנוסחה כדי לתת רווח סמך להפרש רמת האדום בין הסגנון האימפרסיוניסטי לריאליסטי.

ניזכר שהפרש ממוצעי המדגמים היה 15 נקודות, גודל שני המדגמים היה 30 (והם לא חייבים להיות זהים!), וגם חישבנו כבר את S-pooled ויצא 1824. לכן רווח סמך להפרש התוחלות אימפרסיוניסטי פחות ריאליסטי יהיה בין -6.8 לבין 37.4.

ושוב נשים לב רווח הסמך כולל את האפשרות 0 בתוכו, האפשרות שמשמעותה היא שאין הבדל ברמת האדום בין שני הסגנונות ציור, ואפשר להגיד שמכאן לא היינו דוחים השערת אפס דו-צדדית שהתוחלות שוות ברמת מובהקות אלפא 5 אחוז. אבל האמירה הכרוכה ברווח סמך, מדעית, היא מעניינת יותר.

=== 7. עוצמת המבחן ===

הנושא האחרון שנעסוק בו בבדיקת השערות הוא עוצמת המבחן. הבנה של העוצמה הסטטיסטית של מבחן מדעי היא אקוטית לכל חוקרת שרוצה לבצע ניסויים, ורצוי לדעת מהי עוצמת המבחן של הניסוי שאת מבצעת לפני שאת מבצעת אותו, ולא כשהוא עובדה מוגמרת! הרבה פעמים מדענים מערבים אינטואיציה לא נכונה בחישוב עוצמת המבחן, לא מבצעים חישובים מדויקים, ומסתבר להם רק בדיעבד שהשקיעו הרבה זמן ומשאבים במבחן בעל עוצמה נמוכה.

:::

ניזכר מהי עוצמת המבחן באמצעות הדוגמא של הציורים. זכרו שכאן כל האוכלוסיה היא בעצם בכף ידנו, ושורה אחת של קוד בפייתון תגלה לנו מהו באמת ההבדל ברמת האדום בין ציורים אימפרסיוניסטים לריאליסטיים. אני לוקח כאן את רמת האדום של כל הציורים האימפרסיוניסטיים פחות רמת האדום של כל הציורים הריאליסטיים, וראו זה פלא:
יש אכן הבדל, של קצת יותר מ15 נקודות, בין רמת האדום של שני הסגנונות. זאת האמת.

נניח לרגע שזה הבדל מעניין מבחינה מדעית, למראות שבסקאלת אדום של 0 עד 255 -- לא כל כך בטוח.

זה אומר שהשערת האפס שלנו, אותה לא דחינו, היתה שגויה, וביצענו טעות מסוג ראשון.

למה טעינו? ואם היינו עורכים את הניסוי שוב - האם סביר שהיינו טועים שוב?

התשובה נעוצה בעוצמת המבחן: ההסתברות לדחות את השערת האפס כשזו באמת לא נכונה. כאן, תיכף נראה, ההסתברות הזאת -- עוצמת המבחן -- היתה קטנה. ואם היינו אומדים אותה מראש אולי יכולנו לתכנן ניסוי טוב יותר.

:::

אז עוצמת המבחן שמסומנת כאן בפאי, היא ההסתברות לדחות את H0 כשהיא באמת לא נכונה, כלומר תחת H1, המצב האלטרנטיבי.

במקרה שלנו אפשר קודם לראות את זה עם סימולציה: הרעיון הוא לבצע את הניסוי שכולל לקיחת שני מדגמים בגודל של התקציב שלנו, שוב ושוב, לבצע כל פעם מבחן T למדגמים בלתי תלויים, ולראות באיזה אחוז מהפעמים נדחה בצדק את השערת האפס:

כאן אנחנו מדגימים פונקציה שעושה דגימה ומבצעת מבחן T חד-צדדי כמו שעשינו ומחזירה האם יש דחייה או לא, ערך בינארי, בבת אחת. ואנחנו עושים את זה עשרת אלפים פעמים. ומחשבים כמה פעמים מתוך 10000 דחינו בצדק את השערת האפס.

אנחנו מקבלים סיכוי של 45 אחוז!

עוצמה של 45 אחוז פירושה שבערך באחד מכל שני מבחנים לא נדחה את H0 כשהמציאות היא H1, שצריך לדחות את H0. אם היינו יודעים שזאת עוצמת המבחן שלנו סביר להניח שהיינו רוצים לשנות את הניסוי כדי להגדיל אותה.

:::

בפועל אין לנו את כל האוכלוסיה, אנחנו לא יכולים לחזור על הניסוי 10000 פעמים, והכי מאתגר זה שאנחנו לא באמת יודעים את הפרש התוחלות באוכלוסיה גם אם נניח שהוא חיובי.

גישה נפוצה במקרה כזה היא לחשב את עוצמת המבחן לפי פרמטר שנקרא גודל אפקט. ולנסות להתחשב בכמה גדלי אפקט כאלה. גודל האפקט הוא הפרש התוחלות: התוחלת תחת ההשערה האלטרנטיבית פחות התוחלת תחת השערת האפס, כשמקובל לעשות לו סטנדרטיזציה, לחלק אותו בסטיית התקן או אומדן לסטיית התקן, כך שהפער בין ההשערה האלטרנטיבית להשערת האפס נמדד במונחי סטיית תקן, לדוגמא "חצי סטיית תקן".

כאן נניח למשל שהפרש התוחלות הוא 15 נקודות תחת ההשערה האלטרנטיבית ואפס תחת השערת האפס, ולכן גודל האפקט בלי תקנון הוא 15, ונשאל מה הסיכוי לדחות את H0 תחת האפקט הזה, כלומר לקבל pvalue קטן מאלפא רמת המובהקות כשהפרש התוחלות הוא 15.

:::

אפשר להגיע לנוסחה סופית במקרה של מבחן T למדגמים בלתי תלויים עם קצת מאמץ, ורשמתי כאן את הפיתוח למי שרוצה להתעמק. נשים לב שההסתברות מתחילה בדיוק בכלל של מבחן T למדגמים בלתי תלויים: האם הסטטיסטי של הפרש ממוצעי המדגמים, מחולק באומד לטעות התקן, גדול מהערך T הקריטי של מבחן T, אם הפרש התוחלות האמיתי הוא 15 נקודות.

בסופו של דבר זה למצוא הסתברות תחת התפלגות T עם כך וכך דרגות חופש, שהססטיסטי שלנו קטן מאיזשהו ביטוי שמסומן כאן.

מציבים את הביטוי בפייתון ומקבלים שהעוצמה היא 0.38, דומה למה שקיבלנו, כלומר רק בכ40 אחוז מהניסויים, תחת האפקט הזה של 15 נקודות, היינו דוחים בצדק את השערת האפס, במבחן T למדגמים בלתי תלויים, ברמת מובהקות 5 אחוז.

:::

ברור שיש לנו פונקציה שעושה את זה, יש לנו קלאס מספריית statsmodels שנקרא TTestIndPower, שאפשר להזין לתוכו את הנתונים שיש לנו ולבקש את הנתון החסר. במקרה הזה אנחנו יודעים שגודל האפקט הוא 15 נקודות, מחולק באומד לסטיית התקן, רשמתי אותו כאן וזה יוצא 0.35, מספר התצפיות בשתי הקבוצות הוא 30, האלפא המבוקשת היא 0.05 וההשערה שלנו היא חד-צדדית. הערך החסר הוא העוצמה, ונקבל כמו בחישוב הידני 0.38.

:::

איך אפשר להגדיל את עוצמת המבחן?

ניזכר בטבלה שמסכמת את הקשר בין ההסתברויות, וכעת כשאנחנו יודעים שההתפלגויות עצמן ניתן לצייר כהתפלגויות נורמלית, אפשר לייצג את הטבלה הזאת בעצם באמצעות גרף.

תחת השערת האפס הפרש התוחלות הוא אפס. תחת ההשערה האלטרנטיבית הערך הזה חיובי, איזשהו דלתא. אם נעבור בהפרש ממוצעי המדגם איזשהו ערך סף קריטי C נדחה את השערת האפס ונגיד שאנחנו בעצם באיזור ההשערה האלטרנטיבית שמימין. אם אנחנו טועים, הרי שביצענו טעות מסוג ראשון, אנחנו עדיין תחת השערת האפס אבל אנחנו בשטח האלפא שהוא בדרך כלל 1 או 5 אחוזים.
אם לא עברנו את הערך הקריטי, לא נדחה את השערת האפס. אם אנחנו טועים, אנחנו עושים טעות מסוג שני. אנחנו בעצם תחת ההשערה האלטרנטיבית אבל בקצה השמאלי שלה תחת השטח המסומן בבטא. ואם צדקנו, זה מצוין, אנחנו בשטח עוצמת המבחן.

מהגרף הזה קל יותר לראות מה יגדיל את עוצמת המבחן:
אם ההתפלגויות היו רחוקות יותר זו מזו, כלומר גודל אפקט גדול ככל הניתן.
אם ההתפלגויות היו רזות יותר, כלומר עם סטיית תקן קטנה ככל האפשר.
ואם אלפא היתה גדולה ככל הניתן, כלומר להקטין את הערך הקריטי ובכך להגדיל את הסיכוי לטעות מסדר ראשון.

:::

אפשר לראות את זה גם חישובית מהנוסחה שהגענו אליה: יש כאן ביטוי, שאנחנו רוצים שההסתברות מעליו תהיה גדולה כמה שיותר, כלומר אנחנו רוצים שיהיה כמה שיותר קטן.

אני אשאיר לכם לראות את זה מתמטית ואסכם:

ככל שגודל האפקט גדול יותר כך גדלה העוצמה. במילים אחרות, ככל שהתופעה שאנחנו מודדים גדולה ברורה ומובחנת יותר, כך גדלה עוצמת המבחן.

ככל שסטיית התקן של התופעה קטנה או האומד לה קטן, כך גדלה עוצמת המבחן - וזה הגיוני, ככל שאפשר להקטין את שונות התופעה בניסוי מתוכנן היטב כך יהיה קל יותר להבחין בהבדלים דקים יותר.

הדרך המקובלת ביותר להקטין את הפיזור זה באמצעות הגדלת גודל המדגם, זו הדרך הקלה ביותר של החוקר להגדיל את העוצמה אף על פי שהיא קשורה בקשר ישיר לתקציב הניסוי.

לבסוף כמו שאמרנו זה נכון שככל שנגדיל את אלפא, רמת המובהקות או הסיכוי לטעות מסוג ראשון כך תגדל העוצמה -- אבל זה נחשב למנהג פסול. את רוצה שהניסוי שלך יצליח בגלל מדע טוב, לא כי זה היה ניסוי שהיית מוכנה לטעות בו הרבה.

:::

מקובל לעשות ניתוחי עוצמה לפני שעורכים את הניסוי כאמור. באמצעות המתודה plot_power ניתן לקבל עקומות עוצמה עבר ערכים שונים ולנסות להבין היכן אנחנו נמצאים. כאן למשל אני מבקש לדעת מה תהיה העוצמה עבור גדלי מדגם שונים וגודל אפקט שונה במונחים של סטיות תקן. אפשר לראות למשל שעבור גודל אפקט צנוע של חמישית סטיית תקן, אם אנחנו רוצים עוצמה של 80 אחוז לפחות, אנחנו צריכים גודל מדגם של 400 לפחות.

:::

לסיום, נזכיר שוב, שלמרות הכל מובהקות סטטיסטית היא לא מובהקות מדעית. זה שמאמר מדווח על מובהקות סטטיסטית לא פוטר אותנו מלקרוא אותו קריאה ביקורתית ולראות אם הממצא שהוא מתאר אכן מעניין מדעית.

בדוגמא עם הציורים, נניח שרמת האדום בציורים אימפרסיוניסטים היתה גדולה מרמת האדום של ציורים ריאליסטיים בחצי נקודה בלבד. כלומר גודל אפקט של 0.01 -- מאית סטיית תקן בלבד!

עדיין, אם נבצע ניתוח עוצמה, נראה שעבור מדגם גדול מספיק, אם n היה גדול למשל מ150 אלף, היינו מקבלים תוצאה מובהקת סטטיסטית בעוצמה של למעלה מ80 אחוז. הלקח הוא לא לרדוף רק אחרי מובהקות סטטיסטית, לתכנן ניסוי שהוא גם בעל ערך מדעי, ולדווח על גודל האפקט ורווח סמך לפרמטר, לא רק על הpvalue!

עד כאן ביחידה השניה לבדיקת השערות. אני מקווה שקיבלתם כלים לא רק לניתוח ניסויים שכבר התבצעו אלא גם לתכנון ניסויים טובים יותר על סמך הבנה של הפרדיגמה. בשיעור הבא אנחנו עוברים לתחום אחר אם כי הידע שצברנו ישמש אותנו גם שם: בניית מודלים לחיזוי.

:::
