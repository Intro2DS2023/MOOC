<!DOCTYPE html>
<html lang="en"><head>
<script src="../libs/clipboard/clipboard.min.js"></script>
<script src="../libs/quarto-html/tabby.min.js"></script>
<script src="../libs/quarto-html/popper.min.js"></script>
<script src="../libs/quarto-html/tippy.umd.min.js"></script>
<link href="../libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="../libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.3.433">

  <title>Linear and Logistic Regression</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
      }
    pre.numberSource { margin-left: 3em;  padding-left: 4px; }
    div.sourceCode
      { color: #24292e;  }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #24292e; } /* Normal */
    code span.al { color: #ff5555; font-weight: bold; } /* Alert */
    code span.an { color: #6a737d; } /* Annotation */
    code span.at { color: #d73a49; } /* Attribute */
    code span.bn { color: #005cc5; } /* BaseN */
    code span.bu { color: #d73a49; } /* BuiltIn */
    code span.cf { color: #d73a49; } /* ControlFlow */
    code span.ch { color: #032f62; } /* Char */
    code span.cn { color: #005cc5; } /* Constant */
    code span.co { color: #6a737d; } /* Comment */
    code span.cv { color: #6a737d; } /* CommentVar */
    code span.do { color: #6a737d; } /* Documentation */
    code span.dt { color: #d73a49; } /* DataType */
    code span.dv { color: #005cc5; } /* DecVal */
    code span.er { color: #ff5555; text-decoration: underline; } /* Error */
    code span.ex { color: #d73a49; font-weight: bold; } /* Extension */
    code span.fl { color: #005cc5; } /* Float */
    code span.fu { color: #6f42c1; } /* Function */
    code span.im { color: #032f62; } /* Import */
    code span.in { color: #6a737d; } /* Information */
    code span.kw { color: #d73a49; } /* Keyword */
    code span.op { color: #24292e; } /* Operator */
    code span.ot { color: #6f42c1; } /* Other */
    code span.pp { color: #d73a49; } /* Preprocessor */
    code span.re { color: #6a737d; } /* RegionMarker */
    code span.sc { color: #005cc5; } /* SpecialChar */
    code span.ss { color: #032f62; } /* SpecialString */
    code span.st { color: #032f62; } /* String */
    code span.va { color: #e36209; } /* Variable */
    code span.vs { color: #032f62; } /* VerbatimString */
    code span.wa { color: #ff5555; } /* Warning */
  </style>
  <link rel="stylesheet" href="../libs/revealjs/dist/theme/quarto.css">
  <link rel="stylesheet" href="../slides_quarto.css">
  <link href="../libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  
    <link rel="icon" href="../Intro2DS_logo.jpg" type="image/jpg"> 
    <link rel="shortcut icon" href="../Intro2DS_logo.jpg" type="image/jpg">
    <link href="https://fonts.googleapis.com/css?family=Lato:400,700" rel="stylesheet" type="text/css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script></head>
  
  
  

<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="section" class="slide level2 logo-slide">
    <h2></h2>
    </section>
<section id="introduction-to-data-science" class="slide level2 title-slide center">
<h2>Introduction to Data Science</h2>
<h3 id="linear-and-logistic-regression---class-9">Linear and Logistic Regression - Class 9</h3>
<h3 id="giora-simchoni">Giora Simchoni</h3>
<h4 id="gsimchonigmail.com-and-add-intro2ds-in-subject"><code>gsimchoni@gmail.com</code> and add <code>#intro2ds</code> in subject</h4>
<h3 id="stat.-and-or-department-tau">Stat. and OR Department, TAU</h3>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אנחנו מתחילים ביחידה היום בעצם את החלק השני של הקורס. אחרי שעסקנו בהבנת נתונים, אקספלורטורי דאטא אנליסיס ובדיקת השערות, אנחנו רוצים להשתמש בנתונים האלה, לבניית מודלים לחיזוי. נתחיל היום במודלים ליניאריים שיש מאחוריהם לא מעט הנחות, נמשיך למודלים של מאשין לרנינג מודרניים יותר שמאפשרים גם מידול של יחסים לא ליניאריים בכלל, ונגיע למודלים של רשתות נוירונים או למידה עמוקה, מהשנים האחרונות ממש.</p>
<p>חשוב לי להדגיש שוב שאנחנו מסתכלים על כל שיטה ושיטה בהיי לבל, על מנת לתת מבט רחב על התחום. ברור שמי שרוצה ממש לעסוק בתחום, אני ממליץ לו לקרוא עוד הרבה יותר ולקחת עוד קורסים בנושא.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="intro.-to-predictive-modeling" class="slide level2 title-slide center">
<h2>Intro. to Predictive Modeling</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נתחיל במבט על על מה אנחנו מנסים לעשות כאן - מה זה מודלים לחיזוי או predictive modeling?</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="predictive-modeling-and-supervised-learning">Predictive modeling and Supervised learning</h3>
<ul>
<li><p>Basic idea: each observation is made of a vector <span class="math inline">\(x \in \mathcal{X}\)</span> (for example <span class="math inline">\(x \in \mathbb{R}^p\)</span>) and a scalar <span class="math inline">\(y\)</span></p></li>
<li><p>Our goal is to build a model of the relationship between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>: <span class="math display">\[y \approx f(x)\]</span></p></li>
</ul>
<div class="fragment">
<ul>
<li><span class="math inline">\(x\)</span>: predictors, regressors, features, exogenous variables</li>
<li><span class="math inline">\(y\)</span>: response, dependent variable, endogenous variable</li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>הרעיון הבסיסי: יש לנו תצפית לחיזוי שנסמן אותה בX, וX הוא וקטור ממימד p, כלומר יש לנו p משתנים על התצפית שלנו. וY הוא סקלאר.</p>
<p>אנחנו מניחים שY הוא פונקציה של X והמטרה שלנו היא לבנות מודל שיעשה קירוב ליחס הזה.</p>
<p>נזכיר שמות שונות לX כדי שנראה שאנחנו מדברים על אותו דבר: X יכול להיות משתנים, מנבאים, פיצ’רים, משתנים אקסוגניים.</p>
<p>באופן דומה Y נקרא לפעמים משתנה התגובה, המשתנה התלוי, המשתנה האנדוגני – בקורס שלנו, זה בסדר שיהיו שמות שונים.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="predictive-modeling-and-supervised-learning-1">Predictive modeling and Supervised learning</h3>
<p>Two distinct goals for this:</p>
<ol type="1">
<li><p>Prediction: in the future we will get <span class="math inline">\(x\)</span> and have to <em>predict</em> <span class="math inline">\(\hat{y} = f(x)\)</span></p></li>
<li><p>Inference/understanding/model selection: Understanding the nature of the dependence between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>:</p>
<ul>
<li>Which variables in <span class="math inline">\(x\)</span> are important for explaining or predicting <span class="math inline">\(y\)</span>?</li>
<li>What type of dependence does <span class="math inline">\(y\)</span> have on <span class="math inline">\(x\)</span>: linear? more complex?</li>
</ul></li>
</ol>
<div class="fragment">
<ul>
<li><p>Regression: <span class="math inline">\(y \in \mathbb{R}\)</span> numeric</p></li>
<li><p>Classification: <span class="math inline">\(y \in \mathcal{G}\)</span> an unordered set</p></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אם נצליח לבנות מודל איכותי, זה ימלא שתי מטרות:</p>
<p>מטרת החיזוי, אם תגיע תצפית חדשה X נוכל לחזות לה את הY המתאים לה אף על פי שהמודל לא ראה אותה, נקרא לה y_hat.</p>
<p>ומטרת ההסקה או ההבנה: מודל טוב יאפשר לנו להבין את הקשר בין X לY. אילו משתנים בX הם חשובים כדי להסביר או לחזות את Y, ואופי התלות של Y בX, האם הקשר הוא ליניארי? האם הוא מורכב יותר?</p>
<p>אנחנו נדבר על שני סוגים מודלים לחיזוי על פי הY: כשY הוא כמותי, ממשי, כמו גובה של תינוק שעומד להיוולד, זה ייקרא רגרסיה.</p>
<p>כשY הוא קטגוריאלי, הוא קטגוריה מתוך איזושהי קבוצה G, ואנחנו רוצים לסווג X חדש לאיזו קטגוריה הוא שייך, נקרא לזה קלסיפיקציה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="wikiart-paintings-a-classification-problem">Wikiart paintings: a classification problem</h3>
<p><span class="math inline">\(x \in \mathbb{R}^{K \times K \times 3}\)</span>: the image itself</p>
<p><span class="math inline">\(y \in \{\text{impressionist}, \text{realist}\}\)</span></p>
<div>
<ul>
<li class="fragment"><p>More involved example: <a href="https://www.cs.toronto.edu/~kriz/cifar.html">Cifar-10</a> with 10 classes</p></li>
<li class="fragment"><p>A good model: <span class="math inline">\(f(x)\)</span> such that <span class="math inline">\(f(x) \approx 1\)</span> for impressionist and <span class="math inline">\(f(x)\approx 0\)</span> for realist</p></li>
<li class="fragment"><p>Possible <span class="math inline">\(f\)</span>: threshold the average red value for all pixels</p></li>
<li class="fragment"><p>Does not do a very good job in separating impressionist from realist paintings…</p></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בדוגמא של הציורים מאתר wikiart, הבעיה שלנו תהיה בעית קלסיפיקציה. X יהיה הפיקסלים של התמונה של הציור, וראינו שאם התמונה היא בגודל K על K יש K כפול K כפול 3 פיקסלים או משתנים. וY יהיה אחת משתי קטגוריות, ציור ריאליסטי או אימפרסיוניסטי.</p>
<p>דוגמא מורכבת יותר: סיפאר-טן, סט של 60 אלף תמונות עם 10 קלאסים שונים, כמו תמונות של מטוסים, מכוניות וציפורים.</p>
<p>מודל טוב במקרה של הציורים יינתן ערך קרוב ל-1 לציורים אימפרסיוניסטים למשל, וערך קרוב ל-0 לציורים ריאליסטיים.</p>
<p>למשל מודל שבודק מה הרמה הממוצעת של פיקסל אדום בתמונה ומסתכל על איזשהו סף, עד ערך מסוים יחזה 0 ומעליו יחזה 1.</p>
<p>סביר להניח שזה מודל לא טוב, הוא לא יפריד היטב בין ציורים אימפרסיוניסטים לציורים ריאליסטיים.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="netflix-movies-a-regression-problem-sort-of">Netflix movies: a regression problem (sort of)</h3>
<ul>
<li><p>Recall we had <span class="math inline">\(x \in \mathbb{R}^{99}\)</span> movies, plus one special (Miss Congeniality) that we will call <span class="math inline">\(y\)</span></p>
<ul>
<li>All <span class="math inline">\(x\)</span> values are not really in <span class="math inline">\(\mathbb{R}\)</span> but in <span class="math inline">\(\{0 = \text{None},1,2,3,4,5\}\)</span></li>
<li><span class="math inline">\(y\)</span> is in <span class="math inline">\(\{1,2,3,4,5\}\)</span> (no missing)</li>
</ul></li>
<li><p>A good model <span class="math inline">\(f(x)\)</span> sees the scores a user gave to the 99 movies (including which are missing) and gives a value that is close to <span class="math inline">\(y\)</span> for the same user</p></li>
</ul>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בעית רגרסיה אפשר לראות בדוגמא של נטפליקס: X הוא וקטור ממימד 99 סרטים, וY הסקלר הוא הציון של הסרט איזו מין שוטרת.</p>
<p>הערכים של X במקרה הזה לא באמת נמצאים על כל הישר הממשי, הם דירוגים במין סולם אורינלי כזה של 1 עד 5 וראינו שיש בהם גם ערכים חסרים.</p>
<p>גם Y הנתון לנו לא מקבל כל ערך, רק מספרים בין 1 ל5.</p>
<p>בכל זאת מודל טוב יקבל את הציונים הקיימים של משתמש קיים, כולל הסרטים שהוא לא ראה, ונותן חיזוי לדירוג של איזו מין שוטרת הכי קירוב לדירוג Y של אותו משתמש.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="some-more-examples-from-real-life">Some more examples from real life</h3>
<div class="fragment">
<!-- -->
<h4 id="genome-wide-association-studies-gwas-find-genetic-causes-of-disease">Genome-Wide Association Studies (GWAS): find genetic causes of disease</h4>
<ul>
<li><span class="math inline">\(y \in \{\text{sick}, \text{healthy}\}\)</span> for specific disease</li>
<li><span class="math inline">\(x \in \{0,1,2\}^{1M}\)</span> (<span class="math inline">\(p=10^6\)</span>) number of copies of “risk” variant in each location in the genome</li>
<li>The goal is to understand which coordinates in <span class="math inline">\(x\)</span> are related to <span class="math inline">\(y\)</span>, and predict risk of <span class="math inline">\(y\)</span> for new people</li>
</ul>
</div>
<div class="fragment">
<!-- -->
<h4 id="email-spam-detection">Email spam detection:</h4>
<ul>
<li><span class="math inline">\(y \in \{\text{OK}, \text{spam}\}\)</span> for each email</li>
<li><span class="math inline">\(x\)</span> can include sender identity, words and terms (“prize!”, “sex”, …)</li>
<li>The model should identify and remove spam</li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>עוד דוגמאות מעניינות:</p>
<p>Genome Wide Association Studies או GWAS, בהם אנחנו מנסים לבודד גנים שאחראים על מחלות למשל.</p>
<p>Y כאן הוא האם האדם בריא או חולה, Xהוא כל הגנום שלו. זה יכול להגיע למיליון מיקומים על הכרומוזום, שבהם יכול להיות לאדם 0, 1 או 2 עותקים של מוטציות בגן. וזו דוגמא טובה למצב שמעניין אותנו חיזוי על אדם חדש בהתאום לגנום שלו, האם הוא בסיכון למחלה, אבל גם מעניין אותנו לראות אילו גנים אחראים למחלה, כלומר אילו משתנים בX משפיעים על Y.</p>
<p>דוגמא קלאסית נוספת היא חיזוי האם מייל הוא ספאם או לא. X יכול להיות הרבה סוגים של משתנים: מי השולח, מי הנמען, מתי נשלח המייל וכמובן תוכן המייל, המילים השונות שמרכיבות אותו. שימו לב שוקטור שמתאר מילים הוא וקטור ממימד עצום, של כל אוצר המילים בשפה אחת או יותר, בעצם. בכל אופן המטרה היא לחזות האם מייל הוא ספאם וישר להעביר אותו לתיקיית הספאם.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="some-more-examples-from-real-life-1">Some more examples from real life</h3>
<div class="fragment">
<!-- -->
<h4 id="online-advertising">Online advertising:</h4>
<ul>
<li>Surfer arrives on website, need to decide if and what ad to show them</li>
<li><span class="math inline">\(y\)</span> can be the amount she will spend if shown advertising for shirt/shoes/car/home</li>
<li><span class="math inline">\(x\)</span>: surfing history, location, time of day/week/year, information from other databases, …</li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>דוגמא אחרונה היא מעולם הפרסום: גולשת מגיעה לאתר וצריך להחליט האם להראות לה פרסומת, באנר, ואיזו פרסומת להראות לה. Y יהיה השורה התחתונה, כמה כסף היא תבזבז על המוצר בפרסומת. X כאן יכול להיות מגוון ככל שיד הדמיון טובה עליכם: היסטורית הגלישה של הגולשת, המיקום שלה, מתי היא גולשת, ואפילו דאטא מקוקיז וממסדי נתונים חיצוניים.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="some-simple-models-for-netflix">Some simple models for Netflix</h3>
<p>The same score as a similar movie, say Sweet Home Alabama:</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>scatter_cong(<span class="st">'Sweet Home Alabama'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img data-src="c09_regression_files/figure-revealjs/cell-3-output-1.png" width="441" height="461"></p>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נחזור לדוגמא של נטפליקס ונחשוב על מודל פשוט: נחזה את הדירוג של צופה באיזו מין שוטרת באמצעות סרט שדומה לו, למשל ראינו שהציונים של סוויט הום אלבמה מאוד דומים לציונים של איזו מין שוטרת, שני הסרטים הם קומדיות רומנטיות.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="some-simple-models-for-netflix-1">Some simple models for Netflix</h3>
<p>The first PC score (those who love everything, love Miss Congeniality?):</p>
<div class="cell" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> ratings.values[:,:<span class="dv">14</span>]</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>X_centered <span class="op">=</span> X <span class="op">-</span> X.mean(axis <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA()</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>pca.fit(X_centered)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>W <span class="op">=</span> pca.components_.T</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> X_centered <span class="op">@</span> W</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>add_data_1<span class="op">=</span>pd.DataFrame({<span class="st">'PC1'</span>: T[:,<span class="dv">0</span>], <span class="st">'Miss Congeniality'</span>:miss_cong.values[:,<span class="dv">0</span>]})</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>sns.lmplot(x<span class="op">=</span><span class="st">'PC1'</span>, y<span class="op">=</span><span class="st">'Miss Congeniality'</span>, data<span class="op">=</span>add_data_1, legend <span class="op">=</span> <span class="va">False</span>, fit_reg<span class="op">=</span><span class="va">False</span>, ci<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f'Corr </span><span class="sc">{</span>np<span class="sc">.</span>corrcoef(T[:,<span class="dv">0</span>],miss_cong.values[:,<span class="dv">0</span>])[<span class="dv">0</span>,<span class="dv">1</span>] <span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img data-src="c09_regression_files/figure-revealjs/cell-4-output-1.png" width="489" height="509"></p>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>מודל פשוט אחר שכבר רמזנו עליו כשדיברנו על PCA: אולי הscore של צופה בPC הראשון, הPC שמסביר הכי הרבה שונות, הוא מנבא טוב לציון של הסרט איזו מין שוטרת.</p>
<p>ניזכר שבPC הזה הציון של כל צופה גבוה יותר ככל שהוא פחות מסכים עם הדירוג הממוצע של הסרטים. והדירוגים בממוצע הם די גבוהים, לכן נצפה שככל שהציון של צופה גבוה בPC הראשון ככה הוא “שונא” יותר סרטים וגם ייתן ציון נמוך לאיזו מין שוטרת. וזה אכן מה שמתקבל, יחס יורד ומתאם שלילי לא מבוטל.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="predictive-modeling-paradigm">Predictive modeling paradigm</h3>
<ul>
<li><p>We typically assume that we have a <em>training</em> dataset of size <span class="math inline">\(n\)</span>: <span class="math inline">\(Tr = \{(x_1,y_1),\dots,(x_n,y_n)\} = (X_{n\times p},Y_{n\times 1})\)</span></p></li>
<li><p>IID assumption: each pair <span class="math inline">\((x_i, y_i)\)</span> is drawn indepednently from some distribution <span class="math inline">\(P_{x,y}\)</span></p></li>
</ul>
<div>
<ul>
<li class="fragment">A modeling approach takes <span class="math inline">\(Tr\)</span> as input and outputs a <em>prediction model</em> <span class="math inline">\(\hat{f}(x)\)</span> based on the training data
<ul>
<li class="fragment">In prediction: we get a new value <span class="math inline">\(x_0\)</span> and predict <span class="math inline">\(\hat{y}_0 = \hat{f}(x_0)\)</span>.</li>
</ul></li>
<li class="fragment">How good is our prediction? We typically define a loss function <span class="math inline">\(L(y,\hat{y})\)</span> and the quality of the model is <span class="math inline">\(\mathbb{E}_{x_0,y_0}(L(y_0, \hat{y}_0))\)</span></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בכל בעיה של מודל לחיזוי יהיה לנו מדגם למידה או training, שנסמן בTR, המדגם יהיה בגודל N, כלומר N זוגות של X ו-Y. אפשר לכתוב אותם גם כמטריצה X עם N שורות וP עמודות, וY כוקטור באורך N.</p>
<p>ואנחנו נניח את הנחת הIID בקורס שלנו, זוגות התצפיות הם בלתי תלויים, הם נדגמים בצורה בלתי תלויה מאיזושהי התפלגות משותפת PXY. אם התצפיות לא בלתי תלויות אגב זה מצב מעניין מאוד שמביא לפיתוחים מרתקים אבל לא נעסוק בזה בקורס שלנו.</p>
<p>בסופו של דבר הפלט שלנו יהיה מודל לחיזוי, f_hat שמבוסס על מדגם הלמידה, והמטרה האולטימטיבית היא, כשתגיע תצפית חדשה X_0, נחזה לזה y_hat_0 באמצעות המודל שלמדנו f_hat.</p>
<p>איך נמדוד את הביצועים של המודל שלנו? במצב אידאלי נגדיר איזושהי פונקצית הפסד L, שמקבלת ממדגם הלמידה תצפית Y אמיתית ותצפית חזויה y_hat. תוחלת הכמות הזאת, תחת תצפיות שהמודל לא ראה, היא היא הכמות שהיינו רוצים לעשות לה מינימיזציה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="the-loss-function-l">The loss function <span class="math inline">\(L\)</span></h3>
<div>
<ul>
<li class="fragment"><p>It measures the quality of the prediction: we can think of <span class="math inline">\(L(y,\hat{y})\)</span> as a measure of how much we lose when we predict <span class="math inline">\(\hat{y}\)</span> but the truth is <span class="math inline">\(y\)</span>.</p></li>
<li class="fragment"><p>Simple example for classification: <em>misclassification error loss</em> <span class="math display">\[L(y,\hat{y}) = \left\{\begin{array}{ll} 0 &amp; \mbox{if } y=\hat{y}\\
1 &amp; \mbox{if } y\neq\hat{y}\end{array} \right.\]</span></p></li>
<li class="fragment"><p>More complex approach: penalize different types of error differently, e.g.: <span class="math display">\[L(y,\hat{y}) = \left\{\begin{array}{ll} 0 &amp; \mbox{if } y=\hat{y}\\
1 &amp; \mbox{if } y=0,\hat{y}=1\\
10 &amp; \mbox{if } y=1,\hat{y}=0 \end{array} \right.\]</span></p></li>
<li class="fragment"><p>Simple example for regression: <em>squared error loss</em> <span class="math display">\[L(y,\hat{y}) = (y-\hat{y})^2.\]</span></p></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>מה יכולה להיות פונקצית ההפסד L?</p>
<p>זה תלוי בנתונים. היינו רוצים שהיא תבטא כמה אנחנו “מפסידים” כשהתצפית האמיתית היא Y ואנחנו חוזים y_hat.</p>
<p>בקלאסיפיקציה אפשר למשל לחשוב על שיעור התחזיות השגויות: אם y_hat שווה לקטגוריה Y הנכונה, אז שילמנו מחיר 0. אם לא נספור את זה כטעות, מחיר 1.</p>
<p>אפשר לחשוב גם על משקול הטעויות שלנו, הרי לא כל טעות “עולה לנו” באותה מידה. אז על טעות בכיוון אחד ההפסד יוגדר כ1, וטעות בכיוון אחר ההפסד יהיה פי 10. נסו לחשוב על דוגמאות בהן הטעות היא לא סימטרית. למשל באבחון מחלה בה הטיפול אינו בעל תופעות לוואי חמורות, ניתן להגיד שאם נאבחן אדם בריא כחולה אולי לא נסב הרבה נזק. אבל אם נאבחן אדם חולה כבריא נפספס אותו והוא עלול לא לקבל טיפול ותחול הידרדרות במצבו עד כדי סכנה ממשית.</p>
<p>בבעיות רגרסיה, מדד מקובל הוא הטעות הריבועית כפונקצית הפסד. ואפשר גם לדבר על שגיאה בערך מוחלט ועוד המון פונקציות הפסד אחרות שמדגישות מה שחשוב לבעיה הספציפית שלפנינו.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="evaluating-predictive-models">Evaluating predictive models</h3>
<div>
<ul>
<li class="fragment"><p>We are interested in <span class="math inline">\(\mathbb{E}_{x_0,y_0}(L(y_0, \hat{y}_0))\)</span>, but we don’t know it</p></li>
<li class="fragment"><p>Solution: in addition to the training data <span class="math inline">\(Tr\)</span>, have a <em>test</em> data <span class="math inline">\(Te= \{(x_{n+1},y_{n+1}),...,(x_{n+m},y_{n+m})\}\)</span> of size <span class="math inline">\(m\)</span> and evaluate the model on it: <span class="math inline">\(\;\;\hat{Err} = \frac{1}{m} \sum_{i=n+1}^{n+m} L(y_i, \hat{f}(x_i)).\)</span></p></li>
<li class="fragment"><p>For squared error loss, it is typical to report the <em>Root</em> mean squared error: <span class="math display">\[RMSE = \sqrt{\frac{1}{m} \sum_{i=n+1}^{n+m} (y_i-\hat{f}(x_i))^2}\]</span></p></li>
<li class="fragment"><p>Since we typically only have one dataset (as in Netflix, wikiart examples), we split it <em>randomly</em> in two parts:</p>
<ul>
<li class="fragment">Training set (typically <span class="math inline">\(80\%\)</span> of the data)</li>
<li class="fragment">Test set (typically <span class="math inline">\(20\%\)</span> of the data)</li>
</ul></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>מכל מקום, היינו רוצים כאמור את התוחלת של ההפסד תחת התפלגות תצפיות שהמודל לא ראה, אבל אנחנו לא מסוגלים באמת לחשב את זה בלי הערכה טובה של ההתפלגות של הדאטה.</p>
<p>לכן מה שנהוג לעשות זה לחשב את ההפסד האמפירי, על סט נתונים נפרד, בגודל M נאמר, זהו סט המבחן או הטסטינג סט, ונסמן אותו כTE. ואז, הטעות שנרצה למזער היא ממוצע ההפסד על פני הטסט סט הזה, שהמודל לא ראה. אנחנו מקרבים תוחלת על-ידי ממוצע.</p>
<p>למשל ברגרסיה כך יראה הממוצע של פונקצית ההפסד הריבועי, זה נקרא mean squared error או MSE, ונהוג לקחת שורש ולקבל את הroot mean squared error או הRMSE.</p>
<p>בדרך כלל נקבל סט אחד של נתונים, בשאיפה עם מספיק תצפיות, כדי לחלק אותם בצורה אקראית, למדגם למידה (למשל 80 אחוז), ומדגם טסט (20 אחוז).</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="data-splitting">Data Splitting</h3>
<p>Let’s divide our Netflix data 80-20:</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3" data-code-line-numbers="|1-2|3-6|7-10|"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a>X <span class="op">=</span> ratings.values</span>
<span id="cb3-2"><a href="#cb3-2"></a>Y <span class="op">=</span> miss_cong.values[:, <span class="dv">0</span>]</span>
<span id="cb3-3"><a href="#cb3-3"></a>n <span class="op">=</span> X.shape[<span class="dv">0</span>]</span>
<span id="cb3-4"><a href="#cb3-4"></a>tr_size <span class="op">=</span> <span class="bu">int</span>(<span class="fl">0.8</span> <span class="op">*</span> n)</span>
<span id="cb3-5"><a href="#cb3-5"></a>te_size <span class="op">=</span> n <span class="op">-</span> tr_size</span>
<span id="cb3-6"><a href="#cb3-6"></a>tr_ind <span class="op">=</span> np.random.choice(<span class="bu">range</span>(n), tr_size, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb3-7"><a href="#cb3-7"></a>Xtr <span class="op">=</span> X[tr_ind,]</span>
<span id="cb3-8"><a href="#cb3-8"></a>Xte <span class="op">=</span> np.delete(X, tr_ind, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb3-9"><a href="#cb3-9"></a>Ytr <span class="op">=</span> Y[tr_ind]</span>
<span id="cb3-10"><a href="#cb3-10"></a>Yte <span class="op">=</span> np.delete(Y, tr_ind)</span>
<span id="cb3-11"><a href="#cb3-11"></a></span>
<span id="cb3-12"><a href="#cb3-12"></a><span class="bu">print</span>(<span class="ss">f'No. of train rows: </span><span class="sc">{</span>Xtr<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">, no. train of cols: </span><span class="sc">{</span>Xtr<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb3-13"><a href="#cb3-13"></a><span class="bu">print</span>(<span class="ss">f'No. of test rows: </span><span class="sc">{</span>Xte<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">, no. test of cols: </span><span class="sc">{</span>Xte<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb3-14"><a href="#cb3-14"></a><span class="bu">print</span>(<span class="ss">f'no. of obs in train y: </span><span class="sc">{</span>Ytr<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb3-15"><a href="#cb3-15"></a><span class="bu">print</span>(<span class="ss">f'no. of obs in test y: </span><span class="sc">{</span>Yte<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>No. of train rows: 8000, no. train of cols: 99
No. of test rows: 2000, no. test of cols: 99
no. of obs in train y: 8000
no. of obs in test y: 2000</code></pre>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נעשה את החלוקה הזאת בדאטא של נטפליקס בצורה ידנית, מאוחר יותר נראה שיש לנו פונקציה שתבצע לנו את העבודה בצורה אוטומטית.</p>
<p>X הוא הדירוגים על 99 סרטים בדאטאפריים של הרייטינגז, Y הוא הציונים של miss congeniality.</p>
<p>כאן אני מחשב את גודל מדגם הלמידה, 80 אחוז מהN, וגודל מדגם הטסט, כל השאר. ואני דוגם מספר אינדקסים של תצפיות בהתאם באוביקט tr_ind.</p>
<p>עכשיו מתבצעת החלוקה לXtr ו-Xte, ולYtr ו Yte.</p>
<p>בסופו של דבר בהתאם לציפיות יש לנו 8000 תצפיות על 99 סרטים במדגם הלמידה, ו-2000 תצפיות על 99 סרטים במדגם הטסט.</p>
<p>עכשיו אפשר להתחיל לדבר על מודלים לחיזוי ספציפיים לנתונים של נטפליקס.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="linear-regression" class="slide level2 title-slide center">
<h2>Linear Regression</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נתחיל ברגרסיה ליניארית. רגרסיה ליניארית הוא נושא שנכתבו עליו אינספור ספרים עבי כרס החל מאמצע המאה העשרים, ובחוגים מסוימים מקדישים למודל היחיד הזה סמסטר שלם, כמו למשל אקונומטריקה בחוג לכלכלה. כאן ננסה לתת מבט על המודל כמו על מודלים אחרים, ונפנה את מי שמעוניין לקורסים מתקדמים יותר.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="linear-regression-1">Linear Regression</h3>
<div>
<ul>
<li class="fragment"><p>Assume now <span class="math inline">\(x \in \mathbb{R}^p, y\in \mathbb{R}\)</span>, and we want to build a model of the form: <span class="math display">\[\hat{f}(x) = \hat{\beta}_0 + \hat{\beta}_1 x_1 + \ldots + \hat{\beta}_p x_p.\]</span></p></li>
<li class="fragment"><p>We have <span class="math inline">\(Tr\)</span>, how can we estimate the coefficients?</p></li>
<li class="fragment"><p>Find coefficients that ’’fit” <span class="math inline">\(Tr\)</span> well, that is <span class="math inline">\(\hat{f}(x_i) \approx y_i,\;i=1,\ldots,n.\)</span></p></li>
<li class="fragment"><p>Possible approach: Minmize <em>residual sum of squares</em> (RSS): <span class="math display">\[RSS(\beta_0, \beta_1, \dots, \beta_p) = \sum_{i=1}^n (y_i - (\hat{\beta}_0 + \hat{\beta}_1 x_{i1} + \ldots + \hat{\beta}_p x_{ip}))^2 = \|Y - X_{n \times (p+1)} \beta\|^2.\]</span></p></li>
<li class="fragment"><p>This is the <em>ordinary least squares (OLS) linear regression</em> problem</p></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>המודל f_hat שקושר בין וקטור תצפיות X לסקלאר הוא מודל ליניארי: הכמות הנחזית תהיה צירוף ליניארי של המשתנים בX כשהמשקולות מסומנות בבטא, ויש מעליהן סימן האט כי זאת המשימה שלנו לשערך את משקולות הרגרסיה.</p>
<p>איך נמצא את מקדמי הרגרסיה ממדגם הלמידה?</p>
<p>ננסה למצוא מקדמים שמביאים את המודל הכי קרוב לY האמיתי.</p>
<p>למשל, נרצה למזער את סכום השגיאות הריבועיות מהf_hat החזוי לy האמיתי, על פני מדגם הלמידה. אנחנו קוראים להפסד הזה RSS או residual sum of squares, ומסמנים אותו כפונקציה של הבטאות. נשים לב שניתן גם לכתוב אותו בכתיב מטריציוני מה שיכול להאץ את המימוש: הוא בעצם הנורמה הריבועית של הוקטור Y פחות מטריצה X מוכפלת בוקטור המקדמים בטא.</p>
<p>נשים לב שנוספה עמודה למטריצת הדאטא X כאן, ויש לה כבר p + 1 עמודות, וזאת על מנת לאפשר את החותך בטא-אפס שיש לנו במודל. העמודה שתתווסף לX תהיה בעצם וקטור שכולו אחד בצורה הזאת (להדגים).</p>
<p>המודל הזה הוא מודל הרגרסיה הליניארית הקלאסית הרגיל, OLS או ordinary least squares, כי אנחנו רוצים להביא למינימום את השגיאות הריבועיות.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="simple-demo-p1-on-netflix-data">Simple Demo: <span class="math inline">\(p=1\)</span> on Netflix Data</h3>
<p>Let’s go back to <span class="math inline">\(y\)</span> = Miss Congeniality vs.&nbsp;<span class="math inline">\(x_1\)</span> = Sweet Home Alabama:</p>
<p>The <code>statsmodels</code> approach:</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5" data-code-line-numbers="|1-2|4|6|7|8|"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a>sweet_home_idx <span class="op">=</span> <span class="dv">9</span></span>
<span id="cb5-2"><a href="#cb5-2"></a>X_sweet_tr <span class="op">=</span> Xtr[:, [sweet_home_idx]]</span>
<span id="cb5-3"><a href="#cb5-3"></a></span>
<span id="cb5-4"><a href="#cb5-4"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb5-5"><a href="#cb5-5"></a></span>
<span id="cb5-6"><a href="#cb5-6"></a>X_sweet_tr1 <span class="op">=</span> sm.add_constant(X_sweet_tr)</span>
<span id="cb5-7"><a href="#cb5-7"></a>model <span class="op">=</span> sm.OLS(Ytr, X_sweet_tr1)</span>
<span id="cb5-8"><a href="#cb5-8"></a>model <span class="op">=</span> model.fit()</span>
<span id="cb5-9"><a href="#cb5-9"></a><span class="bu">print</span>(<span class="ss">f'y = </span><span class="sc">{</span>model<span class="sc">.</span>params[<span class="dv">0</span>]<span class="sc">:.2f}</span><span class="ss"> + </span><span class="sc">{</span>model<span class="sc">.</span>params[<span class="dv">1</span>]<span class="sc">:.2f}</span><span class="ss">*x1'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell fragment" data-execution_count="5">
<div class="cell-output cell-output-stdout">
<pre><code>y = 2.12 + 0.40*x1</code></pre>
</div>
</div>
<div class="fragment">
<p>The <code>SKlearn</code> approach:</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7" data-code-line-numbers="|1|3|4|"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb7-2"><a href="#cb7-2"></a></span>
<span id="cb7-3"><a href="#cb7-3"></a>model <span class="op">=</span> LinearRegression()</span>
<span id="cb7-4"><a href="#cb7-4"></a>model.fit(X_sweet_tr, Ytr)</span>
<span id="cb7-5"><a href="#cb7-5"></a><span class="bu">print</span>(<span class="ss">f'y = </span><span class="sc">{</span>model<span class="sc">.</span>intercept_<span class="sc">:.2f}</span><span class="ss"> + </span><span class="sc">{</span>model<span class="sc">.</span>coef_[<span class="dv">0</span>]<span class="sc">:.2f}</span><span class="ss">*x1'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell fragment" data-execution_count="6">
<div class="cell-output cell-output-stdout">
<pre><code>y = 2.12 + 0.40*x1</code></pre>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נראה איך מתאימים את מודל הרגרסיה הליניארית דווקא בפייתון קודם, כדי לראות את השורה התחתונה. אחר כך נחזור לאיך זה מתבצע בפועל.</p>
<p>כאן נתחיל עם משתנה יחיד בX וחותך. ניקח סרט אחד והוא יהיה sweet home alabama.</p>
<p>נראה מימוש בשתי ספריות, נתחיל בספריה שהמחברים שלה יותר דאגו למשתמשים עם אורינטציה סטטיסטית, ובאמת הפלט שהיא נותנת עשיר יותר כמו פלטים של תוכנות סטטיסטיות כמו SPSS או R.</p>
<p>אני קורא את הסרט sweet home alabama לתוך מטריצת X_sweet_tr, שתהיה לה עמודה אחת בשלב זה. נשים לב שאני מקפיד להשתמש במדגם הלמידה שלי, ומדגם הטסט כלל לא מופיע!</p>
<p>כעת אני מייבא מספריית statsmodels את המודול api.</p>
<p>בספרייה הזאת החותך לא מתווסף באופן אוטומטי, אנחנו צריכים לבקש על מטריצת הX שלנו add_constant וזה מה שמוסיף לה עמודה של אחדות, נקרא לה עכשיו X_sweet_tr1.</p>
<p>כעת מאתחלים קלאס שנקרא OLS, מזינים לתוכו את Y ואז את X, נקרא לאוביקט הזה model.</p>
<p>ורק כשמבקשים את המתודה fit קורית בעצם הרגרסיה הליניארית, ובאוביקט הmodel שלנו יש את כל מה שאנחנו צריכים.</p>
<p>בפרט יש לאוביקט שלנו שדה שנקרא params ובתוכו נמצאות הבטאות. במקרה שלנו יש שתי בטאות, בטא-אפס לחותך, ובטא-אחת לשיפוע של המשתנה היחיד, ואני מדפיס את המודל הסופי בצורה כזאת:</p>
<p>מסתבר שהמודל חיזוי הליניארי הכי פשוט עם סוויט הום אלבמה כסרט מנבא למיס קונג’יניאליטי, הוא לתת לכולם את ציון הבסיס 2.14, ואז על כל עליה בדירוג של סוויט הום אלבמה להוסיף 0.40.</p>
<p>ספרייה אחרת שכבר ראינו היא sklearn, והיא ספריה שאין לה אוריינטציה סטטיסטית אבל הרבה יתרונות אחרים כמו הממשק האחוד שלה לכל מודל מאשין לרנינג.</p>
<p>כאן אני מייבא את הקלאס לינאר רגרשן, מאתחל אותו לתוך אוביקט ששוב נקרא model. רק כשאני מבקש על model את המתודה פיט, לתוכה אני מכניס את X וY מתבצעת הרגרסיה הליניארית. נשים לב שכאן כאן ברירת המחדל היא להוסיף חותך למודל והX שמכניסים למתודה פיט לא כולל את העמודה של אחדות, sklearn יעשה את זה בשבילכם.</p>
<p>כאן לחותך יש שדה משלו, אינטרספט, ושאר הבטאות יופיעו בשדה coef מהמילה coefficients. נקבל כמובן את אותו מודל.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<p>The model is a simple straight line:</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9" data-code-line-numbers="|1-2|4-5|"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1"></a>pred_x <span class="op">=</span> np.arange(<span class="dv">1</span>, <span class="dv">6</span>).reshape((<span class="dv">5</span>, <span class="dv">1</span>))</span>
<span id="cb9-2"><a href="#cb9-2"></a>y_hat <span class="op">=</span> model.predict(pred_x)</span>
<span id="cb9-3"><a href="#cb9-3"></a></span>
<span id="cb9-4"><a href="#cb9-4"></a>scatter_cong(<span class="st">'Sweet Home Alabama'</span>)</span>
<span id="cb9-5"><a href="#cb9-5"></a>plt.plot(pred_x, y_hat, color <span class="op">=</span> <span class="st">'r'</span>)</span>
<span id="cb9-6"><a href="#cb9-6"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell fragment" data-execution_count="7">
<div class="cell-output cell-output-display">
<p><img data-src="c09_regression_files/figure-revealjs/cell-8-output-1.png" width="441" height="461"></p>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>למקרה שזה לא היה ברור, המודל שקיבלנו הוא משוות קו ישר פשוט. בואו נראה את זה:</p>
<p>אני בונה X מלאכותי שיש בו פשוט את הדירוגים 1 עד 5. ואני מבקש מהמודל לחזות את הציון של sklearn לחזות הדירוג של Y על הדירוגים האלה.</p>
<p>עכשיו אני מציירת שוב את הסקאטרפלוט שלנו של דירוגי מיס קונג’יניאליטי מול סוויט הום אלבמה, ומוסיף עליהם את הקו הישר שחוזה המודל. הקו נראה די מתאים לנתונים גם אם הוא פשטני.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="evaluating-on-the-test-data">Evaluating on the test data</h3>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb10" data-code-line-numbers="|2-3|5|6|"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a><span class="co"># this is the sklearn approach, no need to add constant</span></span>
<span id="cb10-2"><a href="#cb10-2"></a>X_sweet_te <span class="op">=</span> Xte[:, [sweet_home_idx]]</span>
<span id="cb10-3"><a href="#cb10-3"></a>y_hat_te <span class="op">=</span> model.predict(X_sweet_te)</span>
<span id="cb10-4"><a href="#cb10-4"></a></span>
<span id="cb10-5"><a href="#cb10-5"></a>test_RMSE_null <span class="op">=</span> np.sqrt(np.mean((Yte<span class="op">-</span>np.mean(Ytr))<span class="op">**</span><span class="dv">2</span>))</span>
<span id="cb10-6"><a href="#cb10-6"></a>test_RMSE_1movie <span class="op">=</span> np.sqrt(np.mean((Yte<span class="op">-</span>y_hat_te)<span class="op">**</span><span class="dv">2</span>))</span>
<span id="cb10-7"><a href="#cb10-7"></a></span>
<span id="cb10-8"><a href="#cb10-8"></a><span class="bu">print</span>(<span class="ss">f'Test RMSE predicting the mean: </span><span class="sc">{</span>test_RMSE_null<span class="sc">: .2f}</span><span class="ss">'</span>)</span>
<span id="cb10-9"><a href="#cb10-9"></a><span class="bu">print</span>(<span class="ss">f'Test RMSE with Sweet Home Alabama: </span><span class="sc">{</span>test_RMSE_1movie<span class="sc">: .2f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell fragment" data-execution_count="8">
<div class="cell-output cell-output-stdout">
<pre><code>Test RMSE predicting the mean:  0.96
Test RMSE with Sweet Home Alabama:  0.86</code></pre>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אז המודל מובן. קו ישר. אמרנו שכדי להעריך עד כמה המודל טוב, צריך לראות את הביצועים שלו על נתונים שהמודל לא ראה, הטסט סט, ומקובל לעשות את זה עם מדד הRMSE. שורש השגיאה הריבועית הממוצעת.</p>
<p>כאן אני מחלץ את סוויט הום אלבמה גם מהטסט סט, והוואי-הט שלי מתקבל באמצעות קריאה לmodel.predict.</p>
<p>כעת אני מדווח על שני RMSE. RMSE נאל, הוא RMSE שיתקבל אם אני פשוט אחזה את הממוצע של Y שראיתי במדגם הלמידה. זה ייתן לנו איזשהו בייסליין של האם המודל שלנו שיפר במשהו, ואני מאוד מאוד ממליץ לעבוד עם בייסליינים פשוטים במיוחד ברגרסיה, כי הRMSE עצמו לא אומר הרבה כפי שנראה.</p>
<p>RMSE נוסף שאני מחשב הוא הRMSE של המודל שלנו עם סרט אחד בלבד, נשים לה שאני מממש כאן את הנוסחה בדיוק כפי שהיא כתובה, ברור שלsklearn יש פקודות גם בשביל זה.</p>
<p>והתוצאה, במודל הכי פשטני שהוא בעצם קו ישר של הממוצע, נקבל RMSE של 0.96, ועם סוויט הום אלבמה כבר נקבל הפחתה בכעשרה אחוזים ל0.86.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="simple-demo-p-14-on-netflix-data">Simple Demo: <span class="math inline">\(p = 14\)</span> on Netflix Data</h3>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>Xtr_df <span class="op">=</span> pd.DataFrame(Xtr[:, :<span class="dv">14</span>], columns<span class="op">=</span>movies[<span class="st">'title'</span>][:<span class="dv">14</span>])</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>Xtr_df1 <span class="op">=</span> sm.add_constant(Xtr_df)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.OLS(Ytr, Xtr_df1)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> model.fit()</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell fragment" data-execution_count="9">
<div class="cell-output cell-output-stdout">
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.276
Model:                            OLS   Adj. R-squared:                  0.275
Method:                 Least Squares   F-statistic:                     217.8
Date:                Sat, 05 Aug 2023   Prob (F-statistic):               0.00
Time:                        11:07:04   Log-Likelihood:                -9715.2
No. Observations:                8000   AIC:                         1.946e+04
Df Residuals:                    7985   BIC:                         1.957e+04
Df Model:                          14                                         
Covariance Type:            nonrobust                                         
============================================================================================
                               coef    std err          t      P&gt;|t|      [0.025      0.975]
--------------------------------------------------------------------------------------------
const                        0.3707      0.090      4.115      0.000       0.194       0.547
Independence Day             0.0636      0.013      4.780      0.000       0.038       0.090
The Patriot                 -0.0226      0.012     -1.920      0.055      -0.046       0.000
The Day After Tomorrow       0.0445      0.011      4.081      0.000       0.023       0.066
Pirates of the Caribbean     0.0765      0.012      6.380      0.000       0.053       0.100
Pretty Woman                 0.1616      0.012     13.861      0.000       0.139       0.184
Forrest Gump                -0.0663      0.013     -4.944      0.000      -0.093      -0.040
The Green Mile               0.0294      0.014      2.154      0.031       0.003       0.056
Con Air                      0.0835      0.012      6.767      0.000       0.059       0.108
Twister                      0.0908      0.012      7.680      0.000       0.068       0.114
Sweet Home Alabama           0.2195      0.011     19.974      0.000       0.198       0.241
Pearl Harbor                 0.0352      0.011      3.323      0.001       0.014       0.056
Armageddon                  -0.0010      0.013     -0.078      0.938      -0.026       0.024
The Rock                    -0.0160      0.013     -1.241      0.215      -0.041       0.009
What Women Want              0.1493      0.011     13.029      0.000       0.127       0.172
==============================================================================
Omnibus:                      145.057   Durbin-Watson:                   1.984
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              154.185
Skew:                          -0.321   Prob(JB):                     3.31e-34
Kurtosis:                       3.225   Cond. No.                         150.
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בואו נתקדם להשתמש בכל 14 הסרטים שלגביהם אין לנו תצפיות חסרות. כלומר p יהיה 14. כאן אני עוטף אותם כדאטאפריים של פנדאז בשביל פלט נוח יותר. ואז חוזר על הצעדים שלי, מוסיף חותך, קורא לOLS, ומבקש fit לריצת הרגרסיה.</p>
<p>עכשיו אני מבקש model.summary כדי לקבל פלט מקצועי של רגרסיה ליניארית. ברור שאין בסקופ של הקורס שלנו פנאי לעבור על כל מדד ומדד שמודפס כאן. כרגע אני רק רוצה שתשימו לב לעמודה של coef, אנחנו מקבלים על החותך ועל כל סרט את המקדם בטא שלו. המודל הזה כבר נותן ציון בסיס נמוך של 0.4 למיס קונג’יניאליטי, ואז מעניין לראות את המקדמים של הסרטים השונים. אפשר לראות שסרטים כמו אישה יפה, סוויט הום אלבמה ומה נשים רוצות מקבלים מקדמים חיוביים ודי גדולים, פורסט גאמפ למשל מקבל מקדם שלילי.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># this is the statsmodels approach, need to add constant</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>Xte1 <span class="op">=</span> sm.add_constant(Xte[:, :<span class="dv">14</span>])</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>y_hat_te <span class="op">=</span> model.predict(Xte1)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>test_RMSE_14movies <span class="op">=</span> np.sqrt(np.mean((Yte <span class="op">-</span> y_hat_te)<span class="op">**</span><span class="dv">2</span>))</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Test RMSE with the mean: </span><span class="sc">{</span>test_RMSE_null<span class="sc">: .2f}</span><span class="ss">'</span>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Test RMSE with Sweet Home Alabama: </span><span class="sc">{</span>test_RMSE_1movie<span class="sc">: .2f}</span><span class="ss">'</span>)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Test RMSE with 14 movies: </span><span class="sc">{</span>test_RMSE_14movies<span class="sc">: .2f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell fragment" data-execution_count="10">
<div class="cell-output cell-output-stdout">
<pre><code>Test RMSE with the mean:  0.96
Test RMSE with Sweet Home Alabama:  0.86
Test RMSE with 14 movies:  0.81</code></pre>
</div>
</div>
<div class="fragment">
<p>What is the model now?</p>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>ושוב, נרצה לבדוק את הRMSE של המודל על מדגם הטסט שהוא לא ראה. אנחנו מחשבים אותו בדיוק כמו קודם, ומקבלים עוד הפחתה משמעותית, אנחנו כבר ב0.81.</p>
<p>כשהמודל היה עם סרט אחד היה ברור שהמודל הוא בעצם קו ישר. איך נראה המודל שלנו עכשיו? אם תכלילו לשני משתנים המודל יהיה בעצם מישור (להדגים), ויותר משני משתנים נקרא לזה מישור פי-מימדי.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="even-more-adventurous-use-all-99-movies">Even more adventurous: use all 99 movies</h3>
<p>What to do about missing? Let’s keep as 0 for now (did not rate = hate…)</p>
<p><strong>Dealing with missing values is an important topic, that we won’t cover here</strong></p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb16" data-code-line-numbers="|1,6|"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1"></a>Xtr[np.isnan(Xtr)] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb16-2"><a href="#cb16-2"></a>Xtr1 <span class="op">=</span> sm.add_constant(Xtr)</span>
<span id="cb16-3"><a href="#cb16-3"></a>model <span class="op">=</span> sm.OLS(Ytr, Xtr1)</span>
<span id="cb16-4"><a href="#cb16-4"></a>model <span class="op">=</span> model.fit()</span>
<span id="cb16-5"><a href="#cb16-5"></a></span>
<span id="cb16-6"><a href="#cb16-6"></a>Xte[np.isnan(Xte)]<span class="op">=</span><span class="dv">0</span></span>
<span id="cb16-7"><a href="#cb16-7"></a>Xte1 <span class="op">=</span> sm.add_constant(Xte)</span>
<span id="cb16-8"><a href="#cb16-8"></a>y_hat_te <span class="op">=</span> model.predict(Xte1)</span>
<span id="cb16-9"><a href="#cb16-9"></a></span>
<span id="cb16-10"><a href="#cb16-10"></a>test_RMSE_99movies <span class="op">=</span> np.sqrt(np.mean((Yte <span class="op">-</span> y_hat_te)<span class="op">**</span><span class="dv">2</span>))</span>
<span id="cb16-11"><a href="#cb16-11"></a></span>
<span id="cb16-12"><a href="#cb16-12"></a><span class="bu">print</span>(<span class="ss">f'Test RMSE with the mean: </span><span class="sc">{</span>test_RMSE_null<span class="sc">: .2f}</span><span class="ss">'</span>)</span>
<span id="cb16-13"><a href="#cb16-13"></a><span class="bu">print</span>(<span class="ss">f'Test RMSE with Sweet Home Alabama: </span><span class="sc">{</span>test_RMSE_1movie<span class="sc">: .2f}</span><span class="ss">'</span>)</span>
<span id="cb16-14"><a href="#cb16-14"></a><span class="bu">print</span>(<span class="ss">f'Test RMSE with 14 movies: </span><span class="sc">{</span>test_RMSE_14movies<span class="sc">: .2f}</span><span class="ss">'</span>)</span>
<span id="cb16-15"><a href="#cb16-15"></a><span class="bu">print</span>(<span class="ss">f'Test RMSE with 99 movies: </span><span class="sc">{</span>test_RMSE_99movies<span class="sc">: .2f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell fragment" data-execution_count="11">
<div class="cell-output cell-output-stdout">
<pre><code>Test RMSE with the mean:  0.96
Test RMSE with Sweet Home Alabama:  0.86
Test RMSE with 14 movies:  0.81
Test RMSE with 99 movies:  0.77</code></pre>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אבל יש לנו 99 סרטים. בחלקם יש פשוט ערכים חסרים.</p>
<p>בואו נציב לצורך התרגיל במקום ערכים חסרים אפס. כאילו מי שלא דרג סרט מסוים ממש לא אהב אותו. ברור שזה לא הדבר הכי חכם שניתן לעשות כאן ועל טיפול בערכים חסרים גם כן ניתן לבלות סמסטר שלם. ובכל זאת, אולי זה יועיל לנו כפי שמתבטא מהtest RMSE.</p>
<p>ומסתבר שכן, בדוגמא הזאת, אם אנחנו משתמשים בכל 99 הסרטים בהצבת אפס במקום ערכים חסרים הRMSE כבר יורד מתחת ל0.8.</p>
<p>כעת כשראיתם כבר את השורה התחתונה נדבר על איך בעצם מוצאים את המקדמים של הרגרסיה ליניארית, את הבטאות.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="linear-regression---fitting-the-model" class="slide level2 title-slide center">
<h2>Linear Regression - Fitting the Model</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אז איך מתאימים מודל רגרסיה ליניארית. נראה את זה קודם מההיבט האלגברי, טכני. ניתן גם פירוש גיאומטרי. לבסוף נדבר על רגרסיה ליניארית מההיבט הסטטיסטי.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="least-squares-regression-fitting-the-model">Least squares regression: fitting the model</h3>
<ul>
<li><p>Let’s start from the simple case <span class="math inline">\(p=1\)</span>: one feature (Sweet Home Alabama) + constant/intercept</p></li>
<li><p>Finding the coefficients: <span class="math display">\[\min_{\beta_0,\beta_1} \sum_{i=1}^n (y_i - (\beta_0+\beta_1 x_i))^2\]</span></p></li>
</ul>
<div class="fragment">
<ul>
<li>Solution (we won’t prove here): <span class="math display">\[\hat{\beta}_1 = \frac{\sum_i (x_i - \bar{x})(y_i - \bar{y})}{\sum_i (x_i - \bar{x})^2} = \frac{\widehat{Cov(X,Y)}}{\widehat{Var(X)}},\;\;\;\;\hat{\beta}_0 = \bar{y} - \hat{\beta}_1 \bar{x}\]</span></li>
</ul>
</div>
<div class="fragment">
<p>Does <span class="math inline">\(\hat{\beta}_1\)</span> look familiar?</p>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נתחיל במקרה הפשוט של משתנה אחד בX, למשל הסרט סוויט הום אלבמה, ועוד חותך. כך נראה הקריטריון למינימיזציה, הRSS, ואנחנו רוצים לעשות לו מינימום לפי המקדמים בטא-אפס, ובטא-אחת.</p>
<p>זאת בעיה יחסית פשוטה מחשבון דיפרנציאלי ואינטגרלי, אתם יכולים לגזור את הכמות הזאת לפי בטא אחת, להשוות לאפס, ולמצוא את הפתרון שלפנינו. לאחר מכן תגזרו לפי בטא-אפס, תשוו לאפס ותמצאו את הביטוי שיש לנו כאן: ממוצע הY פחות ממוצע הX כפול האומד לבטא-אחת. לבסוף כדי לוודא שזאת אכן נקודת מינימום תצטרכו כמובן להביט על כל מטריצת הנגזרות השניות ולוודא שהיא חיובית, פוזיטיב דפיניט.</p>
<p>ואם האומד לבטא-אחת נראה לכם מוכר, אתם לא טועים, מדובר בנוסחה קרובה מאוד למקדם המתאם של פירסון המוכר. בתרגול תראו את הקשר בין השניים ובאילו מקרים הם יהיו זהים, כלומר שיפוע המודל הליניארי יהיה ממש מקדם המתאם בין X לY.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="general-algebric-solution-for-any-p">General algebric solution for any <span class="math inline">\(p\)</span></h3>
<ul>
<li>Write our problem in matrix-vector notation (now <span class="math inline">\(\beta \in \mathbb{R}^{p+1}\)</span> is vector of coefficients): <span class="math display">\[\min_{\beta} RSS(\beta) = \min_{\beta} \|Y- X\beta\|^2\]</span></li>
</ul>
<div>
<ul>
<li class="fragment"><p>This is a quardratic function of <span class="math inline">\(\beta\)</span>, find minimizer by differentiating and equating to zero. Normal equations: <span class="math display">\[-2X^T (Y-X\beta) = 0\]</span></p></li>
<li class="fragment"><p>This looks scary, but it simply means: <span class="math display">\[\frac{\partial RSS(\beta)}{\partial \beta_j}=\sum_{i=1}^n x_{ij} \left(y_i- (\beta_0 + \sum_{k=1}^p x_{ik} \beta_k)\right) = 0,\;\;j=0,\ldots,p\]</span></p></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אם אנחנו רוצים להכליל לp משתנים מומלץ לכתוב את הRSS בכתיב וקטורי.</p>
<p>אם נגזור ונשווה לאפס נקבל את מה שמכונה המשוואות הנורמליות.</p>
<p>ושוב, לאלו שפחות מתחברים לכתיבה של סט משוואות בכתיב וקטורי, אפשר להראות שבסופו של דבר מדובר בסט של משוואות מהצורה הזאת, גזירה של כמות לפי אחד המקדמים בוקטור בטא, והשוואה לאפס. p + 1 משוואות כאלה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<ul>
<li><p>The problem: <span class="math display">\[-2X^T (Y-X\beta) = 0\]</span></p></li>
<li><p>The solution: <span class="math display">\[X^TX\beta = X^T Y \;\;\Rightarrow\;\; \hat{\beta} = (X^TX)^{-1} X^T Y.\]</span> (the second derivative matrix is positive definite <span class="math inline">\(\Rightarrow\)</span> minimum)</p></li>
</ul>
<div class="fragment">
<ul>
<li>For <span class="math inline">\(p=1\)</span> we would recover back exactly the formulas from before</li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אנחנו פותחים את הסוגריים, מחלקים פי 2, ומגיעים לפתרון הריבועים הפחותים, נוסחה שכדאי להכיר בעל-פה. ושוב, מטריצת הנגזרות השניות היא פוזיטיב דפיניט, לכן אנחנו יודעים שזוהי נקודת מינימום.</p>
<p>תרגיל פשוט למי שרוצה אתגר: עבור p = 1, הראו שפתרון הריבועים הפחותים הוא בדיוק הנוסחאות הספציפיות לבטא-אפס ולבטא-אחת שראינו.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="a-geometric-view">A geometric view</h3>
<ul>
<li><p>The columns of the matrix <span class="math inline">\(X_{n\times (p+1)}\)</span> are vectors <span class="math inline">\(X^c_0, \dots, X^c_p \in \mathbb{R}^n.\)</span><br>Each feature in <span class="math inline">\(Tr\)</span> is such a vector.</p></li>
<li><p>The response vector in <span class="math inline">\(Tr\)</span> is <span class="math inline">\(Y_{n \times 1}\)</span>, which is also a vector in <span class="math inline">\(\mathbb{R}^n\)</span>.</p></li>
</ul>
<div>
<ul>
<li class="fragment"><p><span class="math inline">\(X\beta = X^c_0 \beta_0 + \dots +X^c_p \beta_p\)</span> is a linear combination of the columns.</p></li>
<li class="fragment"><p>Hence, in <span class="math inline">\(\min_\beta \| Y-X\beta\|^2\)</span> we are seeking a linear combination of the columns which is closest to <span class="math inline">\(Y\)</span> in <span class="math inline">\(\text{Span}(X^c_0, \dots ,X^c_p)\)</span>.</p></li>
</ul>
</div>
<div class="fragment">
<p><span class="math inline">\(\Rightarrow\)</span> OLS is an <em>orthogonal projection</em> of <span class="math inline">\(Y\)</span> on the column space of <span class="math inline">\(X\)</span></p>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>חשוב להכיר גם את הפרשנות הגיאומטרית של הפתרון שלנו: הרי כרגע במרחב הלמידה העמודות של X פורסות איזשהו מרחב, וY הוא גם וקטור, נוסף.</p>
<p>אנחנו רוצים למצוא צירוף ליניארי של העמודות האלה של X, זו המשמעות של הביטוי X</p>
<p>לכן כשאנחנו עושים מינימיזציה לRSS, לכמות הזאת, אנחנו בעצם מחפשים את הצירוף הליניארי של עמודות X שהוא הקירוב הטוב ביותר לY. הפתרון שלנו הוא הוקטור הכי קרוב במרחב הנפרש על-ידי עמודות X, לוקטור Y שכנראה לא נמצא במרחב הזה. נדגים זאת על שני משתנים:</p>
<p>(הדגמה על הלוח)</p>
<p>מה זה הוקטור הזה? הוקטור הזה הוא ההטלה האורתוגונלית של הוקטור Y אל המרחב הנפרש על-ידי עמודות X!</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="linear-regression---statistical-perspective" class="slide level2 title-slide center">
<h2>Linear Regression - Statistical Perspective</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>איפה סטטיסטיקה נכנסת לפעולה? עד כאן היתה לנו רק אלגברה ליניארית וחשבון דיפרנציאלי. ומאיפה באים ערכי הטי והpvalue שראינו בפלט הרגרסיה?</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="a-statistical-model-for-inference">A statistical model for inference</h3>
<ul>
<li>So far we did not assume any specific <em>true</em> relationship between <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span></li>
</ul>
<div>
<ul>
<li class="fragment">Let us now <em>assume</em> the following model: <span class="math display">\[y = \beta_0 + \beta_1 x_1 + \ldots + \beta_p x_p + \epsilon,\;\;\epsilon \sim N(0,\sigma^2)\]</span></li>
</ul>
<ol type="1">
<li class="fragment"><span class="math inline">\(E(y|x) = x^T\beta\)</span> is a linear function of <span class="math inline">\(x\)</span></li>
<li class="fragment">The error <span class="math inline">\((y-E(y|x))\)</span> has a normal distribution and is independent for each observation</li>
</ol>
<ul>
<li class="fragment">If this assumption holds, we can investigate the distribution of <span class="math inline">\(\hat{\beta}\)</span> and use that to do inference on the model</li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נשים לב עד עכשיו שלא הנחנו שום מודל שהוא הקשר האמיתי בין X לY. לא היתה שום התפלגות, לא היו כמעט שום תנאים על פתרון הרגרסיה הOLS, ואכן רבים שאין להם נגיעה לסטטיסטיקה בכלל לומדים על רגרסיה ליניארית במסגרת קורסים באלגברה ליניארית.</p>
<p>כעת כן נניח שיש מודל, הנחה די מחמירה: שY הוא צירוף ליניארי של האיקסים, ועוד איזשהו רעש שנסמן באפסילון, משתנה מקרי, ועל הרעש הזה נניח התפלגות נורמלית. נניח שהתוספת הזאת ממורכזת באפס, ויש לה שונות, כמובן לא ידועה, של סיגמא בריבוע.</p>
<p>תיכף ניתן הערה שלא נוכיח, על מדוע התייחסות כזאת לא תשנה את פתרון הריבועים הפחותים, בטא-האט עדיין יהיה (X’X)-1X’beta. אבל בואו נגיד מה התווסף לנו:</p>
<p>כעת Y הוא משתנה מקרי. ויש לו התפלגות ותוחלת, בהינתן האיקסים. התוחלת המותנית של Y בהינתן שהאיקסים קבועים על ערך מסוים, היא x’beta, היא פונקציה ליניארית של X.</p>
<p>הטעות שמתקבלת אם אחסר מY את התוחלת המותנית שלו היא גם משתנה מקרי, זה בעצם האפסילון, אז היא מתפלגת נורמלית, עם תוחלת אפס, ובאון בלתי תלוי בטעויות האחרות.</p>
<p>ותחת הנחת המודל הסטטיסטי גם בטא-האט יהיה וקטור של משתנים מקריים, עם התפלגות! אנחנו כבר יכולים לא רק להגיד מהו הבטא-האט אלא גם לבצע עליו הסקה סטטיסטית. נוכל להגיד האם בטא מסוים שונה בצורה מובהקת סטטיסטית מאפס, כלומר האם הוא באמת חשוב במידול של Y או לא.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h4 id="distribution-of-the-ols-solution-under-the-model-assumptions">Distribution of the OLS solution under the model assumptions</h4>
<div>
<ul>
<li class="fragment"><p>What we know: <span class="math display">\[(a)\; E(Y) = X\beta,\;\;\;\; (b)\; Cov(Y) = \sigma^2 I_n ,\;\;\;\;(c)\; \hat{\beta} = (X^TX)^{-1} X^T Y\]</span></p></li>
<li class="fragment"><p>Mean: <span class="math display">\[E(\hat{\beta}) \stackrel{(c)}{=} (X^TX)^{-1} X^T E(Y) \stackrel{(a)}{=} (X^TX)^{-1} X^T X\beta = \beta.\]</span></p></li>
<li class="fragment"><p>Covariance matrix: <span class="math display">\[Cov(\hat{\beta}) \stackrel{(c)}{=} (X^TX)^{-1} X^T Cov(Y) X (X^TX)^{-1} \stackrel{(b)}{=} \sigma^2 (X^TX)^{-1} (X^T X) (X^TX)^{-1} = \sigma^2 (X^TX)^{-1}.\]</span></p></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אנחנו רוצים למצוא את ההתפלגות של האומד בטא האט. בטא-האט הוא צירוף לינארי של משתנים נורמליים ולכן גם הוא, מתפלג נורמלית, עם איזשהו וקטור תוחלות ומטריצת שונויות (להדגים). השאלה היחידה היא מהו וקטור התוחלות ומטריצת השונויות האלה.</p>
<p>מה ידוע לנו עד כה? התוחלת המותנית של Y היא X בטא. הYים בלתי תלויים, מטריצת השונויות שלהם היא אלכסונית עם סיגמא בריבוע על האלכסון, ניתן לסמן זאת כך. והאומד לבטא-האט נראה כך, הוא לא משתנה כאמור בעקבות ההנחה הסטטיסטית.</p>
<p>התוחלת של בטא-האט: האיקסים הם קבועים, ומליניאריות התוחלת הם יוצאים החוצה ונשארת רק התוחלת של Y, שהיא כידוע X בטא, וכך אנחנו מגיעים לעבודה שהתוחלת של בטא-האט היא בטא עצמו, בטא-האט נקרא אומד חסר הטיה לבטא.</p>
<p>ומטריצת השונות או הקווריאנס של וקטור בטא-האט: כשמחשבים שונות של סקלאר כפול משתנה הסקלאר יוצא בריבוע. כשמחשבים מטריצת שונות של מטריצת קבועים כפול הוקטור שלנו, היא יוצאת בהכפלה משמאל ומימין. אבל מטריצת השונות של Y היא כאמור אלכסונית, וכל מה שנשאר זה הכפלה של הביטוי הזה בסיגמא בריבוע. דברים מצטמצמים ומגיעים לביטוי סופי, סיגמא בריבוע כפול המטריצה ההופכית של X’X.</p>
<p>נסכם: בטא-האט מתפלג נורמלית עם תוחלת בטא האמיתית, ושונות סיגמא בריבוע כפול מטריצת X’X.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="statistical-inference">Statistical inference</h3>
<div>
<ul>
<li class="fragment"><p>From the previous formulas we conclude: <span class="math inline">\(\hat{\beta}_j \sim N(\beta_j, \sigma^2 (X^TX)^{-1}_{j,j}).\)</span></p></li>
<li class="fragment"><p>Recall that our second goal (beyond prediction) was <em>inference</em>: which variables are important?</p></li>
<li class="fragment"><p>Now we can formalize this as a hypothesis test: for each variable <span class="math inline">\(j\)</span>, test the null <span class="math inline">\(H_{0j}: \beta_j = 0.\)</span></p></li>
<li class="fragment"><p>If <span class="math inline">\(H_{0j}\)</span> holds, then <span class="math inline">\(\hat{\beta}_j \sim N(0, \sigma^2 (X^TX)^{-1}_{j,j}).\)</span></p></li>
<li class="fragment"><p>Assuming <span class="math inline">\(\sigma^2\)</span> is known, this leads to a simple <span class="math inline">\(Z\)</span>-test as we studied</p></li>
<li class="fragment"><p>Since <span class="math inline">\(\sigma^2\)</span> is not known, we need to estimate it and get a T-test instead (details omitted).</p></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אז איך מבצעים הסקה סטטיסטית על הבטאות?</p>
<p>באופן שולי ניתן לראות שכל בטא-האט-ג’י בוקטור מתפלג נורמלית עם תוחלת בטא-ג’יי ושונות שהיא סיגמא בריבוע, כפול האיבר האלכסון במטריצת X’X.</p>
<p>זה אומר שעכשיו אנחנו יכולים לבצע בדיקת השערות על כל בטא-ג’יי: השערת האפס תהיה שבטא-ג’יי שווה לאפס. ההשערה האלטרנטיבית, תהיה כמעט תמיד דו-צדדית, שבטא-ג’יי שונה מאפס, כלומר המשתנה הזה חשוב במודל.</p>
<p>תחת השערת האפס ההתפלגות של בטא-האט-ג’יי היא נורמלית עם אותה שונות אבל עם תוחלת אפס,</p>
<p>אם היינו יודעים את השונות סיגמא בריבוע זה כל מה שאנחנו צריכים בשביל מבחן Z. אנחנו לא יודעים את השונות סיגמא בריבוע ולכן אנחנו עושים מבחן T.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h4 id="back-to-the-14-movies-model-now-with-the-inference">Back to the 14-movies model, now with the inference:</h4>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.276
Model:                            OLS   Adj. R-squared:                  0.275
Method:                 Least Squares   F-statistic:                     217.8
Date:                Sat, 05 Aug 2023   Prob (F-statistic):               0.00
Time:                        11:07:05   Log-Likelihood:                -9715.2
No. Observations:                8000   AIC:                         1.946e+04
Df Residuals:                    7985   BIC:                         1.957e+04
Df Model:                          14                                         
Covariance Type:            nonrobust                                         
============================================================================================
                               coef    std err          t      P&gt;|t|      [0.025      0.975]
--------------------------------------------------------------------------------------------
const                        0.3707      0.090      4.115      0.000       0.194       0.547
Independence Day             0.0636      0.013      4.780      0.000       0.038       0.090
The Patriot                 -0.0226      0.012     -1.920      0.055      -0.046       0.000
The Day After Tomorrow       0.0445      0.011      4.081      0.000       0.023       0.066
Pirates of the Caribbean     0.0765      0.012      6.380      0.000       0.053       0.100
Pretty Woman                 0.1616      0.012     13.861      0.000       0.139       0.184
Forrest Gump                -0.0663      0.013     -4.944      0.000      -0.093      -0.040
The Green Mile               0.0294      0.014      2.154      0.031       0.003       0.056
Con Air                      0.0835      0.012      6.767      0.000       0.059       0.108
Twister                      0.0908      0.012      7.680      0.000       0.068       0.114
Sweet Home Alabama           0.2195      0.011     19.974      0.000       0.198       0.241
Pearl Harbor                 0.0352      0.011      3.323      0.001       0.014       0.056
Armageddon                  -0.0010      0.013     -0.078      0.938      -0.026       0.024
The Rock                    -0.0160      0.013     -1.241      0.215      -0.041       0.009
What Women Want              0.1493      0.011     13.029      0.000       0.127       0.172
==============================================================================
Omnibus:                      145.057   Durbin-Watson:                   1.984
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              154.185
Skew:                          -0.321   Prob(JB):                     3.31e-34
Kurtosis:                       3.225   Cond. No.                         150.
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>לא ניכנס לפרטים, בקורס לנו לא תצטרכו לעשות מבחן טי ידני על הבטאות, אבל אתם כן מבינים כעת הרבה יותר מהפלט רגרסיה של statsmodels שראינו קודם.</p>
<p>(הדגמה על הפלט)</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="ols-regression-summary">OLS regression summary</h3>
<ul>
<li><p>Minimize RSS on <span class="math inline">\(Tr\)</span> to find the “best” linear fit for <span class="math inline">\(Y\)</span> as a function of <span class="math inline">\(X\)</span></p></li>
<li><p>Algebraic solution, geometric interpretation: projection</p></li>
<li><p>Under the assumed statistical model (strong assumptions!) can do inference on which variables are important</p></li>
<li><p>The most important tool in the statistical/predictive modeling toolbox!</p></li>
<li><p>Learn more: Statistical Models course in Statistics</p></li>
</ul>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נסכם, ואז ניתן שתי הערות:</p>
<p>כדי לקבל את אומד הריבועים הפחותים אנחנו עושים מינימיזציה של הRSS, סכום השגיאות הריבועיות על מדגם הטריין, וזה יביא לנו את הצירוף הליניארי הטוב ביותר של X כדי להתקרב לוקטור Y.</p>
<p>הפתרון הוא אלגברי לחלוטין, והפירוש הגיאומטרי שלו הוא בעצם איך נראית ההטלה של הוקטור Y על המרחב שנפרש על-ידי X.</p>
<p>המודל הסטטיסטי בעצם מאפשר לנו לבצע הסקה סטטיסטית על המקדמים בבטא ולתת אמירות כמו המשתנה חשוב או לא חשוב למודל, כי הוא שונה או לא שונה מאפס ברמת מובהקות מסוימת.</p>
<p>זה הכלי אולי החשוב ביותר מבחינה מסורתית שיש למדען נתונים, כי המון מודלים מתחילים מהנקודה שבה הוא נגמר והוא תמיד ישמש בייסליין פשוט שבאופן מפתיע לא תמיד קל לנצח.</p>
<p>ומי שרוצה להעמיק עוד, מוזמן לקחת קורס כמו מודלים סטטיסטיים בחוג לסטטיסטיקה, ו/או לקרוא מגוון עצום של ספרים שנכתבו בנושא.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="comment-i-ols-interpretation">Comment I: OLS Interpretation</h3>
<ul>
<li>As we just saw, under the statistical model, <span class="math inline">\(E\hat{\beta} = \beta \;\Rightarrow\; E(\hat{y}|x) = x^T E (\hat{\beta}) = x^T \beta = E(y|x).\)</span></li>
</ul>
<div class="fragment">
<ul>
<li><p>Even when the model doesn’t hold, the use of RSS / squared error loss implies estimation of conditional expectation (details omitted)</p></li>
<li><p>Hence an interpretation of the OLS prediction is an <em>attempt</em> to estimate the conditional expectation <span class="math inline">\(E(y|x)\)</span></p></li>
</ul>
</div>
<div class="fragment">
<ul>
<li><p>This conditional expectation is clearly interesting: it summarizes what we learned about <span class="math inline">\(y\)</span> from seeing <span class="math inline">\(x\)</span></p></li>
<li><p>The attempt may not be successful, if the model is not so good (more on that later), but at least we know what we are trying to predict!</p></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>שתי הערות חשובות:</p>
<p>כפי שראינו, תחת המודל הסטטיסטי, האומד בטא-האט, הוא בעצם אומד חסר הטיה לבטא האמיתי. אבל זה אומר, שגם y_hat בהינתן X, התחזיות שלנו הסופיות, הן אומד חסר הטיה למודל הליניארי, לx’beta, כלומר לתוחלת של Y בהינתן X.</p>
<p>כלומר, מה שאנחנו בעצם עושים ברגרסיה ליניארית זאת אמידה של תוחלת מותנית, אפילו אם המודל לא נכון.</p>
<p>זו פרשנות נורא יפה של מה שאנחנו מנסים לעשות בבניית מודלים לחיזוי, להעריך את מה שאנחנו יודעים על Y, הסיכום שלו, בהינתן שראינו את כל המשתנים באיקס.</p>
<p>אנחנו ניקח את התוחלת המותנית של Y בהינתן X איתנו הלאה, זה מה שננסה לחזות גם במודלים אחרים, אנחנו פשוט לא נהיה מחויבים ליחס הליניארי הנוקשה הזה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="comment-ii-ols-via-likelihood">Comment II: OLS via Likelihood</h3>
<ul>
<li><p>Recall the assumed model: <span class="math display">\[y = \beta_0 + \beta_1 x_1 + \ldots + \beta_p x_p + \epsilon,\;\;\epsilon \sim N(0,\sigma^2)\]</span></p></li>
<li><p>An alternative criterion to <em>maximize</em> in order to get <span class="math inline">\(\hat{\beta}\)</span>: the Likelihood of the data <span class="math display">\[L(\beta|X, y) = \prod_{i = 1}^n{f(y_i|X;\beta)}\]</span></p></li>
<li><p>The <span class="math inline">\(f\)</span> being the Normal distribution density</p></li>
<li><p>This can be shown to give the exact same solution to <span class="math inline">\(\hat{\beta}\)</span>!</p></li>
</ul>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>ועוד הערה ששווה לתת:</p>
<p>אפשר היה להגיע לפתרון הריבועים הפחותים גם בדרך אחרת. להתחיל בכלל במודל הסטטיסטי כפי שרשמנו אותו: Y הוא צירוף ליניארי של המשתנים ועוד רעש נורמלי בלתי תלוי. תחת ההנחה הזאת Y הוא כאמור משתנה מקרי נורמלי, ויש לו פונקצית צפיפות מוכרת. אפשר היה לנסות למקסם כמות אחרת מהRSS, שנקראת נראות או likelihood, והיא מכפלת הצפיפויות.</p>
<p>הדבר המדהים הוא, שזה היה מביא אותנו לאותו פתרון ריבועים פחותים לבטא-האט! אנחנו נראה שוב את הנראות בקרוב, ובאופן כללי אמידת נראות מקסימלית היא שיטה סטטיסטית מקובלת ומצוינת לקבל אומדים כשמניחים התפלגות מסוימת, לאו דווקא נורמלית, כמו כאן.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="logistic-regression" class="slide level2 title-slide center">
<h2>Logistic Regression</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>התחלנו ברגרסיה, כשY הוא ממשי, ונעבור עכשיו לקלאסיפיקציה, כשY קטגוריאלי.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="what-about-classification">What about classification?</h3>
<ul>
<li><p>We will focus on the simplest (and most important) case of two-class classification:</p>
<ul>
<li>Impressionist vs.&nbsp;realist</li>
<li>Sick vs healthy</li>
<li>Buy vs don’t buy</li>
</ul></li>
<li><p>As before, we have <span class="math inline">\(Tr = (X,Y)\)</span> of size <span class="math inline">\(n\)</span>, <span class="math inline">\(Te\)</span> of size <span class="math inline">\(m\)</span>.</p></li>
<li><p>For now, keep assuming <span class="math inline">\(x \in \mathbb{R}^p\)</span> is numeric as in the wikiart paintings example</p></li>
</ul>
<div class="fragment">
<ul>
<li>Can we use the OLS mechanism we have built to build a classification model?</li>
</ul>
</div>
<div class="fragment">
<ul>
<li>For sure we can, if we encode <span class="math inline">\(y=\text{impressionist} \Rightarrow y=1,\;\;y=\text{realist} \Rightarrow y=0\)</span>, we have numeric <span class="math inline">\(y\)</span></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נתמקד בבעיה הפשוטה שY הוא אחת משתי קטגוריות אפשריות, כלומר הוא בינארי, ובתרגול תדברו קצת יותר על Y שיש לו יותר משתי קטגוריות.</p>
<p>דוגמאות לY בינארי יכולות להיות כאמור למדל האם יש לנו ציור אימפרסיוניסטי או ריאליסטי, האם האדם נשא של נגיף או לא, האם צרכנית תקנה או לא תקנה מוצר כלשהו.</p>
<p>אנחנו עדיין ממדלים באמצעות הטריין סט, מדגם הלמידה בגודל n שמורכב מזוגות תצפיות של X ושל Y. ונניח גם שהאיקסים שלנו ממשיים, בתרגול תיתקלו גם באיקסים קטגוריאליים.</p>
<p>אז נשאלת השאלה: האם ניתן להשתמש בכל התוצאות שלנו מרגרסיה ליניארית עבור Y שהוא קטגוריאלי עם שתי קטגוריות?</p>
<p>התשובה היא שברור שכן, פשוט צריך להפוך אותו לנומרי, נגדיר שאימפרסיוניסטי זה 1, וריאליסטי זה 0, והנה יש לנו Y ממשי וכל הפונקציות הרלוונטיות בפייתון יעבדו. לא נקבל שגיאה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="what-is-wrong-with-using-ols-for-classification">What is wrong with using OLS for classification?</h3>
<ul>
<li>If we encode <span class="math inline">\(y\)</span> as above what is <span class="math inline">\(E(y|x)\)</span>? It is <span class="math inline">\(P(y=\text{impressionist}|\;\text{image})\)</span> — a clearly interesting quantity</li>
</ul>
<div class="fragment">
<ul>
<li><p>Problem: as a probability, <span class="math inline">\(0\leq P(y=\text{impressionist}|\;\text{image}) \leq 1.\)</span> But model predictions <span class="math inline">\(x^T\hat{\beta}\)</span> can fall outside the legal range!</p></li>
<li><p>Another problem: can we make the model assumptions of normal <span class="math inline">\(\epsilon\)</span>? No — because <span class="math inline">\(y\)</span> can only be <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span></p></li>
</ul>
</div>
<div class="fragment">
<ul>
<li>The idea: try to create an approach that is similar to OLS, but more fitting for classification, taking into account the limited range of values and the need for a sensible statistical model</li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אז איפה פה בכל זאת השגיאה, למה זה לא פתרון טבעי לבעיה?</p>
<p>נזכור שמה אנחנו ממדלים בעצם ברגרסיה ליניארית? את התוחלת המותנית של Y בהינתן X, את מה שלמדנו על Y בממוצע בעקבות המידע על המשתנים האחרים. ומה זו התוחלת של משתנה שיש לו שתי תוצאות, אפס או 1? כמו משתנה ברנולי, זו ההסתברות שהוא יקבל 1 או ההסתברות שהציור הוא ריאליסטי בדוגמא שלנו בהינתן שראינו את הפיקסלים בתמונה.</p>
<p>זה מצוין. אבל הסתברות היא כמות בין אפס לאחת! ואין שום אילוץ ברגרסיה ליניארית לקבל תחזיות בין אפס לאחת. נוכל לקבל חיזויים קטנים מאפס, גדולים מאחת, ונוכל לקבל אפילו סט של תחזיות שכולן מתחת לאפס או כולן מעל 1. ואז מה נעשה?</p>
<p>ניתקל בעוד בעיה כשנרצה לבצע הסקה סטטיסטית: האם סביר להניח שY הוא צירוף ליניארי של משתנים ועוד רעש נורמלי, אפסילון, בלתי תלוי? לא, כי וואי מקבל ערכים אפס או אחת.</p>
<p>אז אנחנו צריכים גישה אחרת. גישה שכן תתחשב בערכים האפשריים שY יכול לקבל ושתתאים מודל סטטיסטי הולם לבעיה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="logistic-regression-1">Logistic regression</h3>
<ul>
<li><p>Deals with the two problems above</p></li>
<li><p>We start from assuming a model: <span class="math display">\[\log\frac{P(y=1|x)}{P(y=0|x)} = \log\frac{P(y=1|x)}{1 - P(y=1|x)} = \text{logit}(P(y=1|x)) = x^T\beta\]</span></p></li>
<li><p>Notice that now all values are legal: <span class="math display">\[ 0\leq P(y=1|x) \leq 1 \;\; \Leftrightarrow\;\; -\infty \leq \log\frac{P(y=1|x)}{P(y=0|x)} \leq \infty.\]</span></p></li>
</ul>
<div class="fragment">
<ul>
<li>Another way of writing this: <span class="math display">\[P(y=1|x) = \frac{\exp(x^T\beta)}{1+\exp(x^T\beta)} \quad\quad P(y=0|x) = 1- P(y=1|x) = \frac{1}{1+\exp(x^T\beta)}\]</span></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>גישה כזאת היא רגרסיה לוגיסטית.</p>
<p>אנחנו לא ממדלים את Y עצמו כמודל ליניארי. אלא את הכמות הבאה: לוג, של ההסתברות שY שווה 1, חלקי ההסתברות שY שווה אפס. הכמות הזאת היא תהיה צירוף ליניארי של המשתנים באיקס. ניתן גם לרשום את זה כלוג של ההסתברות p חלקי 1 פחות p, כך שאנחנו רואים שבמקום למדל את התוחלת של Y בהינתן X אנחנו ממדלים איזושהי פונקציה G שלה. הפונקציה הזאת די מפורסמת וקוראים לה גם לוג’יט.</p>
<p>מכל מקום כעת הכמות שאנחנו ממדלים היא בין מינוס אינסוף לאינסוף ולכן כל חיזוי שלנו יהיה כמות לגיטימית.</p>
<p>אם יש לנו את המקדמים ואנחנו רוצים לקבל בחזרה את ההסתברות החזויה, את הכמות בין אפס לאחת, אפשר לראות שהפונקציה ההופכית נראית כך: e בחזקת הצירוף הליניארי, חלקי 1 ועוד e בחזקת הצירוף הליניארי. או ההסתברות המשלימה עם נוסחה קצת יותר נעימה שמופיעה כאן.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="fitting-a-logistic-regression">Fitting a logistic regression</h3>
<ul>
<li><p>Given training data <span class="math inline">\(Tr\)</span>, we want to find the best coefficients <span class="math inline">\(\hat{\beta}\)</span></p></li>
<li><p>This is done by maximum likelihood, finding <span class="math inline">\(\beta\)</span> to maximize: <span class="math display">\[L(\beta|X, y) = \prod_{i = 1}^n{P(y_i|x_i;\beta)} = \prod_{i = 1}^n{P(y_i = 1|x_i;\beta)^{y_i}P(y_i = 0|x_i;\beta)^{1-y_i}}\]</span></p></li>
</ul>
<div class="fragment">
<p><span class="math display">\[\max_\beta \prod_{i=1}^n  \left(\frac{\exp(x_i^T\beta)}{1+\exp(x_i^T\beta)}\right)^{y_i} \left(\frac{1}{1+\exp(x_i^T\beta)}\right)^{1-y_i}\]</span></p>
</div>
<div>
<ul>
<li class="fragment"><p>The solution is <span class="math inline">\(\hat{\beta}\)</span>, the logistic regression coefficients estimates</p></li>
<li class="fragment"><p>Predicting on <span class="math inline">\(x \in Te\)</span>: <span class="math display">\[\widehat{P(y=1|x)} = \frac{\exp(x^T\hat{\beta})}{1+\exp(x^T\hat{\beta})}\;\; \Rightarrow\;\; \hat{y} = \begin{cases} 1 &amp; \mbox{if } \widehat{P(y=1|x)}&gt; 0.5 \\
0 &amp; \mbox{otherwise}\end{cases}\]</span></p></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אז אנחנו מוצאים את המקדמים במקרה של רגרסיה לוגיסטית?</p>
<p>כאן אנחנו חייבים לעבור דרך פונקצית הנראות, הlikelihood ולבצע אמידת נראות מקסימלית. פונקצית הנראות שלנו היא פונקציה של בטא בהינתן הדאטא בטריינינג ומסומנת בדרך כלל בL. במקרה הבדיד כמו לפנינו שY הוא בעצם משתנה ברנולי, מדובר במכפלת ההסתברויות במדגם תחת המודל.</p>
<p>מאחר שY מקבל ערכים אפס או אחת, ניתן לרשום את הביטוי בצורה כזאת. נציב את הביטויים של מודל הרגרסיה הלוגיסטית עבור ההסתברות שוואי שווה אחת ועבור ההסתברות שוואי שווה אפס. ונגיע לא ביטוי לא סימפטי אבל מפורש, שצריך למקסם כדי לקבל את בטא-האט.</p>
<p>כשנקבל את בטא-האט, ותגיע תצפית חדשה ממדגם הטסט, נוכל לחזות את ההסתברות שהיא אחת באמצעות הצבה בנוסחה של הפונקציה ההופכית. ואם אנחנו רוצים סופי, האם Y הוא 1 או 0, אפשר להשוות את ההסתברות הנחזית לאיזשהו קאטאוף, לדוגמא חצי. אם היא גדולה מחצי נחזה 1, ואם לא נחזה 0.</p>
<p>הערה לפני שממשיכים: זה לא סתם שלא רשמנו כאן ביטוי מפורש לבטא-האט, הסיבה שאין כזה. פונקצית הנראות אמנם מפורשת וקמורה אבל אין לה פתרון סגור, לכן משתמשים בשיטות אופטימיזציה כמו ניוטון רפסון למי שמכיר, כדי למצוא את המקדמים.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="interpretation-of-coefficients">Interpretation of coefficients</h3>
<ul>
<li><p>We can write our model as: <span class="math display">\[\log\frac{P(y=1|x)}{P(y=0|x)} = x^T\beta\]</span></p></li>
<li><p>The expression on the left is called the <em>log odds</em>: log of the ratio of positive vs negative probability</p></li>
<li><p>Interpretation: <span class="math inline">\({\beta}_j\)</span> is the change in the log odds from a change of 1 unit in <span class="math inline">\(x_j\)</span>.</p></li>
</ul>
<div class="fragment">
<ul>
<li>For example, if <span class="math inline">\({\beta}_j=1\)</span> then when <span class="math inline">\(x_j=1\)</span> vs <span class="math inline">\(x_j=0\)</span> the log odds increase by <span class="math inline">\(1\)</span>, so the odds increase times <span class="math inline">\(e=2.72\)</span>, which is roughly the increase in <span class="math inline">\({P(y=1|x)}\)</span> when it is close to <span class="math inline">\(0\)</span>.</li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>הפרשנות של מקדמי הבטא ברגרסיה לוגיסטית הרבה פחות פשוטה לעומת רגרסיה ליניארית, ועלולה לבלבל, אז נשים לב:</p>
<p>ועוד מילה על המודל שלנו. יחס הסיכויים שאנחנו ממדלים הוא בעצם הodds. בשפה יומיומיות, אם מאורע יכול לקרות בסיכוי שליש, או לא לקרות בסיכוי שני שליש, אנחנו אומרים “הוא יקרה בסיכוי של 1 ל-2”. כלומר מה שאנחנו ממדלים כצירוף ליניארי הוא הלוג-אודז, לוג יחס הסיכויים.</p>
<p>אז מה המשמעות של מקדם בטא-ג’יי? עלייה של יחידה אחת בXj, פירושה עלייה של בטא-ג’יי בלוג אודז.</p>
<p>ואם זה לא אומר הרבה, קחו את האקספוננט של בטא-ג’יי ותראו מה הוא עושה לאודז עצמו. עלייה של בטא-ג’יי בגודל 1 היא עלייה פי e של האודז עצמו.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="example-saheart" class="slide level2 title-slide center">
<h2>Example: SAHeart</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נראה כעת דוגמא של רגרסיה לוגיסטית על דאטא קטן שמתאים לבעיה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="example-south-african-hearth-disease-data">Example: South African Hearth Disease Data</h3>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>saheart <span class="op">=</span> pd.read_table(<span class="st">"../datasets/SAheart.data"</span>, header <span class="op">=</span> <span class="dv">0</span>, sep<span class="op">=</span><span class="st">','</span>, index_col<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(saheart.describe())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              sbp     tobacco         ldl   adiposity       typea     obesity  \
count  462.000000  462.000000  462.000000  462.000000  462.000000  462.000000   
mean   138.326840    3.635649    4.740325   25.406732   53.103896   26.044113   
std     20.496317    4.593024    2.070909    7.780699    9.817534    4.213680   
min    101.000000    0.000000    0.980000    6.740000   13.000000   14.700000   
25%    124.000000    0.052500    3.282500   19.775000   47.000000   22.985000   
50%    134.000000    2.000000    4.340000   26.115000   53.000000   25.805000   
75%    148.000000    5.500000    5.790000   31.227500   60.000000   28.497500   
max    218.000000   31.200000   15.330000   42.490000   78.000000   46.580000   

          alcohol         age         chd  
count  462.000000  462.000000  462.000000  
mean    17.044394   42.816017    0.346320  
std     24.481059   14.608956    0.476313  
min      0.000000   15.000000    0.000000  
25%      0.510000   31.000000    0.000000  
50%      7.510000   45.000000    0.000000  
75%     23.892500   55.000000    1.000000  
max    147.190000   64.000000    1.000000  </code></pre>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בנתונים שלפנינו יש 462 גברים מדרום אפריקה. יש לנו מידע רפואי עליהם כמו לחץ דם, מידת העישון, צריכת אלכוהול וגיל, והמשתנה שיעניין אותנו הוא הchd, coronary heart disease, האם הם לקו בהתקף לב או לא.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="saheart-data-splitting-with-sklearn">SAHeart: Data Splitting with <code>SKlearn</code></h3>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb22" data-code-line-numbers="|4-6|"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1"></a>saheart_X<span class="op">=</span>pd.get_dummies(saheart.iloc[:, :<span class="dv">9</span>]).iloc[:, :<span class="dv">9</span>]</span>
<span id="cb22-2"><a href="#cb22-2"></a>saheart_y<span class="op">=</span>saheart.iloc[:, <span class="dv">9</span>]</span>
<span id="cb22-3"><a href="#cb22-3"></a></span>
<span id="cb22-4"><a href="#cb22-4"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb22-5"><a href="#cb22-5"></a></span>
<span id="cb22-6"><a href="#cb22-6"></a>Xtr, Xte, Ytr, Yte <span class="op">=</span> train_test_split(saheart_X, saheart_y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb22-7"><a href="#cb22-7"></a></span>
<span id="cb22-8"><a href="#cb22-8"></a><span class="bu">print</span>(<span class="ss">f'No. of train rows: </span><span class="sc">{</span>Xtr<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">, no. train of cols: </span><span class="sc">{</span>Xtr<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb22-9"><a href="#cb22-9"></a><span class="bu">print</span>(<span class="ss">f'No. of test rows: </span><span class="sc">{</span>Xte<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">, no. test of cols: </span><span class="sc">{</span>Xte<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb22-10"><a href="#cb22-10"></a><span class="bu">print</span>(<span class="ss">f'no. of obs in train y: </span><span class="sc">{</span>Ytr<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb22-11"><a href="#cb22-11"></a><span class="bu">print</span>(<span class="ss">f'no. of obs in test y: </span><span class="sc">{</span>Yte<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>No. of train rows: 369, no. train of cols: 9
No. of test rows: 93, no. test of cols: 9
no. of obs in train y: 369
no. of obs in test y: 93</code></pre>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נגדיר את מטריצת הX שלנו ואת הY. יש לנו כאן משתנה קטגוריאלי שמצריך טיפול מיוחד עם הפונקציה get_dummies, ולא ניכנס לזה כרגע.</p>
<p>מכל מקום אנחנו רוצים לחלק את הדאטאט לטריין וטסט. עשינו את זה ידנית עם הדאטא של נטפליקס, בואו נשתמש כאן בפונקציה מקובלת מספריית sklearn, הפונקציה train_test_split, שמקבלת את מטריצת הX, את הוקטור Y, את גודל מדגם הטסט כמספר עשרוני, כאן עשרים אחוז, וגם איזשהו סיד כדי שההקצאה האקראית תישמר בריצות חוזרות. מה שמתקבל הוא X טריין, X טסט, Y טריין, Y טסט.</p>
<p>והנה אנחנו מדפיסים את גודל הדאטא, בשורה התחתונה יש לנו p = 9 משתנים.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="saheart-lr-with-statsomdels">SAHeart: LR with <code>statsomdels</code></h3>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.Logit(Ytr, sm.add_constant(Xtr))</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> model.fit()</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell fragment" data-execution_count="16">
<div class="cell-output cell-output-stdout">
<pre><code>Optimization terminated successfully.
         Current function value: 0.513971
         Iterations 6
                           Logit Regression Results                           
==============================================================================
Dep. Variable:                    chd   No. Observations:                  369
Model:                          Logit   Df Residuals:                      359
Method:                           MLE   Df Model:                            9
Date:                Sat, 05 Aug 2023   Pseudo R-squ.:                  0.1994
Time:                        11:07:05   Log-Likelihood:                -189.66
converged:                       True   LL-Null:                       -236.90
Covariance Type:            nonrobust   LLR p-value:                 2.041e-16
==================================================================================
                     coef    std err          z      P&gt;|z|      [0.025      0.975]
----------------------------------------------------------------------------------
const             -5.3373      1.478     -3.612      0.000      -8.234      -2.441
sbp                0.0081      0.006      1.262      0.207      -0.004       0.021
tobacco            0.0563      0.029      1.926      0.054      -0.001       0.114
ldl                0.1676      0.064      2.599      0.009       0.041       0.294
adiposity          0.0273      0.033      0.823      0.411      -0.038       0.092
typea              0.0411      0.014      3.005      0.003       0.014       0.068
obesity           -0.0820      0.049     -1.661      0.097      -0.179       0.015
alcohol            0.0019      0.006      0.344      0.731      -0.009       0.013
age                0.0473      0.013      3.530      0.000       0.021       0.074
famhist_Absent    -0.8135      0.255     -3.191      0.001      -1.313      -0.314
==================================================================================</code></pre>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>ברגע שיודעים לבצע רגרסיה ליניארית בstatsmodels או בsklearn רגרסיה לוגיסטית זה קל.</p>
<p>פשוט מאתחלים את הקלאס Logit, מזינים לתוכו את Y טריין ואז את X טריין בתוספת חותך, וקוראים לmodel.fit.</p>
<p>אם נבקש summary נקבל פלט סטטיסטי עשיר ומסודר של המקדמים ומבחנים סטטיסטיים עליהם.</p>
<p>נשים לב שהמבחנים כאן הם מבחני Z אבל לא ניכנס בקורס הזה לסיבה לכך. מכל מקום לכל מקדם יש טעות תקן שונה, אז כדי להשוות ביניהם נסתכל על הציוני תקן, על ערכי הZ. משתנים עם ערכים גבוהים הםage למשל, הגיל. לכל שנת חיים נוספת, המודל מוסיף איזושהי כמות ללוג-אודז שהפציינט יחלה בהתקף לב. מקדם שלילי גדול הוא הfamhist_Absent, שמשמעותו האם אין לך היסטוריה משפחתית של התקף לב. אם אין, יורדת לך כמות של 0.8 מהלוג-אודז.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="saheart-lr-with-sklearn">SAHeart: LR with <code>SKlearn</code></h3>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LogisticRegression(solver<span class="op">=</span><span class="st">'lbfgs'</span>,max_iter<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>model.fit(Xtr, Ytr)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'intercept:'</span>, model.intercept_)</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'coef:'</span>, model.coef_)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>intercept: [-5.37683503]
coef: [[ 0.0080158   0.0557117   0.16737956  0.0271416   0.0410251  -0.08127558
   0.00199583  0.04753859 -0.76405442]]</code></pre>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בsklearn הקלאס שאנחנו רוצים נקרא LogisticRegression. כאן אנחנו יכולים לפרט איזשהו סולבר ומספר איטרציות, כי כאמור רגרסיה לוגיסטית מצריכה שיטות נומריות לאופטימיזציה.</p>
<p>אחרי שהגדרנו את המודל נקרא לfit, ונדפיס את המקדמים שהתקבלו. כמו ברגרסיה ליניארית, sklearn הרבה יותר מוכוון מאשין-לרנינג ולא סטטיסטיקה, אז הפלט שלו מוגבל.</p>
<p>נשים לב גם שקיבלנו מקדמים דומים ל-statsmodels אך לא זהים, כי לא מדובר בנוסחאות סגורות.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="saheart-lr-test-performance">SAHeart: LR Test Performance</h3>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb28" data-code-line-numbers="|3|4|5|"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb28-2"><a href="#cb28-2"></a></span>
<span id="cb28-3"><a href="#cb28-3"></a>p_hat_te <span class="op">=</span> model.predict_proba(Xte)[:, <span class="dv">1</span>]</span>
<span id="cb28-4"><a href="#cb28-4"></a>y_hat_te <span class="op">=</span> p_hat_te <span class="op">&gt;</span> <span class="fl">0.5</span></span>
<span id="cb28-5"><a href="#cb28-5"></a>conf <span class="op">=</span> confusion_matrix(Yte, y_hat_te)</span>
<span id="cb28-6"><a href="#cb28-6"></a></span>
<span id="cb28-7"><a href="#cb28-7"></a>pd.DataFrame(</span>
<span id="cb28-8"><a href="#cb28-8"></a>  confusion_matrix(Yte, y_hat_te),</span>
<span id="cb28-9"><a href="#cb28-9"></a>  index<span class="op">=</span>[<span class="st">'true:no'</span>, <span class="st">'true:yes'</span>], </span>
<span id="cb28-10"><a href="#cb28-10"></a>  columns<span class="op">=</span>[<span class="st">'pred:no'</span>, <span class="st">'pred:yes'</span>]</span>
<span id="cb28-11"><a href="#cb28-11"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">pred:no</th>
<th data-quarto-table-cell-role="th">pred:yes</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">true:no</td>
<td>52</td>
<td>7</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">true:yes</td>
<td>15</td>
<td>19</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="fragment">
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>acc <span class="op">=</span> np.mean(Yte <span class="op">==</span> y_hat_te)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>err <span class="op">=</span> np.mean(Yte <span class="op">!=</span> y_hat_te)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Accuracy: </span><span class="sc">{</span>acc<span class="sc">: .2f}</span><span class="ss">, Misclassification loss: </span><span class="sc">{</span>err<span class="sc">: .2f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy:  0.76, Misclassification loss:  0.24</code></pre>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אבל איך אנחנו מכמתים את הביצועים של המודל על מדגם הטסט, על זה לא דיברנו. אפשר לדווח את הנראות שאותה מיקסמנו, אבל זה לא יגיד הרבה.</p>
<p>מקובל יותר למשל לחזות את ההסתברויות p_hat על מדגם הטסט, באמצעות הנוסחה שראינו. בsklearn זה נעשה עם הפונקציה predict_proba.</p>
<p>ואז להשוות את ההתסברויות החזויות לאיזשהו קאטאוף דיפולטי של חצי. ואם אתם מודאגים מזה אתם צודקים, ותיכף נדבר על זה. זה יביא אותנו לחיזוי סופי של Y, האם הוא 0 או 1.</p>
<p>את החיזוי הזה אפשר להכניס לתוך קונפיוז’ן מטריקס או “מטריצת בלבול”, מטריצה 2 על 2 שתראה לנו, מתוך הפציינטים שהם לא חולים, כמה המודל חזה שהם כן חולים, וכמה לא. ומתוך הפציינטים שהם כן חולים, כמה המודל חזה שהם חולים וכמה לא.</p>
<p>אפשר גם לחשב מדדים אינטואיטיביים של אחוז דיוק, accuracy, ואחוז שגיאה, error. מדובר באופן כללי באחוז התצפיות מהטסט סט שהמודל צדק לגביהן, והאחוז שהוא טעה. כאן על נתונים שהמודל לא ראה הוא צודק ב76 אחוז וטועה ב24 אחוז.</p>
<p>בחלק האחרון של השיעור נרחיב על אווליואציה של מודלים לקלסיפיקציה, מסתבר שהמדדים שהסתכלנו עליהם כרגע יכולים להיות בעייתיים.</p>
<p>לדוגמא (להדגים), נניח ש99 אחוז מהפציינטים היו בריאים ורק אחוז אחד היו חולים. מה אם אתן לכם מודל שחוזה שכל הפציינטים הם בריאים? זה מודל נהדר, הוא יקבל אקיורסי של 99 אחוז! חייב להיות אם כן מדד טוב יותר שיעיד על כך שזה מודל גרוע.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="classification-model-evaluation" class="slide level2 title-slide center">
<h2>Classification Model Evaluation</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אז אני טוען שאחוז הaccuracy לא תמיד משקף נכון את הביצועים של המודל, וראינו שהתופעה חמורה במיוחד כשהנתונים הם מה שקרוי imbalanced, אין באוכלוסיה מספר שווה של דוגמאות חיוביות ושליליות. ואנחנו זקוקים למדדים טובים יותר.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="measuring-classification-performance">Measuring Classification Performance</h3>
<ul>
<li><p>Different errors have different costs/value.</p></li>
<li><p>Summarize performance in different ways that capture different types of errors:</p></li>
</ul>
<div class="fragment">
<table>
<thead>
<tr class="header">
<th></th>
<th>Pred</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Real</strong></td>
<td>Pos</td>
<td>Neg</td>
<td>Total</td>
</tr>
<tr class="even">
<td>Pos</td>
<td><span class="math inline">\(TP\)</span></td>
<td><span class="math inline">\(FN\)</span></td>
<td><span class="math inline">\(P\)</span></td>
</tr>
<tr class="odd">
<td>Neg</td>
<td><span class="math inline">\(FP\)</span></td>
<td><span class="math inline">\(TN\)</span></td>
<td><span class="math inline">\(N\)</span></td>
</tr>
<tr class="even">
<td>Total</td>
<td><span class="math inline">\(\hat{P}\)</span></td>
<td><span class="math inline">\(\hat{N}\)</span></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div class="fragment">
<p><span class="math inline">\(P = \sum_{i=n+1}^{n+m} y_i\)</span> number of positive examples, similarly <span class="math inline">\(N\)</span>.</p>
<p><span class="math inline">\(\hat{P} = \sum_{i=n+1}^{n+m} \hat{y}_i\)</span> number of positive predictions, similarly <span class="math inline">\(\hat{N}\)</span>.</p>
<p><span class="math inline">\(TP = \sum_{i=n+1}^{n+m} y_i \hat{y}_i\)</span> number of true positives, <span class="math inline">\(FP = \hat{P}-TP\)</span></p>
<p><span class="math inline">\(TN = \sum_{i=n+1}^{n+m} (1-y_i) (1-\hat{y}_i)\)</span> number of true negatives, <span class="math inline">\(FN = \hat{N}-TN\)</span></p>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>רמזנו בתחילת היחידה, שלטעויות שונות יכול להיות משקל שונה. לפספס חולה ולהגיד לו שהוא בריא, יכולה להיות לזה משמעות אחרת לגמרי מלהגיד לאדם בריא שהוא חולה.</p>
<p>נסמן את הכמויות בטבלת הקונפיוז’ן מטריקס בצורה כזו:</p>
<p>מספר הדוגמאות החיוביות, או חולים, באופן שולי נסמן כP. מספר הדוגמאות השליליות נסמן כN. באופן דומה, מספר החיזויים החיוביים נסמן כP_hat, ומספר החיזויים השליליים נסמן כN_hat.</p>
<p>אם המציאות היא חולה והמודל חזה חולה, זה true positive או TP. אם המציאות היא חולה והמודל חזה לא-חולה, כלומר בריא, זה false negative או FN.</p>
<p>באופן דומה מגדירים false positive וtrue negative.</p>
<p>ומי שצריך להגדיר את זה עם נוסחאות יותר פורמליות, אפשר להגדיר את כל הכמויות האלה עם y וy_hat בצורה כזאת.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<table>
<thead>
<tr class="header">
<th></th>
<th>Pred</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Real</strong></td>
<td>Pos</td>
<td>Neg</td>
<td>Total</td>
</tr>
<tr class="even">
<td>Pos</td>
<td><span class="math inline">\(TP\)</span></td>
<td><span class="math inline">\(FN\)</span></td>
<td><span class="math inline">\(P\)</span></td>
</tr>
<tr class="odd">
<td>Neg</td>
<td><span class="math inline">\(FP\)</span></td>
<td><span class="math inline">\(TN\)</span></td>
<td><span class="math inline">\(N\)</span></td>
</tr>
<tr class="even">
<td>Total</td>
<td><span class="math inline">\(\hat{P}\)</span></td>
<td><span class="math inline">\(\hat{N}\)</span></td>
<td><span class="math inline">\(m\)</span></td>
</tr>
</tbody>
</table>
<hr>
<div class="fragment">
<p>Accuracy: <span class="math inline">\(P(Correct) = \;(TN+TP)/m\)</span></p>
<p>Prediction error: <span class="math inline">\(P(Error) = \;(FN+FP)/m\)</span></p>
<p>Precision+ (positive predictive value): <span class="math inline">\(P(True + | Pred +) = \;TP/\hat{P}\)</span></p>
<p>Recall+ (sensitivity, true positive rate): <span class="math inline">\(P(Pred + | True +) = \;TP/P\)</span></p>
<p>False positive rate: <span class="math inline">\(P(Pred + | True -) = \;FP/N\)</span></p>
<p>Harmonic mean of precision and recall: <span class="math inline">\(\;F_1 = 2 \times \frac{Precision \times Recall}{Precision + Recall}\)</span></p>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>הטבלה הזאת מאפשרת לנו להסתכל על מדדים הרבה יותר ספציפיים למה שמעניין אותנו בבעיה הנתונה. נפרט אותם כעת:</p>
<p>האקיורסי כעת היא סכום התאים על האלכסון של הקונפיוז’ן מטריקס, הTP והTN, חלקי m גודל מדגם הטסט.</p>
<p>טעות הניבוי היא בדיוק סכום התאים האחרים לא על האלכסון חלקי m.</p>
<p>הפרסיז’ן הוא הסיכוי להיות חולה בהינתן שחזיתי חולה. נקרא גם positive predictive value או PPV. באופן דומה אפשר להגדיר את הפרסיז’ן לקלאס האחר, הסיכוי להיות לא-חולה אם חזיתי לא-חולה, או הnegative predictive value. בכל מקרה נרצה שהפרסיז’ן יהיה כמה שיותר גדול.</p>
<p>מדד אחר הוא הריקול, או sensitivity או true positive rate, TPR. זה הסיכוי שבהינתן חולה המודל אכן חוזה חולה, או שיעור החולים שהמודל אכן מחלץ. גם כאן ניתן לחשוב על הריקול של הקלאס האחר, אחוז הבריאים שהמודל מחלץ נכון. וגם כאן ברור שנרצה שהמדד הזה יהיה גדול ככל שניתן.</p>
<p>מדד שנרצה שיהיה קטן ככל האפשר הוא הfalse positive rate, הFPR, בהינתן לא-חולה הסיכוי לחזות חולה.</p>
<p>ומאחר שהמדדים פרסיז’ן וריקול מודדים דברים שונים והיינו רוצים ששניהם יהיו גבוהים מתסכלים לפעמים על הממוצע ההרמוני שלהם, 2 כפול המכפלה שלהם חלקי הסכום שלהם.</p>
<p>למה צריך את כל זה? בדיוק בגלל מה שאמרנו, יכול להיות לקוח של המודל שלנו, שפשוט לא מסוגל לפספס אף חולה, לקוח כזה ירצה ריקול כמה שיותר גבוה. ויכולה להיות לקוחה שאין לה בעיה לפספס חולים, אבל כשהמודל מסמן לה חולים הוא חייב להיות צודק, היא לא יכולה להעניק טיפול קשה כזה לבריאים – בשביל לקוחה כזאת נרצה אולי למקסם את הפרסיז’ן. וברור שיהיה כאן טריידאוף בין השניים במודל לא מושלם.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>  confusion_matrix(Yte, y_hat_te),</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>  index<span class="op">=</span>[<span class="st">'true:no'</span>, <span class="st">'true:yes'</span>], </span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>  columns<span class="op">=</span>[<span class="st">'pred:no'</span>, <span class="st">'pred:yes'</span>]</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">pred:no</th>
<th data-quarto-table-cell-role="th">pred:yes</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">true:no</td>
<td>52</td>
<td>7</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">true:yes</td>
<td>15</td>
<td>19</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="fragment">
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(Yte, y_hat_te))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

           0       0.78      0.88      0.83        59
           1       0.73      0.56      0.63        34

    accuracy                           0.76        93
   macro avg       0.75      0.72      0.73        93
weighted avg       0.76      0.76      0.76        93
</code></pre>
</div>
</div>
</div>
<div class="fragment">
<p>All is still based on that cutoff, 0.5!</p>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בנתונים שלנו כך נראית הקונפיוז’ן מטריקס:</p>
<p>כדי לקבל את כל המדדים שדיברנו עליהם אפשר לבקש classification_report מsklearn. נדגים לראות שהבנו.</p>
<p>למשל, הפרסיז’ן של החולים: אם חזיתי חולה או 1, מה הסיכוי שהפציינט באמת חולה: מתוך 26 חזויים כחולים, 19 אכן חולים, דיוק של 73 אחוז.</p>
<p>או, הריקול של החולים, אם אתה חולה מה הסיכוי שהמודל יחזה נכון. מתוך 34 חולים המודל צדק רק לגבי 19, שזה 56 אחוז, לא גבוה מאוד.</p>
<p>נשים לב אגב שהכל מבוסס על ערך הסף הזה שהשווינו אליו את ההסתברויות החזויות, הקאטאוף של חצי – יכול להיות שעם קאטאוף אחר היינו מקבלים מדדים טובים יותר?</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="classification-evaluation-different-goals">Classification evaluation: different goals</h3>
<p>We can think of several different prediction goals, all potentially important:</p>
<ol type="1">
<li>Classify correctly — make few (weighted) errors on test set or new prediction points</li>
<li>Predict probabilities well: <span class="math inline">\(\widehat{P(y=1|x)} \approx P(y=1|x)\)</span> for new points</li>
<li>Rank well: given multiple prediction points, predict which one is <em>more likely</em> to have <span class="math inline">\(y = 1\)</span>.</li>
</ol>
<div class="fragment">
<p>These different tasks can reflect in the loss function / model evaluation task:</p>
<ol type="1">
<li>Correct classification: misclassification loss as above, also precision, recall etc.</li>
<li>Good probability prediction: using Bernoulli loss / cross entropy: <span class="math display">\[L(y,\hat{p}) = \hat{p}^y (1-\hat{p})^{(1-y)}\]</span></li>
<li>How do we measure ranking perofrmance of a model on a test set?</li>
</ol>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>באופן כללי יכולות להיות לדאטא סיינטיסט מטרות שונות במודל קלסיפיקציה:</p>
<p>האם אני רוצה פשוט לחזות נכון.</p>
<p>האם מעניינות אותי דווקא ההסתברויות הנחזות ולדאוג שהן יהיו מכוילות כמו שיותר עם ההסתברויות המקוריות.</p>
<p>ואולי, כל מה שמעניין אותי זה הדירוג של תצפיות, מבחינת הסיכוי שהן 1 או שהפציינט חולה. לא חשוב לי אפילו אם הכמויות שאני חוזה הן הסתברויות, אלא אני מתייחס אליהן כאיזשהו סקור כללי שאני רוצה שידרג נכון את התצפיות שלי.</p>
<p>המטרה שלי משפיעה על המדד שלי לטיב המודל:</p>
<p>אם המטרה שלי היא פשוט לחזות נכון אני מסתכל על מדדים כמו אלה שראינו: אחוז דיוק, פרסיז’ן, ריקול.</p>
<p>אם המטרה שלי היא הסתברויות מכוילת כמה שיותר, אני באמת אדווח אולי על הלוס שהשתמשנו בו, הנראות.</p>
<p>אבל אם, כמו שקורה פעמים רבות, המדד שמעניין אותי זה הראקינג, רק הדירוג של התצפיות, איך כדאי להסתכל על הביצועים של המודל?</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="the-roc-curve">The ROC Curve</h3>
<p>The idea: to evaluate ranking performance, do not set the threshold <span class="math inline">\(0.5\)</span> but check what happens at all possible thresholds:</p>
<ol type="1">
<li>True positive rate: what % of the positive observations pass the threshold?</li>
<li>False positive rate: what % of the negative observations pass the threshold?</li>
</ol>
<div class="fragment">
<ul>
<li>The ROC curve plots TPR vs FPR for all possible threholds: if the model ranks well, for high thresholds we will have <span class="math inline">\(FPR\approx 0\)</span>, while for low thresholds we will have <span class="math inline">\(TPR \approx 1\)</span></li>
</ul>
</div>
<div class="fragment">
<ul>
<li>Note that even if <span class="math inline">\(\widehat{P(y=1|x)}\)</span> predicts probabilities badly, or even if the predictions are not in the range <span class="math inline">\([0,1]\)</span>, the ranking can still be good</li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אם מה שמעניין אותנו הוא ראנקינג, נהוג להסתכל בעקומה שנקראת receiver operating characteristic או ROC בקיצור.</p>
<p>הרעיון הוא לא להסתפק בקאטאוף דיפולטי של חצי כפי שעשינו, כי יכול להיות שהסקור שהוצאנו איננו בדיוק הסתברות. נשנה את הקאטאוף בצעדים קבועים, ובכל צעד נמדוד את ה: טרו פוזיטיב רייט, זה בעצם הריקול, ואת הפולס פוזיטיב רייט, אחוז הדוגמאות השליליות שעוברות את הקאטאוף הנוכחי ונחזות כחיוביות.</p>
<p>עקומת הROC תצייר את הTPR לעומת הFPR לכל קאטאוף אפשרי. מודל מושלם ימצא קאטאוף שעבורו הTPR קרוב ל1 והFPR קרוב ל0.</p>
<p>ושוב נדגיש שגם אם ההסתברות הנחזית מגיעה ממודל שבכלל לא אמור להוציא הסתברויות והיא לא מכוילת או אפילו היא לא הסתברות, היא איזשהו סקור, הדירוג עצמו עדיין יכול להיות מצוין. וזה היתרון הגדול של גישה כזאת. התחשבות בקאטאופים שונים והעובדה שהיא פרקטית לכל סקור.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<div class="cell" data-execution_count="22">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_curve, auc</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>fpr, tpr, thresholds <span class="op">=</span> roc_curve(Yte, p_hat_te)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>auc1 <span class="op">=</span> auc(fpr, tpr)</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>plt.plot(fpr, tpr, color<span class="op">=</span><span class="st">'darkorange'</span>,</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>         lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'ROC curve (area = </span><span class="sc">%0.2f</span><span class="st">)'</span> <span class="op">%</span> auc1)</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], color<span class="op">=</span><span class="st">'navy'</span>, lw<span class="op">=</span><span class="dv">2</span>, linestyle<span class="op">=</span><span class="st">'--'</span>)</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>plt.xlim([<span class="fl">0.0</span>, <span class="fl">1.0</span>])</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>plt.ylim([<span class="fl">0.0</span>, <span class="fl">1.05</span>])</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'False Positive Rate'</span>)</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'True Positive Rate'</span>)</span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'ROC curve for our logistic model'</span>)</span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">"lower right"</span>)</span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img data-src="c09_regression_files/figure-revealjs/cell-23-output-1.png" width="525" height="449"></p>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כך נראית עקומת הROC על מדגם הטסט שלנו, עבור מודל הרגרסיה הלוגיסטית שמנסה לחזות אם פציינט יחלה במחלת לב או לא.</p>
<p>הקוד בפייתון לבצע את זה נמצא כאן למי שרוצה.</p>
<p>אנחנו לא רואים את הספים עצמם שהקוד משנה, אבל כן נוצרת עקומה יפה של TPR מול FPR, ואנחנו רואים שעבור ספים נמוכים מתקבל TPR גבוה, ועבור ספים גבוהים מתקבל FPR נמוך. אפשר גם לראות את הטריידאוף בין שני המדדים בצורה יפה.</p>
<p>ואם רוצים לחזור לניבוי סופי, אפשר לבחור את הקאטאוף שיביא אותנו לנקודה האופטימלית מבחינתנו. אם אין לנו העדפה מסוימת, כמו שהדגמנו קודם, הנקודה האופטימלית שומרת כל TPR כמו שיותר גבוה וFPR כמה שיותר נמוך אז זו תהיה הנקודה הכי קרובה לקצה השמאלי העליון של הגרף, נאמר זאת.</p>
<p>וברור שבמודל מושלם יימצא סף שמגיע עד הנקודה בקצה השמאלי עליון של הגרף.</p>
<p>במודל כזה השטח תחת העקומה יהיה השטח של כל הריבוע, 1 כפול 1, זאת אומרת 1, וכאן כפי שמודפס השטח הוא רק 0.8, או 80 אחוז.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="the-area-under-the-curve-auc">The Area Under the Curve (AUC)</h3>
<ul>
<li><p><em>For a random ranking:</em> <span class="math inline">\(FPR \approx TPR\)</span> at every threshold, so we are around the diagonal <span class="math inline">\(x=y\)</span>: <span class="math display">\[AUC\approx 0.5\]</span></p></li>
<li><p><em>For a perfect ranking model:</em> at high thresholds, <span class="math inline">\(FPR=0\)</span>, at low thresholds <span class="math inline">\(TPR=1\)</span>, hence: <span class="math display">\[AUC=1.\]</span></p></li>
</ul>
<div class="fragment">
<ul>
<li>Very nice interpretation of AUC: Assume the test set has <span class="math inline">\(m_1\)</span> ones (<span class="math inline">\(y=1\)</span>) and <span class="math inline">\(m_0\)</span> zeros, then AUC is the % of correctly ranked pairs with different response: <span class="math display">\[AUC = \frac{ \#\left\{(i,j): y_i = 0, y_j=1 \mbox{ and } \hat{p}_i &lt; \hat{p}_j\right\}}{m_1\times m_0}\]</span></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>השטח תחת עקומת הROC , הarea under curve או AUC, הוא מדד מקובל מאוד, והוא מצוין כי הוא לא תלוי בקאטאוף ספציפי, הוא מתחשב בכולם, מעין ממוצע או אינטגרציה של טיב המודל על פני ספים שונים.</p>
<p>מודל אקראי לחלוטין, שככל שאנחנו מעלים את הסף כך יורד הTPR ועולה הFPR באופן שווה, העקומה תהיה בעצם הקו האלכסוני בריבוע, והשטח תחתיה, הAUC יהיה חצי.</p>
<p>מודל מושלם כאמור, יגיע לAUC של 1, כל שטח הריבוע.</p>
<p>פרשנות יפה של AUC היא, מתוך כל זוגות התצפיות האפשריות, אחת חיובית ואחת שלילית, כמה מדורגות “נכון”. ומה זה נכון? אם הסקור הנאמד לתצפית החיובית, גדול מהסקור לתצפית השלילית.</p>
<p>בצורה פורמלית אפשר לסמן זאת כך, אם יש לנו m0 תצפיות שליליות וm1 תצפיות חיוביות, אז הAUC שווה לאחוז הזוגות שעבורם p_hat לתצפית החיובית גבוה מp_hat לתצפית השלילית. ונשים לב שהמדד הזה גם לא סובל במרכאות אם יש לנו הרבה יותר תצפיות חיוביות משליליות במדגם, או להיפך, כמו שראינו עבור מדד הaccuracy. זו פרופורציה שבכל מקרה נרצה שתהיה כמה שיותר קרובה לאחת.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="but-think.">But think.</h3>
<ul>
<li><p>Where did our paintings go?</p></li>
<li><p>Is logistic regression a suitable model for our paintings images?</p></li>
</ul>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נקודה אחרונה למחשבה: למה לא הזכרנו בשיעור הזה את הציורים שלנו הריאליסטיים והאימפרסיוניסטיים? למה לא השתמשנו ברגרסיה לוגיסטית כדי לבנות מודל שיחזה האם ציור הוא אימפרסיוניסטי?</p>
<p>ברור שאפשר, ואתם תבנו מודל כזה בשיעורי הבית. ואז אתם תגלו שמודל כזה לא יהיה מאוד איכותי. נסו לחשוב למה!</p>
<p>ביחידות הבאות נמשיך עם בניית מודלים לחיזוי, אבל נוותר על המודל הליניארי הנוקשה. יחד עם זאת, כל המושגים שלמדנו היום ישמשו אותנו היטב.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>

<img src="../Intro2DS_logo_white.jpg" class="slide-logo r-stretch"><div class="footer footer-default">
<p><a href="https://intro2ds2023.github.io/mooc/" target="_blank">Intro to Data Science</a></p>
</div>
</section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../libs/revealjs/plugin/search/search.js"></script>
  <script src="../libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'smaller': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': true,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        text: function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>