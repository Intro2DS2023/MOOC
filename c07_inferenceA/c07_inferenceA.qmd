---
format:
  revealjs:
    slide-number: true
    chalkboard: true
    fig-width: 6
    fig-asp: 0.618
    template-partials:
      - "../title-slide.html"
css: "../slides_quarto.css"
standalone: false
include-in-header: "../header_quarto.html"
logo: "../Intro2DS_logo_white.jpg"
pagetitle: "Inference - Part A"
callout-appearance: simple
smaller: true
execute:
  eval: true
  echo: true
code-line-numbers: false
code-block-border-left: true
highlight-style: github
footer: "[Intro to Data Science](https://intro2ds2023.github.io/mooc/){target='_blank'}"
---

## {.logo-slide}

## Introduction to Data Science {.title-slide}

### Inference - Part A - Class 7

### Giora Simchoni

#### `gsimchoni@gmail.com` and add `#intro2ds` in subject

### Stat. and OR Department, TAU

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

## The Big Picture {.title-slide}

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

### Basic idea of statistical inference

![](images/sampling_inference_diagram.png)

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

### Basic idea of statistical inference

::: {.fragment}
The *distribution* is something we want to learn about: 

- Which candidate has more support in the population?
- Do impressionist paintings have more red than realist paintings?
:::

::: {.fragment}
We are given a *sample* of data $X$ and want to use it to learn about the population:

- An election survey
- 30 impressionist paintings and 30 realist paintings
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

### Hypothesis testing

::: {.fragment}
We have a *null* world we believe in unless convinced otherwise: 

- The candidates have equal support
- There is no difference in red level between impressionist and realist paintings
:::

::: {.fragment}
We want to use the sample to determine whether to reject the null:

- Does the sample **convincingly indicate** that candidate 1 has higher support?
- Does the sample contain **clear evidence** of more red in girls?
:::

::: {.fragment}
This is often indicated through the p-value, which *calculates* how consistent our data is with the null hypothesis

Another view: the p-value measures how *surprising* the data we see is, if the null holds
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

### Conceptual example: Criminal trial

- In a criminal trial, suspects get convicted only if their guilt is proven *beyond reasonable doubt* 
- This is a hypothesis test with null hypothesis: the suspect is innocent
- Data: the evidence the sides bring in trial
- Beyond reasonable doubt: the evidence is not consistent with the null of innocence
- Difference: the decision is based on the judge's intuition, whereas formal hypothesis testing is based on calculating probabilities

::: {.fragment}
Key element: The two hypotheses are not symmetric!
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

### The importance of (formal) hypothesis testing in the world

::: {.fragment}
All scientific discovery is done through the hypothesis testing formalism:

- Null hypothesis: We did not discover something new (like a new particle, or a new genetic influence on disease)
- Examples: Higgs boson search, studies for finding genes that cause disease
- P value: strength of evidence that what we found is indeed new and different
:::

::: {.fragment}
All the formal processes of testing medications, food etc. 

- Null hypothesis: the new medicine does not reduce cholesterol
- Example: study with people who got the medicine or placebo
- P value: how convincing is the evidence that the medicine is more effective than placebo?
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

## Example: Red Paintings {.title-slide}

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

### Red Paintings Example

- We want to examine whether there is more red in impressionist paintings vs realist paintings

- The "world" is the 16K paintings we have: 8K realist, 8K impressionist

- Imagine we can't check all of them, but can only sample a few of each kind and see the difference

- Our challenge: to determine if it is *convincing* evidence that impressionist paintings are redder overall

- Use hypothesis testing approach

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

```{python}
#| echo: false

import sys
import warnings
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from skimage import transform, color, img_as_ubyte

def check_mem():
    # These are the usual ipython objects, including this one you are creating
    ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']

    # Get a sorted list of the objects and their sizes
    print(sorted([(x, sys.getsizeof(globals().get(x))) for x in globals() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True))

def get_file_list(df, folder, n_sample = None, seed = None):
    if n_sample is None:
        file_ids_list = df.title.values
    else:
        file_ids_list = df.sample(n = n_sample, random_state = seed).title.values
    files_list = [folder + '/' + file_id for file_id in file_ids_list]
    return files_list

def read_image_and_resize(f, w = 100, h = 100):
    img = plt.imread(f)
    img = transform.resize(img, (w, h), mode='constant', anti_aliasing=True)
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        img = img_as_ubyte(img)
    if img.shape != (100, 100, 3):
        img = color.gray2rgb(img)
    img = img[np.newaxis, :, :, :3]
    if img.shape != (1, 100, 100, 3):
        raise ValueError(f + str(img.shape))
    return img

def read_images_4d_array(files_list):
    images_list = [read_image_and_resize(file) for file in files_list]
    images_array = np.concatenate(images_list)
    return images_array

def get_images_matrix(csv_file, folder, n = None, seed = 1976):
    df = pd.read_csv(csv_file)
    files_list = get_file_list(df, folder, n, seed)
    images = read_images_4d_array(files_list)
    return images

def get_all_pixels(x):
    return x.reshape(-1, np.prod(x.shape[1:]))

folder = 'C:/Users/gsimchoni/Downloads/wikiart2/wikiart/'
```

```{python}
real_sample = get_images_matrix(folder + 'realism_train.csv', folder + 'realism', n = 30, seed = 1977)
impr_sample = get_images_matrix(folder + 'impressionism_train.csv', folder + 'impressionism', n = 30, seed = 1977)

real_red = real_sample[:, :, :, 0].mean(axis = (1, 2))
impr_red = impr_sample[:, :, :, 0].mean(axis = (1, 2))

print(real_red[:10])
print(impr_red[:10])
```


::: {.fragment}
```{python}
print(f'Realist paintings mean red value: {real_red.mean():.2f}')
print(f'Impressionist paintings mean red value: {impr_red.mean():.2f}')
print(f'Means difference: {impr_red.mean() - real_red.mean(): .2f}')
```
:::

::: {.fragment}
It looks as you expected, girls average red pixel is higher by about 15 points, but if you do it again, results would be different, wouldn't they?
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

```{python}
real_sample2 = get_images_matrix(folder + 'realism_train.csv', folder + 'realism', n = 30, seed = 1979)
impr_sample2 = get_images_matrix(folder + 'impressionism_train.csv', folder + 'impressionism', n = 30, seed = 1979)

real_red2 = real_sample2[:, :, :, 0].mean(axis = (1, 2))
impr_red2 = impr_sample2[:, :, :, 0].mean(axis = (1, 2))

print(f'Realist paintings mean red value: {real_red2.mean():.2f}')
print(f'Impressionist paintings mean red value: {impr_red2.mean():.2f}')
print(f'Means difference: {impr_red2.mean() - real_red2.mean(): .2f}')
```

::: {.fragment}
Assume sampling is expensive. You have the capacity for 60 paintings.

How will you know, that the difference you're seeing is of significance? That it will "stick"? That what everyone is thinking, the null hypothesis, should be rejected, and your alternative hypothesis is more likely?
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

## The Null Distribution by Simulation {.title-slide}

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

### The Null Distribution by Simulation

- Under the null hypothesis, impressionist and realist paintings come from the same homogenous population.

- To illustrate this we will create an **artificial null** world, made of 16K paintings images in our training dataset. Then we can randomly assign half as impressionist and half as realist 

- In this world we **know** that impressionist paintings and realist paintings have about the same amount of red

::: {.fragment}

```{python}
real_all = get_images_matrix(folder + 'realism_train.csv', folder + 'realism')
impr_all = get_images_matrix(folder + 'impressionism_train.csv', folder + 'impressionism')

real_red_all = real_all[:, :, :, 0].mean(axis = (1, 2))
impr_red_all = impr_all[:, :, :, 0].mean(axis = (1, 2))

population = np.concatenate([real_red_all, impr_red_all])

print(population.shape)
```
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

```{python}
plt.hist(population, bins=20)
plt.show()
```

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

----

- We can sample two random samples of so-called "impressionist" and so-called "realist" paintings to prove to ourselves that the difference between their means should be about zero:

```{python}
real_red_null = np.random.choice(population, 30, replace=False)
impr_red_null = np.random.choice(population, 30, replace=False)
print(f'Means difference: {impr_red_null.mean() - real_red_null.mean(): .2f}')
```

::: {.fragment}
- We got a mean difference which is different than zero, *by random*. And again and again:

```{python}
real_red_null = np.random.choice(population, 30, replace=False)
impr_red_null = np.random.choice(population, 30, replace=False)
print(f'Means difference: {impr_red_null.mean() - real_red_null.mean(): .2f}')

real_red_null = np.random.choice(population, 30, replace=False)
impr_red_null = np.random.choice(population, 30, replace=False)
print(f'Means difference: {impr_red_null.mean() - real_red_null.mean(): .2f}')
```

:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

----

### The Null Distribution

- We want to know how is *our* original average difference of about 15 points is in comparison to these **null** average differences between groups coming from the same population.

- So we'll make a lot of the them and look at their distribution, the Null Distribution of the means difference:

::: {.fragment}
```{python}
#| code-line-numbers: "|6|"

def sample_null_mean_diff(n = 30):
    real_red_null = np.random.choice(population, n, replace=False)
    impr_red_null = np.random.choice(population, n, replace=False)
    return impr_red_null.mean() - real_red_null.mean()

null_mean_diffs = np.array([sample_null_mean_diff() for i in range(10000)])

print(f'Max null mean diff: {max(null_mean_diffs): .2f}')
print(f'Min null mean diff: {min(null_mean_diffs): .2f}')
```
:::

::: {.fragment}
- We can see that the max null mean differences is actually much higher than our original 15 points. So at random, when there is *no difference*, you can get mean differences of over 30!
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

Let's look at the Null Distirbution histogram:

```{python}
#| code-fold: true

fig, ax = plt.subplots()

N, bins, patches = ax.hist(null_mean_diffs, bins=np.arange(-45, 45, 5))
for i in range(0, 12):
    patches[i].set_facecolor('blue')
for i in range(12, len(patches)):
    patches[i].set_facecolor('red')

plt.show()
```

It seems like our original value of 15 points difference is not that extreme. There's a measure for that:

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

### P-Value

- How extreme is our original 15 points result?

::: {.fragment}
- What is the probability under the Null Distribution, where there is no difference between "realist" and "impressionist", of getting 15 or higher?
:::

::: {.fragment}
```{python}
one_sided_p_value = np.mean(null_mean_diffs >= 18)

print(f'P(mean_diff >= 15 | H0) = {one_sided_p_value: .2f}')
```
:::

::: {.fragment}
- It looks like the chance of getting a difference of 15 points or higher, when there is no difference, is ~7%. Does that convince you that there actually is a difference, that indeed the realist and impressionist samples came from two different, separate, distributions?
:::

::: {.fragment}
- It is a standard in both academia and industry to not be persuaded by a p-value larger than a threshold $\alpha$ of 1% or 5% (a.k.a Type I Error, see soon).
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

### Two-sided Hypothesis

- If the original alternative hypothesis were "impressionist paintings images' red level is *different* than realist", the p-value should have been two sided.

- Because the probability of getting our original value or "more extreme" would have meant "more extreme in absolute value":

::: {.fragment}

```{python}
two_sided_p_value = np.mean(np.abs(null_mean_diffs) > 15)

print(f'P(|mean_diff| >= 15 | H0) = {two_sided_p_value: .2f}')
```
:::

::: {.incremental}
- 14% chance of observing a result like 15 points or more extreme, at random, when there is no difference. 15 points doesn't look convincing.

- But in real life we only have that one hard-earned sample. We don't have the population. And from here, the rest is mathematical approximation for getting that p-value and other measures, with what we have.
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

## Binomial Example {.title-slide}

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

### Simpler conceptual example

- I am given a coin and I want to know if it is fair (heads/tails equally likely)
- I am only allowed to throw it 10 times, and I get 8 heads
- Mark the null hypothesis $H_0: P(\text{head})=\frac{1}{2}$
- Can I reject $H_0$? 

::: {.incremental}
- If I had a null distribution, I could get a p-value: see what % of the time I would get 8 or more heads if the coin was fair 
- Can I get this null distribution? Easily!
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

### Method 1: Simulation (as before)

```{python}
null_res = np.random.binomial(10, 0.5, size=10000)
```

::: {.fragment}
```{python}
pd.value_counts(null_res, normalize=True).sort_index()
```
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

```{python}
#| code-fold: true

fig, ax = plt.subplots()
N, bins, patches = ax.hist(null_res, bins=np.arange(0, 11, 0.5))
for i in range(0, 15):
    patches[i].set_facecolor('blue')
for i in range(15, 19):
    patches[i].set_facecolor('red')
plt.show()
```

::: {.fragment}
```{python}
one_sided_p_value = np.mean(null_res >= 8)
print(f'P(heads >= 8 | H0) = {one_sided_p_value: .3f}')

two_sided_p_value = np.mean(null_res >= 8) + np.mean(null_res<=2)
print(f'P(heads>=8 or heads<=2 | H0) = {two_sided_p_value: .3f}')

```
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

### Method 2: Binomial Dist.

- Denote by $X$ the number of heads in 10 tosses.

- Under $H_0: P(\text{head})=\frac{1}{2}$ what is the distribution of $X$?

::: {.fragment}
$X \sim Bin(10, \frac{1}{2})$
:::

::: {.incremental}
- One sided: $P(X \geq 8)=  \left(\binom{10}{8} + \binom{10}{9} + \binom{10}{10}\right) \cdot 2^{-10} = 0.055$

- Two sided: $2 \cdot 0.055 = 0.11$

- **Important lesson: proper simulation and proper mathematical analysis should give similar results**
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

## Type-I and Type-II Errors {.title-slide}

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

### The Alternative Hypothesis

::: {.incremental}
- Let us introduce the simple alternative hypothesis

- In the courtroom example:
$$H_0: \text{innocent}$$
$$H_1: \text{guilty}$$

- In the coin example, $X \sim Bin(10, p)$, and:
$$H_0: p = 0.5$$
$$H_1: p = 0.8$$

- In the paintings example, $\mu$ is the diff in red between impressionist and realist, and:
$$H_0: \mu = 0$$
$$H_1: \mu = 20$$

:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

### Type I and Type II Errors

- What could go wrong?

::: {.incremental}
- We **reject $H_0$** when it is true, Type-I error: $\alpha = P(\text{reject } H_0 | H_0 \text{ true})$

- We **don't reject $H_0$** when we should, Type-II error: $\beta = P(\text{not reject } H_0 | H_1 \text{ true})$

- (notice the jargon)
:::

::: {.fragment}
The meaning of these terms is often better understood in a table:

| Reality\\Decision | Not Reject $H_0$    | Reject $H_0$   |
|---|------|-----|
| $H_0$ | Confidence: $1 - \alpha$ | Type I Error: $\alpha$ |
| $H_1$ |  Type I Error: $\beta$    | Power: $1 - \beta$    |
:::

::: {.fragment}
Statistical power is often written as $1 - \beta$, or: $\pi = P(\text{reject } H_0 | H_1 \text{ true})$

Highly important, see later.
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

### Two Common Approaches to Testing

1. Compute p-value and compare to some threshold $\alpha$ (1%, 5%)
    - If p-value $\le \alpha \Rightarrow$ reject $H_0$
    - If p-value $> \alpha \Rightarrow$ don't reject $H_0$

::: {.fragment}
2. Looking at some statistic of the sample $T(X)$, by fixing $\alpha$ at some "significance level", extract a critical value $C$ and compare to it:
    - If $T(X) \ge C \Rightarrow$ reject $H_0$
    - If $T(X) < C \Rightarrow$ don't reject $H_0$

(for a one-sided hypothesis)
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

### Method 3: Rejection Area

- Denote by $X$ the number of heads in 10 tosses.

- $X \sim Bin(10, p)$, under $H_0: p =\frac{1}{2}$

- $T(X) = X$, the outcome itself

::: {.fragment}
- Set $\alpha = 0.01$

- Extract $C$:
$$\alpha = 0.01 \approx P(X \ge C) \Rightarrow C = 9$$
:::

::: {.fragment}
- If $X \ge 9 \Rightarrow$ reject $H_0$
- If $X < 9 \Rightarrow$ don't reject $H_0$
:::

::: {.fragment}
- Got $X = 8$ in sample so not rejecting $H_0$
:::

::: {.fragment}
- **Crucial Question**: Did we need $H_1$?
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

### Or by simulation

Back to paintings, set $\alpha = 0.01$ and extract $C$ the 99th quantile of the null:

::: {.fragment}
```{python}
print(f'C (above which 1% of null distribution) = {np.quantile(null_mean_diffs, 0.99): .2f}')
```

We got 15 points difference, so.
:::

::: {.fragment}
Again: Did we need $H_1$?
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

### Intro. to Power

- It is only when we want to calculate the power when we need a specific $H_1$.

::: {.fragment}
- In the coin example, $X \sim Bin(10, p)$, and:
$$H_0: p = 0.5$$
$$H_1: p = 0.8$$
:::

::: {.fragment}
- The test was set at:
    - If $X \ge 9 \Rightarrow$ reject $H_0$ (rejection area)
    - If $X < 9 \Rightarrow$ don't reject $H_0$
:::

::: {.fragment}
Power = $P(\text{reject } H_0 | H_1 \text{ true}) = P_{H_1}(X \ge 9) = \binom{10}{9}\cdot 0.8^9\cdot 0.2 + \binom{10}{10}\cdot 0.8^{10} = 0.376$
:::

::: {.fragment}
So for this test we have less than 40% chance of rejecting $H_0$ when we should!
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::

---

### Or by simulation?

::: {.fragment}
How would we calculate the power for the paintings test?
:::

::: {.notes}
::: {style="direction:rtl; font-size:16px"}
:::
:::
