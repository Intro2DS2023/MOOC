{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgCP7pYn996l"
      },
      "source": [
        "# Read the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RGZT-ht996n"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import pearsonr\n",
        "import warnings\n",
        "\n",
        "ratings = pd.read_csv('netflix/train_ratings_all.csv', header = None)\n",
        "miss_cong = pd.read_csv('netflix/train_y_rating.csv', header = None, names = ['score'])\n",
        "movies = pd.read_csv('netflix/movie_titles.csv', header = None, names = ['year', 'title'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgpM30WV996o"
      },
      "source": [
        "# Peek at the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpG2zHwFALqq"
      },
      "outputs": [],
      "source": [
        "print('Head of ratings DataFrame:')\n",
        "ratings.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YxecvovAN53"
      },
      "outputs": [],
      "source": [
        "print('Head of miss_cong DataFrame:')\n",
        "miss_cong.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibdjexbo_YWk"
      },
      "outputs": [],
      "source": [
        "print(f'No. of raters (rows): {ratings.shape[0]}, no. of movies (cols): {ratings.shape[1]}')\n",
        "print(f'No. of miss_cong raters (rows): {miss_cong.shape[0]}, no. of movies (cols): {miss_cong.shape[1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-yIBe6q996o"
      },
      "outputs": [],
      "source": [
        "print('Head of movies DataFrame:')\n",
        "movies.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cxhJSGXBb2F"
      },
      "outputs": [],
      "source": [
        "print(f'No. of movies (rows): {movies.shape[0]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7dy_eFx996p"
      },
      "source": [
        "# Missing Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iC30pNd-996p"
      },
      "source": [
        "## General"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hu3bz12mB2yA"
      },
      "source": [
        "We'd want to put `None` where there are zeros:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCz_gLn7996p"
      },
      "outputs": [],
      "source": [
        "ratings[ratings == 0] = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMhKSXSwDUPR"
      },
      "source": [
        "How many missing values?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DvGll1iDHia"
      },
      "outputs": [],
      "source": [
        "total_missing = np.sum(np.isnan(ratings.values))\n",
        "total_obs = np.prod(ratings.shape)\n",
        "\n",
        "print(f'Total missing values: {total_missing} out of total observations: {total_obs}')\n",
        "print(f'So that\\'s {total_missing / total_obs :.2f} missing')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIfN0AQICdyq"
      },
      "outputs": [],
      "source": [
        "# can also work directly in pandas (in pandas 2.0 df.sum(axis=None) should work)\n",
        "pd.isna(ratings).sum().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4kbiset996p"
      },
      "source": [
        "## Focusing on Movies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pceC0jeKD8D9"
      },
      "source": [
        "See no. of missing observations per movie, add it as another column of movies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmNCyFwx996p"
      },
      "outputs": [],
      "source": [
        "missing_per_movie = pd.isna(ratings).sum(axis=0)\n",
        "movies['n_missing'] = missing_per_movie\n",
        "\n",
        "movies.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvpSaDz8996q"
      },
      "outputs": [],
      "source": [
        "# finding n missing of a specific movie\n",
        "movies.loc[movies['title'] == 'American Beauty', 'n_missing']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPKqNl5QEQuq"
      },
      "source": [
        "Finding min, max, median and mean movie per `n_missing`:\n",
        "\n",
        "(ignoring first 14 movies with no missing at all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Whhx814I996q"
      },
      "outputs": [],
      "source": [
        "movies_with_missing = movies.iloc[14:, :]\n",
        "\n",
        "def get_val_of_col_by_col(df, by, col, value):\n",
        "  idx = (np.abs(df[by] - value)).idxmin() # taking id *closest* to value because mean is involved\n",
        "  return df.at[idx, col]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUQ9x5dVE0nY"
      },
      "outputs": [],
      "source": [
        "min_n_missing = np.min(movies_with_missing['n_missing'])\n",
        "min_n_missing_movie = get_val_of_col_by_col(movies_with_missing, 'n_missing', 'title', min_n_missing)\n",
        "\n",
        "max_n_missing = np.max(movies_with_missing['n_missing'])\n",
        "max_n_missing_movie = get_val_of_col_by_col(movies_with_missing, 'n_missing', 'title', max_n_missing)\n",
        "\n",
        "median_n_missing = np.median(movies_with_missing['n_missing'])\n",
        "median_n_missing_movie = get_val_of_col_by_col(movies_with_missing, 'n_missing', 'title', median_n_missing)\n",
        "\n",
        "mean_n_missing = np.mean(movies_with_missing['n_missing'])\n",
        "mean_n_missing_movie = get_val_of_col_by_col(movies_with_missing, 'n_missing', 'title', mean_n_missing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_11siDeE8Fu"
      },
      "outputs": [],
      "source": [
        "print(f'movie with minimum n missing: {min_n_missing_movie}, with {min_n_missing} missing')\n",
        "print(f'movie with maximum n missing: {max_n_missing_movie}, with {max_n_missing} missing')\n",
        "print(f'movie with median n missing: {median_n_missing_movie}, with {median_n_missing} missing')\n",
        "print(f'movie closest to mean n missing: {mean_n_missing_movie}, mean being {mean_n_missing :.2f} missing')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhtCnu_rHpsB"
      },
      "source": [
        "Let's see a histogram of missingness:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fd3vLPsm996q"
      },
      "outputs": [],
      "source": [
        "sns.displot(movies['n_missing'], kde=False, rug=True)\n",
        "plt.ylabel('n movies')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAyHjBbCH5EW"
      },
      "source": [
        "What would you say is the skewness of such a distribution?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QPo64y2IBP0"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "\n",
        "print(f'Skewness of missingness in movies:{stats.skew(movies[\"n_missing\"]):.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHBdV4y9996q"
      },
      "source": [
        "## Focus on Raters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRqCdpTZI4kn"
      },
      "source": [
        "See no. of missing observations per rater, creating a new DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laG3L0yJ996q"
      },
      "outputs": [],
      "source": [
        "raters = pd.DataFrame({'rater': range(ratings.shape[0])})\n",
        "missing_per_rater = pd.isna(ratings).sum(axis=1)\n",
        "raters['n_missing'] = missing_per_rater\n",
        "\n",
        "raters.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gcruax0cJcVC"
      },
      "source": [
        "Finding min, max, median and mean rater per `n_missing`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5szauFI996r"
      },
      "outputs": [],
      "source": [
        "min_n_missing = np.min(raters['n_missing'])\n",
        "min_n_missing_rater = get_val_of_col_by_col(raters, 'n_missing', 'rater', min_n_missing)\n",
        "\n",
        "max_n_missing = np.max(raters['n_missing'])\n",
        "max_n_missing_rater = get_val_of_col_by_col(raters, 'n_missing', 'rater', max_n_missing)\n",
        "\n",
        "median_n_missing = np.median(raters['n_missing'])\n",
        "median_n_missing_rater = get_val_of_col_by_col(raters, 'n_missing', 'rater', median_n_missing)\n",
        "\n",
        "mean_n_missing = np.mean(raters['n_missing'])\n",
        "mean_n_missing_rater = get_val_of_col_by_col(raters, 'n_missing', 'rater', mean_n_missing)\n",
        "\n",
        "print(f'rater with minimum n missing: {min_n_missing_rater}, with {min_n_missing} missing')\n",
        "print(f'rater with maximum n missing: {max_n_missing_rater}, with {max_n_missing} missing')\n",
        "print(f'rater with median n missing: {median_n_missing_rater}, with {median_n_missing} missing')\n",
        "print(f'rater closest to mean n missing: {mean_n_missing_rater}, mean being {mean_n_missing:.2f} missing')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lObXhnk9996r"
      },
      "outputs": [],
      "source": [
        "# histogram\n",
        "sns.displot(raters['n_missing'], kde=False, rug=True)\n",
        "plt.ylabel('n raters')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSDGPstpKn19"
      },
      "outputs": [],
      "source": [
        "sns.displot(raters['n_missing'], kde=False, rug=True, bins=20)\n",
        "plt.ylabel('n raters')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjYb60Uy996r"
      },
      "source": [
        "# Scores Exploration (ignoring missing values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTqr_nFv996r"
      },
      "source": [
        "## General"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PYe3hfsMkQI"
      },
      "source": [
        "Min, max, median, mean scores:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdA0aQva996r"
      },
      "outputs": [],
      "source": [
        "print(f'min movies score: {np.nanmin(ratings.values):.2f}')\n",
        "print(f'max movies score {np.nanmax(ratings.values):.2f}')\n",
        "print(f'median movies score: {np.nanmedian(ratings.values):.2f}')\n",
        "print(f'mean movies score: {np.nanmean(ratings.values):.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5zKsw07MpUZ"
      },
      "source": [
        "Barchart of all scores ignoring nans:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYOLl0NZ996r"
      },
      "outputs": [],
      "source": [
        "sns.displot(ratings.values[~np.isnan(ratings.values)], kde=False, rug=True)\n",
        "plt.ylabel('n scores')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sGR9gOG996s"
      },
      "outputs": [],
      "source": [
        "# same, less fancy but shorter\n",
        "plt.hist(ratings.values[~np.isnan(ratings.values)], bins = 5, range=(0.5,5.5))\n",
        "plt.ylabel('n scores')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rq9psVfO996s"
      },
      "source": [
        "## Mean Scores, Marginal on Movies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asiySiV5OpxY"
      },
      "source": [
        "Let's see mean score per movie, adding it as another column of movies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oC8pH81996s"
      },
      "outputs": [],
      "source": [
        "movies['mean_score'] = ratings.mean(axis=0)\n",
        "\n",
        "movies.head(14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQTVnxxp996s"
      },
      "outputs": [],
      "source": [
        "# finding min, max, median and mean movie per mean_score\n",
        "min_mean_score = np.min(movies['mean_score'])\n",
        "min_mean_score_movie = get_val_of_col_by_col(movies, 'mean_score', 'title', min_mean_score)\n",
        "\n",
        "max_mean_score = np.max(movies['mean_score'])\n",
        "max_mean_score_movie = get_val_of_col_by_col(movies, 'mean_score', 'title', max_mean_score)\n",
        "\n",
        "median_mean_score = np.median(movies['mean_score'])\n",
        "median_mean_score_movie = get_val_of_col_by_col(movies, 'mean_score', 'title', median_mean_score)\n",
        "\n",
        "mean_mean_score = np.mean(movies['mean_score'])\n",
        "mean_mean_score_movie = get_val_of_col_by_col(movies, 'mean_score', 'title', mean_mean_score)\n",
        "\n",
        "print(f'movie with minimum mean score: {min_mean_score_movie}, with mean {min_mean_score:.2f}')\n",
        "print(f'movie with maximum mean score: {max_mean_score_movie}, with mean {max_mean_score:.2f}')\n",
        "print(f'movie with median mean score: {median_mean_score_movie}, with mean {median_mean_score:.3f}')\n",
        "print(f'movie closest to mean mean score: {mean_mean_score_movie}, mean being {mean_mean_score:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ketg_CjG996s"
      },
      "outputs": [],
      "source": [
        "# histogram\n",
        "sns.displot(movies['mean_score'], kde=False, rug=True)\n",
        "plt.ylabel('n movies')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfvfzftyPzp8"
      },
      "source": [
        "What would you say is the skewness of such a distribution?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxaDQGjNPzqC"
      },
      "outputs": [],
      "source": [
        "print(f'Skewness of mean score in movies:{stats.skew(movies[\"mean_score\"]):.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nq_sDjVN996s"
      },
      "source": [
        "## Mean Scores, Marginal on Raters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0dIUCICQ0sp"
      },
      "source": [
        "See mean score per rater, adding it as another column of raters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7PsJOq3996s"
      },
      "outputs": [],
      "source": [
        "mean_score_per_rater = np.nanmean(ratings.values, axis=1)\n",
        "raters['mean_score'] = mean_score_per_rater\n",
        "\n",
        "raters.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7XBTK-n996t"
      },
      "outputs": [],
      "source": [
        "# finding min, max, median and mean rater per mean_score\n",
        "min_mean_score = np.min(raters['mean_score'])\n",
        "min_mean_score_rater = get_val_of_col_by_col(raters, 'mean_score', 'rater', min_mean_score)\n",
        "\n",
        "max_mean_score = np.max(raters['mean_score'])\n",
        "max_mean_score_rater = get_val_of_col_by_col(raters, 'mean_score', 'rater', max_mean_score)\n",
        "\n",
        "median_mean_score = np.median(raters['mean_score'])\n",
        "median_mean_score_rater = get_val_of_col_by_col(raters, 'mean_score', 'rater', median_mean_score)\n",
        "\n",
        "mean_mean_score = np.mean(raters['mean_score'])\n",
        "mean_mean_score_rater = get_val_of_col_by_col(raters, 'mean_score', 'rater', mean_mean_score)\n",
        "\n",
        "print(f'rater with minimum mean score: {min_mean_score_rater}, with mean {min_mean_score:.2f}')\n",
        "print(f'rater with maximum mean score: {max_mean_score_rater}, with mean {max_mean_score:.2f}')\n",
        "print(f'rater with median mean score: {median_mean_score_rater}, with mean {median_mean_score:.3f}')\n",
        "print(f'rater closest to mean mean score: {mean_mean_score_rater}, mean being {mean_mean_score:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZwgHs61RrAo"
      },
      "outputs": [],
      "source": [
        "# a rater with mean 5.0?\n",
        "raters.loc[[957]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ju6VGv_ESBIa"
      },
      "outputs": [],
      "source": [
        "ratings.loc[[957]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4D4c84Nq996t"
      },
      "outputs": [],
      "source": [
        "# histogram\n",
        "sns.displot(raters['mean_score'], kde=False, rug=True)\n",
        "plt.ylabel('n raters')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZHvczDXSYwM"
      },
      "source": [
        "What would you say is the skewness of such a distribution?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pa3utkapSedz"
      },
      "outputs": [],
      "source": [
        "print(f'Skewness of mean score in raters:{stats.skew(raters[\"mean_score\"]):.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq06pfe2996t"
      },
      "source": [
        "## Mean Scores, Marginal on Release Year"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf2UwPQ7996t"
      },
      "source": [
        "**Warning**: a lot of pandas magic ahead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MByIEUmD996t"
      },
      "outputs": [],
      "source": [
        "# first, \"attach\" year to ratings:\n",
        "ratings_by_year = ratings.T # transpose\n",
        "ratings_by_year['year'] = movies['year'] # add new column\n",
        "ratings_by_year.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgUt5beB996u"
      },
      "outputs": [],
      "source": [
        "# Then, \"melt\" DataFrame, so each year will have each score in a separate line\n",
        "ratings_by_year = pd.melt(ratings_by_year, id_vars=['year'], value_vars=list(range(10000)))\n",
        "ratings_by_year.columns = ['year', 'rater_id', 'score']\n",
        "ratings_by_year.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fF2zlJf3S86d"
      },
      "outputs": [],
      "source": [
        "# notice this a \"long\" DataFrame\n",
        "ratings_by_year.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1-1c3ZO996u"
      },
      "outputs": [],
      "source": [
        "# boxplots are problematic on a 1 to 5 scale...\n",
        "sns.boxplot(x='year', y='score', data = ratings_by_year)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BMXJ25l996u"
      },
      "outputs": [],
      "source": [
        "# so we can get mean score per year and use a simple line chart\n",
        "ratings_by_year = ratings_by_year.groupby('year')['score'].mean().reset_index()\n",
        "ratings_by_year.columns = ['year', 'mean_score']\n",
        "sns.lineplot(x='year', y='mean_score', data = ratings_by_year)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJ5SIFnA996u"
      },
      "source": [
        "# Pairwise Correlations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVGQ9aQ_996u"
      },
      "source": [
        "## General"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bxjf2RnGUTpZ"
      },
      "source": [
        "Is a movie \"missingness\" correlated with its mean score?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6KTi-_j9962"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(x='n_missing', y='mean_score', data = movies)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UamzDDp6UngP"
      },
      "outputs": [],
      "source": [
        "r = pearsonr(movies['n_missing'], movies['mean_score'])[0]\n",
        "print(f'Pearson r correlation: {r:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUquLbcXUcyj"
      },
      "source": [
        "Is a rater's \"missingness\" correlated with her mean score?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSZrHEeA9963"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(x='n_missing', y='mean_score', data = raters)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1rEQ1gOUq3A"
      },
      "outputs": [],
      "source": [
        "r = pearsonr(raters['n_missing'], raters['mean_score'])[0]\n",
        "print(f'Pearson r correlation: {r:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEHCXorH9963"
      },
      "outputs": [],
      "source": [
        "# it looked to me like with very high \"missingness\" the mean score is lower, but:\n",
        "raters['n_missing_high'] = raters['n_missing'] > 50\n",
        "sns.boxplot(x='n_missing_high', y='mean_score', data = raters)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4y53NN3i9963"
      },
      "source": [
        "## Marginal on Movies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihEB_Oa_Vb5O"
      },
      "source": [
        "Let's look at a scatterplot of two specific movies, ignoring missing observations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLqNboAj9963"
      },
      "outputs": [],
      "source": [
        "def scatter_movies(mov1, mov2):\n",
        "  mov1_id = movies.index[movies['title'] == mov1][0]\n",
        "  mov2_id = movies.index[movies['title'] == mov2][0]\n",
        "  sns.scatterplot(x=mov1_id, y=mov2_id, data = ratings)\n",
        "  plt.xlabel(mov1)\n",
        "  plt.ylabel(mov2)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9m46PsaVZVH"
      },
      "outputs": [],
      "source": [
        "scatter_movies('American Beauty', 'The Patriot')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKt_zZ3J9963"
      },
      "outputs": [],
      "source": [
        "# oops, either use boxplots or make dots diameter proportional to group's size\n",
        "def scatter_movies(mov1, mov2):\n",
        "  mov1_id = movies.index[movies['title'] == mov1][0]\n",
        "  mov2_id = movies.index[movies['title'] == mov2][0]\n",
        "  mov1_scores = ratings.values[:, mov1_id]\n",
        "  mov2_scores = ratings.values[:, mov2_id]\n",
        "  nas = np.logical_or(np.isnan(mov1_scores), np.isnan(mov2_scores))\n",
        "  agg_data = pd.DataFrame({'mov1': mov1_scores[~nas], 'mov2': mov2_scores[~nas]}).groupby(['mov1', 'mov2']).size().reset_index()\n",
        "  agg_data.columns = [mov1, mov2, 'count']\n",
        "  sns.scatterplot(x=mov1, y=mov2, size = 'count', hue = 'count', data = agg_data, legend = False)\n",
        "  plt.xlabel(mov1)\n",
        "  plt.ylabel(mov2)\n",
        "  plt.show()\n",
        "\n",
        "scatter_movies('American Beauty', 'The Patriot')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzLke1kk9964"
      },
      "outputs": [],
      "source": [
        "# look at correlation of scores of two specific movies\n",
        "def corr_movies(mov1, mov2):\n",
        "    mov1_id = movies.index[movies['title'] == mov1][0]\n",
        "    mov2_id = movies.index[movies['title'] == mov2][0]\n",
        "    mov1_scores = ratings.values[:, mov1_id]\n",
        "    mov2_scores = ratings.values[:, mov2_id]\n",
        "    nas = np.logical_or(np.isnan(mov1_scores), np.isnan(mov2_scores))\n",
        "    return np.round(pearsonr(mov1_scores[~nas], mov2_scores[~nas])[0], 3)\n",
        "\n",
        "corr_movies('American Beauty', 'The Patriot')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZ4_lW0fV4_J"
      },
      "outputs": [],
      "source": [
        "scatter_movies('Pretty Woman', 'Sweet Home Alabama')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2YNoYQaV7O8"
      },
      "outputs": [],
      "source": [
        "corr_movies('Pretty Woman', 'Sweet Home Alabama')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wTwxgJAWD3f"
      },
      "source": [
        "Get all movies 99 * (99 - 1) / 2 pairwise correlations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CL8q6rJ_9964"
      },
      "outputs": [],
      "source": [
        "movies_titles = movies['title'].values\n",
        "pair_counter = 0\n",
        "pair_corrs = dict()\n",
        "\n",
        "# a nested loop is a bit cumbersome, see pd.DataFrame.corr()\n",
        "for i in range(len(movies_titles) - 1):\n",
        "    for j in range(i + 1, len(movies_titles)):\n",
        "        mov1 = movies_titles[i]\n",
        "        mov2 = movies_titles[j]\n",
        "        pair_corrs[pair_counter] = {'mov1': mov1, 'mov2': mov2, 'corr': corr_movies(mov1, mov2)}\n",
        "        pair_counter += 1\n",
        "\n",
        "pair_corrs_df = pd.DataFrame.from_dict(pair_corrs, 'index')\n",
        "pair_corrs_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "of_YhTx-9964"
      },
      "outputs": [],
      "source": [
        "# pair of movies with highest correlation:\n",
        "max_corr_pair_id = pair_corrs_df['corr'].idxmax()\n",
        "max_pair = pair_corrs_df.iloc[max_corr_pair_id, :].values.tolist()\n",
        "print(f'movie1: {max_pair[0]}, movie2: {max_pair[1]}, correlation: {max_pair[2]:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSRNyqbr9964"
      },
      "outputs": [],
      "source": [
        "# see how the scatterplot of these movies look like\n",
        "scatter_movies(max_pair[0], max_pair[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zypWm61F9964"
      },
      "outputs": [],
      "source": [
        "# pair of movies with lowest correlation:\n",
        "min_corr_pair_id = pair_corrs_df['corr'].idxmin()\n",
        "min_pair = pair_corrs_df.iloc[min_corr_pair_id, :].values.tolist()\n",
        "print(f'movie1: {min_pair[0]}, movie2: {min_pair[1]}, correlation: {min_pair[2]:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUampYuj9965"
      },
      "outputs": [],
      "source": [
        "# see how the scatterplot of these movies look like\n",
        "scatter_movies(min_pair[0], min_pair[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuHT8Prq9965"
      },
      "source": [
        "But beware: what would be the correlation between two movies all 10K raters chose to give a perfect rating?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tq43zIh09965"
      },
      "outputs": [],
      "source": [
        "# histogram\n",
        "sns.displot(pair_corrs_df['corr'], kde=False, rug=True)\n",
        "plt.ylabel('n pairs of movies')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAi8ifLO9965"
      },
      "source": [
        "# Focus on Raters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cczrZz0hXcz8"
      },
      "source": [
        "Look at a scatterplot of two specific raters, ignoring missing observations, making marker diameter proportional to group size:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h29JMPgA9965"
      },
      "outputs": [],
      "source": [
        "def scatter_raters(rater1, rater2):\n",
        "    rater1_scores = ratings.values[rater1, :]\n",
        "    rater2_scores = ratings.values[rater2, :]\n",
        "    nas = np.logical_or(np.isnan(rater1_scores), np.isnan(rater2_scores))\n",
        "    agg_data = pd.DataFrame({'rater1': rater1_scores[~nas], 'rater2': rater2_scores[~nas]}).groupby(['rater1', 'rater2']).size().reset_index()\n",
        "    agg_data.columns = [rater1, rater2, 'count']\n",
        "    sns.scatterplot(x=rater1, y=rater2, size = 'count', hue = 'count', data = agg_data, legend = False)\n",
        "    plt.show()\n",
        "\n",
        "scatter_raters(0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6H4A6QR39966"
      },
      "outputs": [],
      "source": [
        "# look at correlation of two specific raters\n",
        "def corr_raters(rater1, rater2):\n",
        "    rater1_scores = ratings.values[rater1, :]\n",
        "    rater2_scores = ratings.values[rater2, :]\n",
        "    nas = np.logical_or(np.isnan(rater1_scores), np.isnan(rater2_scores))\n",
        "    return np.round(pearsonr(rater1_scores[~nas], rater2_scores[~nas])[0], 3)\n",
        "\n",
        "corr_raters(0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSISbqLY9966"
      },
      "outputs": [],
      "source": [
        "# for looking at all 10K * (10K - 1) / 2 pairwise correlations definitely use:\n",
        "# ratings.T.corr()\n",
        "\n",
        "# we'll stick to a nested loop and sample 10K *pairs* of raters\n",
        "n = 10000\n",
        "pair_corrs = dict()\n",
        "for i in range(n):\n",
        "    rater1, rater2 = np.random.choice(range(raters.shape[0]), 2, replace = False)\n",
        "    pair_corrs[i] = {'rater1': rater1, 'rater2': rater2, 'corr': corr_raters(rater1, rater2)}\n",
        "pair_corrs_df = pd.DataFrame.from_dict(pair_corrs, 'index')\n",
        "pair_corrs_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wo2UjsFI9966"
      },
      "outputs": [],
      "source": [
        "# here more likely to get missing values (why?)\n",
        "sum(np.isnan(pair_corrs_df['corr']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7APSB-Qh9966"
      },
      "outputs": [],
      "source": [
        "# pair of raters with highest correlation:\n",
        "max_corr_pair_id = pair_corrs_df['corr'].idxmax()\n",
        "max_pair = pair_corrs_df.iloc[max_corr_pair_id, :].values.tolist()\n",
        "print(f'rater1: {max_pair[0]}, rater2: {max_pair[1]}, correlation: {max_pair[2]:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwmcaBwY9966"
      },
      "outputs": [],
      "source": [
        "# see how the scatterplot of these raters look like\n",
        "scatter_raters(int(max_pair[0]), int(max_pair[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjV9eOB89967"
      },
      "outputs": [],
      "source": [
        "# pair of raters with lowest correlation:\n",
        "min_corr_pair_id = pair_corrs_df['corr'].idxmin()\n",
        "min_pair = pair_corrs_df.iloc[min_corr_pair_id, :].values.tolist()\n",
        "print(f'rater1: {min_pair[0]}, rater2: {min_pair[1]}, correlation: {min_pair[2]:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwFXtJOW9967"
      },
      "outputs": [],
      "source": [
        "# see how the scatterplot of these raters look like\n",
        "scatter_raters(int(min_pair[0]), int(min_pair[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEvqd91_9967"
      },
      "outputs": [],
      "source": [
        "# histogram\n",
        "pair_corrs_no_nans = pair_corrs_df['corr'][~np.isnan(pair_corrs_df['corr'])]\n",
        "sns.displot(pair_corrs_no_nans, kde=False, rug=True)\n",
        "plt.ylabel('n pairs of raters')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TKJz8zP9967"
      },
      "source": [
        "# Correlation with Miss Congeniality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5j0ZVh539967"
      },
      "outputs": [],
      "source": [
        "miss_cong_scores = miss_cong['score'].values\n",
        "\n",
        "# see scatterplot of miss congeniality against another specific movie\n",
        "def scatter_miss_cong(mov1):\n",
        "    mov1_id = movies.index[movies['title'] == mov1][0]\n",
        "    mov1_scores = ratings.values[:, mov1_id]\n",
        "    nas = np.logical_or(np.isnan(mov1_scores), np.isnan(miss_cong_scores))\n",
        "    agg_data = pd.DataFrame({'mov1': mov1_scores[~nas], 'mov2': miss_cong_scores[~nas]}).groupby(['mov1', 'mov2']).size().reset_index()\n",
        "    agg_data.columns = [mov1, 'Miss Congeniality', 'count']\n",
        "    sns.scatterplot(x=mov1, y='Miss Congeniality', size = 'count', hue = 'count', data = agg_data, legend = False)\n",
        "    plt.show()\n",
        "\n",
        "scatter_miss_cong('Con Air')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAUeP8zQ9967"
      },
      "outputs": [],
      "source": [
        "# look at correlation of miss congeniality against another specific movie\n",
        "def corr_miss_cong(mov1):\n",
        "    mov1_id = movies.index[movies['title'] == mov1][0]\n",
        "    mov1_scores = ratings.values[:, mov1_id]\n",
        "    nas = np.logical_or(np.isnan(mov1_scores), np.isnan(miss_cong_scores))\n",
        "    return np.round(pearsonr(mov1_scores[~nas], miss_cong_scores[~nas])[0], 3)\n",
        "\n",
        "corr_miss_cong('Con Air')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82h4IFad9968"
      },
      "outputs": [],
      "source": [
        "# all Miss Congeniality's correlations with other movies\n",
        "miss_cong_corrs = dict()\n",
        "for i, mov1 in enumerate(movies_titles):\n",
        "    miss_cong_corrs[i] = {'mov1': mov1, 'corr': corr_miss_cong(mov1)}\n",
        "miss_cong_corrs_df = pd.DataFrame.from_dict(miss_cong_corrs, 'index')\n",
        "miss_cong_corrs_df.head(14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUJGccpd9968"
      },
      "outputs": [],
      "source": [
        "# movie with highest correlation to Miss Congeniality:\n",
        "max_corr_id = miss_cong_corrs_df['corr'].idxmax()\n",
        "max_movie = miss_cong_corrs_df.iloc[max_corr_id, :].values.tolist()\n",
        "print(f'movie with max corr to Miss Congeniality: {max_movie[0]}, correlation: {max_movie[1]:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaVzo5Kr9968"
      },
      "outputs": [],
      "source": [
        "# see how the scatterplot looks like\n",
        "scatter_miss_cong(max_movie[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9Ul4X2K9968"
      },
      "outputs": [],
      "source": [
        "# movie with lowest correlation to Miss Congeniality:\n",
        "min_corr_id = miss_cong_corrs_df['corr'].idxmin()\n",
        "min_movie = miss_cong_corrs_df.iloc[min_corr_id, :].values.tolist()\n",
        "print(f'movie with min corr to Miss Congeniality: {min_movie[0]}, correlation: {min_movie[1]:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sso0zHKZ9968"
      },
      "outputs": [],
      "source": [
        "# see how the scatterplot looks like\n",
        "scatter_miss_cong(min_movie[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lpnphau9969"
      },
      "source": [
        "# Miss Congeniality Distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJcPVSFzZ4PM"
      },
      "source": [
        "First, how does the marginal distirbution of Miss Congeniality look like?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgELYVO59969"
      },
      "outputs": [],
      "source": [
        "sns.displot(miss_cong_scores, kde=False, rug=True)\n",
        "plt.ylabel('n raters')\n",
        "plt.show()\n",
        "\n",
        "print(f'Miss Congeniality mean score is: {np.mean(miss_cong_scores):.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-rqV0Eg9969"
      },
      "source": [
        "## Conditional on Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoudSclKaIKx"
      },
      "source": [
        "Now, how does it look like conditional on scoring high (4 or 5) on another movie?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64Q8hpp79969"
      },
      "outputs": [],
      "source": [
        "def miss_cong_dist_cond_high(mov1, high_thresh = 4.0):\n",
        "    mov1_id = movies.index[movies['title'] == mov1][0]\n",
        "    mov1_scores = ratings.values[:, mov1_id]\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.simplefilter(\"ignore\")\n",
        "        miss_cong_filtered = miss_cong_scores[mov1_scores >= high_thresh]\n",
        "    sns.displot(miss_cong_filtered, kde=False, rug=True)\n",
        "    plt.ylabel('n raters')\n",
        "    plt.show()\n",
        "    print(f'Miss Congeniality mean score is: {np.mean(miss_cong_filtered):.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hynuYRNTaRPC"
      },
      "outputs": [],
      "source": [
        "miss_cong_dist_cond_high('The Wedding Planner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1yvjm9d9969"
      },
      "outputs": [],
      "source": [
        "miss_cong_dist_cond_high('Pulp Fiction')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtjpTEMLaa-Q"
      },
      "source": [
        "How does it look like conditional on scoring low (1 or 2) on another movie?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EaJTcp09969"
      },
      "outputs": [],
      "source": [
        "def miss_cong_dist_cond_low(mov1, low_thresh = 2.0):\n",
        "    mov1_id = movies.index[movies['title'] == mov1][0]\n",
        "    mov1_scores = ratings.values[:, mov1_id]\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.simplefilter(\"ignore\")\n",
        "        miss_cong_filtered = miss_cong_scores[mov1_scores <= low_thresh]\n",
        "    sns.displot(miss_cong_filtered, kde=False, rug=True)\n",
        "    plt.ylabel('n raters')\n",
        "    plt.show()\n",
        "    print(f'Miss Congeniality mean score is: {np.mean(miss_cong_filtered):.2f}')\n",
        "\n",
        "miss_cong_dist_cond_low('The Wedding Planner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqRtHs0j996-"
      },
      "outputs": [],
      "source": [
        "miss_cong_dist_cond_low('Pulp Fiction')"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
