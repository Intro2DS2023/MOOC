<!DOCTYPE html>
<html lang="en"><head>
<script src="../libs/clipboard/clipboard.min.js"></script>
<script src="../libs/quarto-html/tabby.min.js"></script>
<script src="../libs/quarto-html/popper.min.js"></script>
<script src="../libs/quarto-html/tippy.umd.min.js"></script>
<link href="../libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="../libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.3.433">

  <title>Local Modeling: KNN and Decision Trees</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
      }
    pre.numberSource { margin-left: 3em;  padding-left: 4px; }
    div.sourceCode
      { color: #24292e;  }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #24292e; } /* Normal */
    code span.al { color: #ff5555; font-weight: bold; } /* Alert */
    code span.an { color: #6a737d; } /* Annotation */
    code span.at { color: #d73a49; } /* Attribute */
    code span.bn { color: #005cc5; } /* BaseN */
    code span.bu { color: #d73a49; } /* BuiltIn */
    code span.cf { color: #d73a49; } /* ControlFlow */
    code span.ch { color: #032f62; } /* Char */
    code span.cn { color: #005cc5; } /* Constant */
    code span.co { color: #6a737d; } /* Comment */
    code span.cv { color: #6a737d; } /* CommentVar */
    code span.do { color: #6a737d; } /* Documentation */
    code span.dt { color: #d73a49; } /* DataType */
    code span.dv { color: #005cc5; } /* DecVal */
    code span.er { color: #ff5555; text-decoration: underline; } /* Error */
    code span.ex { color: #d73a49; font-weight: bold; } /* Extension */
    code span.fl { color: #005cc5; } /* Float */
    code span.fu { color: #6f42c1; } /* Function */
    code span.im { color: #032f62; } /* Import */
    code span.in { color: #6a737d; } /* Information */
    code span.kw { color: #d73a49; } /* Keyword */
    code span.op { color: #24292e; } /* Operator */
    code span.ot { color: #6f42c1; } /* Other */
    code span.pp { color: #d73a49; } /* Preprocessor */
    code span.re { color: #6a737d; } /* RegionMarker */
    code span.sc { color: #005cc5; } /* SpecialChar */
    code span.ss { color: #032f62; } /* SpecialString */
    code span.st { color: #032f62; } /* String */
    code span.va { color: #e36209; } /* Variable */
    code span.vs { color: #032f62; } /* VerbatimString */
    code span.wa { color: #ff5555; } /* Warning */
  </style>
  <link rel="stylesheet" href="../libs/revealjs/dist/theme/quarto.css">
  <link rel="stylesheet" href="../slides_quarto.css">
  <link href="../libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  
    <link rel="icon" href="../Intro2DS_logo.jpg" type="image/jpg"> 
    <link rel="shortcut icon" href="../Intro2DS_logo.jpg" type="image/jpg">
    <link href="https://fonts.googleapis.com/css?family=Lato:400,700" rel="stylesheet" type="text/css">
  </head>

<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="section" class="slide level2 logo-slide">
    <h2></h2>
    </section>
<section id="introduction-to-data-science" class="slide level2 title-slide center">
<h2>Introduction to Data Science</h2>
<h3 id="local-modeling-knn-and-decision-trees---class-10">Local Modeling: KNN and Decision Trees - Class 10</h3>
<h3 id="giora-simchoni">Giora Simchoni</h3>
<h4 id="gsimchonigmail.com-and-add-intro2ds-in-subject"><code>gsimchoni@gmail.com</code> and add <code>#intro2ds</code> in subject</h4>
<h3 id="stat.-and-or-department-tau">Stat. and OR Department, TAU</h3>
<aside class="notes">
<div style="direction:rtl; font-size:16px">

</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="k-nearest-neighbour-knn" class="slide level2 title-slide center">
<h2>K-Nearest Neighbour (KNN)</h2>
</section>
<section class="slide level2">

<h3 id="global-vs-local-modeling">Global vs local modeling</h3>
<ul>
<li><p>So far we have learned two predictive modeling techniques: OLS regression and logistic regression</p></li>
<li><p>Common theme: Global, parametric models (+ probabilistic model for inference) — lots of assumptions!</p></li>
</ul>
<div class="fragment">
<ul>
<li>A different approach: <em>Local</em> modeling: I am similar to my neighbors</li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אילו מודלים לחיזוי למדנו עד כה? רגרסיה ליניארית ורגרסיה לוגיסטית. המודלים האלה הם מודלים גלובליים. באיזה מובן? במובן שיש לשניהם סט של פרמטרים, סימנו אותם בבטא, תוצר הרגרסיה הוא הסט הנאמד בטא-האט, ובכל נקודה במרחב אנחנו מכילים עליה את נוסחת הרגרסיה, שהיא משוואה, יחידה, גלובלית. לדוגמא כשמידלנו את הסיכוי לפציינטים לחלות במחלת לב לא התאמנו נוסחה שונה לחולים עם היסטוריה משפחתית וחולים בלי היסטוריה משפחתית של המחלה. שם נוסף למודלים כאלה הוא מודלים פרמטריים, והם באים עם לא מעט הנחות כמו קשר ליניארי, ואם אנחנו רוצים לבצע הסקה גם הנחות סטטיסטיות.</p>
<p>צורת מחשבה שונה לחלוטין, היא מידול לוקאלי. פציינט שאין לו היסטוריה משפחתית של מחלות לב, שהוא בן 50 ומעשן - נחפש במדגם הלמידה פציינטים אחרים שדומים לו ונראה אם להם יש מחלת לב או לא, או האחוז מהם שיש להם מחלת לב. בגישה הזאת אני לא מסתכל אפילו על חולים בני 70 שיש להם היסטוריה משפחתית והם לא מעשנים – הם לא רלוונטיים לפציינט שלי, ולכן אנחנו קוראים לגישה הזאת לוקאלית.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="simple-example-1-nearest-neighbor">Simple example: 1-nearest neighbor</h3>
<ol type="1">
<li>Define a distance over the <span class="math inline">\(\cal{X}\)</span> space. For <span class="math inline">\(x\in \mathbb{R}^p\)</span> can simply choose the Euclidean distance: <span class="math display">\[d(x,u) = \|x-u\|^2\]</span></li>
<li>For a prediction point (say <span class="math inline">\(x_0 \in Te\)</span>), find its nearest neighbor in the <span class="math inline">\(Tr\)</span> <span class="math display">\[ i_0 = \arg\min_i d(x_0,x_i)\]</span></li>
<li>Predict <span class="math inline">\(x_0\)</span> as the response at the nearest neighbor <span class="math inline">\(\hat{y}_0 = y_{i_0}\)</span></li>
</ol>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>הדוגמה הפשוטה ביותר למודל nearest neighbor היא 1-nearest-neighbor או 1NN.</p>
<p>צריך להגדיר קודם איזושהי מטריקה של מרחק בין שתי תצפיות, בין שני וקטורי X. הבחירה הפשוטה ביותר אף שהיא לאו דווקא הכי נכונה לנתונים שלכם היא מרחק אוקלידי.</p>
<p>וכשמגיעה תצפית חדשה, אין “מודל”. אנחנו מחשבים מיהו השכן הקרוב ביותר שלה במדגם הלמידה, לפי מטריקת המרחק שקבענו. חשוב לשים לב שאין כאן שום התחשבות בY, המטריקה מחושבת רק על וקטורי הX.</p>
<p>ואז, נחזה עבור התצפית את הY של השכן הכי קרוב. אנחנו יודעים אותו כי הוא במדגם הלמידה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="k-nearest-neighbor-knn-methods">K-nearest neighbor (KNN) methods</h3>
<ul>
<li>Repeat the same steps, but instead of finding the nearest neighbor only, find the <span class="math inline">\(k\)</span> nearest points in <span class="math inline">\(Tr\)</span> to <span class="math inline">\(x_0\)</span>. Assume their indexes are <span class="math inline">\(i_{01},\dots,i_{0k}\)</span></li>
</ul>
<div>
<ul>
<li class="fragment"><p>For regression predict the average: <span class="math display">\[\hat{y}_0 = \frac{1}{k} \sum_{j=1}^k y_{i_{0j}}\]</span></p></li>
<li class="fragment"><p>For classification predict the majority: <span class="math display">\[\hat{y}_0 = \left\{\begin{array}{ll} 1 &amp; \mbox{if } \frac{1}{k} \sum_{j=1}^k y_{i_{0j}} &gt; 1/2\\
0 &amp; \mbox{otherwise}\end{array} \right.\]</span></p></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>ההכללה המתבקשת של 1NN היא KNN. למה שאסתכל רק אצל השכן הכי קרוב לתצפית, אולי אסתכל אצל עשרת השכנים הקרובים ביותר שלה, ואמצע את הY שלהם באופן מסוים, אולי הדעה של עשרה שכנים היא חיזוי טוב יותר מהדעה של שכן יחיד.</p>
<p>ברגרסיה, החיזוי של תצפית יהיה ממוצע הY של K השכנים.</p>
<p>בקלסיפיקציה לשני קלאסים, החיזוי של תצפית יהיה אם הרוב שייך לקלאס 1, כלומר אם ממוצע הYים הוא מעל חצי. בפועל זה אומר תחזה אחת אם למעלה מחמישה שכנים מתוך עשרה הם גם אחת. אפשר גם לחזות את ההסתברות להיות אחת בקרב השכנים לצרכי חישוב עקומת ROC וAUC.</p>
<p>נשאלת השאלה אבל: באיזה K להשתמש?</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="reminder-saheart-data">Reminder: SAHeart Data</h3>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(saheart_X.head())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       sbp  tobacco   ldl  adiposity  typea  obesity  alcohol  age  famhist
index                                                                      
1      160    12.00  5.73      23.11     49    25.30    97.20   52        0
2      144     0.01  4.41      28.61     55    28.87     2.06   63        1
3      118     0.08  3.48      32.28     52    29.14     3.81   46        0
4      170     7.50  6.41      38.03     51    31.99    24.26   58        0
5      134    13.60  3.50      27.78     60    25.99    57.34   49        0</code></pre>
</div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(saheart_y.head())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>index
1    1
2    1
3    0
4    1
5    1
Name: chd, dtype: int64</code></pre>
</div>
</div>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>SA_Xtr, SA_Xte, SA_Ytr, SA_Yte <span class="op">=</span> train_test_split(saheart_X, saheart_y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">41</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'No. of train rows: </span><span class="sc">{</span>SA_Xtr<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">, no. train of cols: </span><span class="sc">{</span>SA_Xtr<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'No. of test rows: </span><span class="sc">{</span>SA_Xte<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">, no. test of cols: </span><span class="sc">{</span>SA_Xte<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'no. of obs in train y: </span><span class="sc">{</span>SA_Ytr<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'no. of obs in test y: </span><span class="sc">{</span>SA_Yte<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>No. of train rows: 369, no. train of cols: 9
No. of test rows: 93, no. test of cols: 9
no. of obs in train y: 369
no. of obs in test y: 93</code></pre>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>ניזכר בדאטא על פציינטים מדרום אפריקה, שבו אנחנו מעניינים לחזות האם יחלו במחלת לב או לא, 0 או 1. אלה הם הנתונים שלנו, ובשורה התחתונה יש לנו במדגם הלמידה כ370 תצפיות עם 9 משתנים, ובמדגם הטסט כ90 תצפיות.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="knn-for-saheart-classification">KNN for SAHeart (Classification)</h3>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7" data-code-line-numbers="|1|5-7|10-11|12-13|14-15|"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb7-2"><a href="#cb7-2"></a></span>
<span id="cb7-3"><a href="#cb7-3"></a>ntr <span class="op">=</span> SA_Xtr.shape[<span class="dv">0</span>]</span>
<span id="cb7-4"><a href="#cb7-4"></a>nte <span class="op">=</span> SA_Xte.shape[<span class="dv">0</span>]</span>
<span id="cb7-5"><a href="#cb7-5"></a>tr_err <span class="op">=</span> []</span>
<span id="cb7-6"><a href="#cb7-6"></a>te_err <span class="op">=</span> []</span>
<span id="cb7-7"><a href="#cb7-7"></a>kvals <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">200</span>]</span>
<span id="cb7-8"><a href="#cb7-8"></a></span>
<span id="cb7-9"><a href="#cb7-9"></a><span class="cf">for</span> k <span class="kw">in</span> kvals:</span>
<span id="cb7-10"><a href="#cb7-10"></a>    knn <span class="op">=</span> KNeighborsClassifier(n_neighbors <span class="op">=</span> k)</span>
<span id="cb7-11"><a href="#cb7-11"></a>    knn.fit(SA_Xtr, SA_Ytr)</span>
<span id="cb7-12"><a href="#cb7-12"></a>    yhat_tr <span class="op">=</span> knn.predict(SA_Xtr) <span class="op">&gt;</span> <span class="fl">0.5</span></span>
<span id="cb7-13"><a href="#cb7-13"></a>    yhat <span class="op">=</span> knn.predict(SA_Xte) <span class="op">&gt;</span> <span class="fl">0.5</span></span>
<span id="cb7-14"><a href="#cb7-14"></a>    tr_err.append(np.<span class="bu">sum</span>(yhat_tr <span class="op">!=</span> SA_Ytr) <span class="op">/</span> ntr)</span>
<span id="cb7-15"><a href="#cb7-15"></a>    te_err.append(np.<span class="bu">sum</span>(yhat <span class="op">!=</span> SA_Yte) <span class="op">/</span> nte)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="fragment">
<div class="callout callout-important callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>Is Euclidean distance suited for this task?</p>
</div>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כאן אנחנו עושים סימולציה של KNN עם K שונים.</p>
<p>אנחנו מייבאים את הקלאס KNeighborsClassifier מsklearn, מאתחילים וקטורי טעות לטריין ולטסט, ואת הK שנרצה להשתמש בו. לכל K אנחנו מאתחלים את הקלאס עם הארגומנט n_neighbors שווה k, ומתאימים על מדגם הלמידה. נשים לב שאם לא ציינו אחרת, המטריקה בשימוש היא מרחק אוקלידי, ותיכף נגיד על זה משהו.</p>
<p>מה בעצם מתבצע כאן? זה תלוי במימוש אבל בגדול, לא הרבה. הרי עיקר העבודה בKNN תהיה בשביל החיזוי, כשמגיעה תצפית חדשה, ואנחנו צריכים לחשב את המרחק בינה לכל התצפיות כדי לקבל את K השכנים הקרובים ביותר. מכל מקום זה מה שאנחנו עושים בשלב הזה לטריין ולטסט, נשים לב שהחיזוי הסופי הוא בדיוק לפי מה שלמדנו, האם ממוצע התצפיות גדול מחצי, כן או לא.</p>
<p>לבסוף אנחנו מחשבים את טעות הmissclassification עבור הטריין והטסט ומוסיפים לרשימות.</p>
<p>לפני התוצאה: כאמור, נשאל אם מרחק אוקלידי ראוי לבעיה שלנו. לא בטוח, מרחק אוקלידי, כמו שונות, מושפע מאוד מערכים קיצוניים, ובמקרה שלנו למשתנים שונות יש סקאלות שונות, כמו שניתן לראות בשקף הקודם. אז המרחק עצמו עלול להיות מושפע יותר ממשתנים מסוימים ולא מאחרים. לכן מומלץ לעשות סטנדרטיזציה אם יש צורך לפני שמריצים KNN.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8" data-code-line-numbers="|2-3|"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">4</span>))</span>
<span id="cb8-2"><a href="#cb8-2"></a>plt.plot(kvals, tr_err, color<span class="op">=</span><span class="st">'darkorange'</span>, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'train'</span> )</span>
<span id="cb8-3"><a href="#cb8-3"></a>plt.plot(kvals, te_err, color<span class="op">=</span><span class="st">'navy'</span>, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'test'</span>)</span>
<span id="cb8-4"><a href="#cb8-4"></a>plt.ylim([<span class="fl">0.0</span>, <span class="fl">0.5</span>])</span>
<span id="cb8-5"><a href="#cb8-5"></a>plt.xlabel(<span class="st">'k'</span>)</span>
<span id="cb8-6"><a href="#cb8-6"></a>plt.ylabel(<span class="st">'Misclass. Err.'</span>)</span>
<span id="cb8-7"><a href="#cb8-7"></a>plt.title(<span class="st">'KNN on SAheart'</span>)</span>
<span id="cb8-8"><a href="#cb8-8"></a>plt.legend(loc<span class="op">=</span><span class="st">"lower right"</span>)</span>
<span id="cb8-9"><a href="#cb8-9"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell fragment" data-execution_count="6">
<div class="cell-output cell-output-display">
<p><img data-src="c10_knn_trees_files/figure-revealjs/cell-7-output-1.png" width="366" height="376"></p>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כאן אנחנו מסרטטים את טעות החיזוי עבור הטריין והטסט כפונקציה של K.</p>
<p>דבר ראשון שראוי לשים לב אליו הוא טעות החיזוי במדגם הטריין עבור K = 1. הטעות הזאת היא אפס, משום שבמדגם הלמידה, איזו תצפית היא השכן הקרוב ביותר לתצפית נתונה? התצפית עצמה! אם נחזה עבור תצפית את הערך שלה מובן שלא יהיו טעויות. הדרך היחידה שיכולות להיות טעויות במקרה כזה היא אם יש ties, אם יש עוד תצפיות שיש להן וקטור X זהה בנתונים, והמודל החליט לבחור לא את התצפית המקורית כשכן הקרוב ביותר, אלא אחרת, מסיבות כלשהן, וערך הY של התצפית הזאת הוא לא ערך הY של התצפית המקורית. זה מכל מקום מה שיכול לקרות במימוש של sklearn.</p>
<p>באופן כללי לכן הקו הכתום הוא פחות מעניין, הקו הכחול הוא המעניין כי הוא מייצג את השגיאה עבור נתונים שהמודל לא ראה. אנחנו רואים כאן דפוס שיחזור על עצמו, ועוד ננתח אותו: עבור K קטן שגיאת הטסט גדולה, מגיעים לאיזשהו מינימום טעות באמצע, כאן סביב 50 שכנים, ואז הטעות מתחילה לעלות. אפשר לחשוב כבר למה זה קורה בצורה אינטואיטיבית: להתחשב רק במעט שכנים, זו החלטה מאוד רועשת, סביר להניח שמעט מאוד שכנים יכולים לטעות מאוד בחיזוי. להתחשב בהרבה שכנים זה גם לא טוב, ככל שנגדיל את הרדיוס שאומר מה זאת שכונה נקבל שכנים רחוקים כבר שלא רלוונטיים ואולי לא צריך להתחשב הם. והK האופטימלי הוא כנראה איפשהו באמצע.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="reminder-netflix-data">Reminder: Netflix Data</h3>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(netflix_X.iloc[:<span class="dv">5</span>, :<span class="dv">3</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>title  Independence Day  The Patriot  The Day After Tomorrow
0                     2            4                       4
1                     4            5                       3
2                     5            5                       5
3                     3            3                       3
4                     4            4                       4</code></pre>
</div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(netflix_Y.head())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0    3
1    4
2    5
3    2
4    5
Name: score, dtype: int64</code></pre>
</div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>NE_Xtr, NE_Xte, NE_Ytr, NE_Yte <span class="op">=</span> train_test_split(netflix_X, netflix_Y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'No. of train rows: </span><span class="sc">{</span>NE_Xtr<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">, no. train of cols: </span><span class="sc">{</span>NE_Xtr<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'No. of test rows: </span><span class="sc">{</span>NE_Xte<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">, no. test of cols: </span><span class="sc">{</span>NE_Xte<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'no. of obs in train y: </span><span class="sc">{</span>NE_Ytr<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'no. of obs in test y: </span><span class="sc">{</span>NE_Yte<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>No. of train rows: 8000, no. train of cols: 14
No. of test rows: 2000, no. test of cols: 14
no. of obs in train y: 8000
no. of obs in test y: 2000</code></pre>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נעשה את אותו הדבר על הדאטא של נטפליקס, רק ברגרסיה, עם 14 הסרטים עבורם יש לנו דאטא מלא. ניזכר שבמדגם הלמידה יש 8000 צופים שדירגו מ1 עד 5 14 סרטים, ובמדגם הטסט יש 2000 צופים. וניזכר שהפעם הY שלנו הוא כמותי, לא קטגוריאלי, אנחנו ברגרסיה.</p>
<p>כאן, למשל, אפשר כבר לשער שמרחק אוקלידי יהיה מתאים יותר, כי כל הסרטים מדורגים באותה סקאלה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="knn-for-netflix-regression">KNN for Netflix (Regression)</h3>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb15" data-code-line-numbers="|1|7|10-11|12-13|14-15|"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsRegressor</span>
<span id="cb15-2"><a href="#cb15-2"></a></span>
<span id="cb15-3"><a href="#cb15-3"></a>ntr <span class="op">=</span> NE_Xtr.shape[<span class="dv">0</span>]</span>
<span id="cb15-4"><a href="#cb15-4"></a>nte <span class="op">=</span> NE_Xte.shape[<span class="dv">0</span>]</span>
<span id="cb15-5"><a href="#cb15-5"></a>tr_err <span class="op">=</span> []</span>
<span id="cb15-6"><a href="#cb15-6"></a>te_err <span class="op">=</span> []</span>
<span id="cb15-7"><a href="#cb15-7"></a>kvals <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">500</span>]</span>
<span id="cb15-8"><a href="#cb15-8"></a></span>
<span id="cb15-9"><a href="#cb15-9"></a><span class="cf">for</span> k <span class="kw">in</span> kvals:</span>
<span id="cb15-10"><a href="#cb15-10"></a>    knn <span class="op">=</span> KNeighborsRegressor(n_neighbors <span class="op">=</span> k)</span>
<span id="cb15-11"><a href="#cb15-11"></a>    knn.fit(NE_Xtr, NE_Ytr)</span>
<span id="cb15-12"><a href="#cb15-12"></a>    yhat_tr <span class="op">=</span> knn.predict(NE_Xtr)</span>
<span id="cb15-13"><a href="#cb15-13"></a>    yhat <span class="op">=</span> knn.predict(NE_Xte)</span>
<span id="cb15-14"><a href="#cb15-14"></a>    tr_err.append(np.sqrt(np.<span class="bu">sum</span>((yhat_tr <span class="op">-</span> NE_Ytr)<span class="op">**</span><span class="dv">2</span>) <span class="op">/</span> ntr))</span>
<span id="cb15-15"><a href="#cb15-15"></a>    te_err.append(np.sqrt(np.<span class="bu">sum</span>((yhat <span class="op">-</span> NE_Yte)<span class="op">**</span><span class="dv">2</span>) <span class="op">/</span> nte))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>התהליך כאן הוא כמעט זהה, רק שאנחנו משתמשים בקלאס KNeighborsRegressor. כשאנחנו חוזים אנחנו מקבלים כמות ממוצעת על פני השכנים בyhat. לבסוף טעות החיזוי שלנו היא הRMSE שמחושב כאן.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">4</span>))</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>plt.plot(kvals, tr_err, color<span class="op">=</span><span class="st">'darkorange'</span>, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'train'</span> )</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>plt.plot(kvals, te_err, color<span class="op">=</span><span class="st">'navy'</span>, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'test'</span>)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>plt.ylim([<span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'k'</span>)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'RMSE'</span>)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'KNN on Netflix'</span>)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">"lower right"</span>)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>plt.show() </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img data-src="c10_knn_trees_files/figure-revealjs/cell-13-output-1.png" width="366" height="376"></p>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>גם כאן קיבלנו דפוס דומה, שגיאת החיזוי, כאן הRMSE, מתקרבת לאפס אבל היא לא זהותית אפס במדגם הטריין, כי יש כנראה ties, משתמשים עם דפוס דירוג זהה.</p>
<p>והקו הכחול שמייצג את הטסט הוא המעניין, והוא מראה שבסביבות K = 100 שכנים קרובים ביותר מגיעים למינימום שגיאה, מעבר לזה זה כבר לא משנה, אז כנראה שנבחר כאן למודל סופי K = 100.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="the-problems-with-knn">The problems with KNN?</h3>
<ol type="1">
<li><p>What is the appropriate distance metric?</p></li>
<li><p>If the data are “sparse” in the space, nearest neighbors are far and the results can be very bad</p></li>
</ol>
<ul>
<li><p><em>Curse of dimensionality</em>: if the dimension <span class="math inline">\(p\)</span> is high, data are by definition sparse</p></li>
<li><p>KNN fails in these settings</p></li>
</ul>
<div class="fragment">
<p>Interesting solution to both problems: Adaptive local methods</p>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>היתרון הכי גדול של KNN הוא ברור: אין הנחות. כל לקוח של המודל יכול להבין את זה, קח את השכנים הקרובים ביותר לתצפית נתונה, ותחזה את הממוצע שלהם בשבילה.</p>
<p>אילו בעיות בכל זאת יש עם המודל הזה שבפועל לא משיג חיזויים טובים על נתונים מסוימים כמו מודלים אחרים שנלמד?</p>
<p>קודם כל בחירת המרחק. אמרנו שאין הנחות, אבל כאן דווקא כן מסתתרות הנחות, איך נראים הנתונים שמתאים להם מרחק אוקלידי או דווקא מרחק אחר.</p>
<p>בעיה משמעותית היא כשאנחנו רוצים לבצע KNN על דאטא שיכול להיות דליל באיזורים מסוימים. אם נקודה רחוקה מאוד מהשכן הכי קרוב שלה, KNN לא מביא את זה לידי ביטוי, למרות שהשכן אולי כבר לא רלוונטי. כשהמימד של הבעיה, מספר המשתנים p גבוה מאוד, אנחנו יכולים להיות בטוחים שהתופעה הזאת תקרה, והיא נקראת קללת המימד, או curse of dimensionality.אנחנו רגילים לחשוב על מרחב דו-מימדי או תלת-מימדי, אבל מרחב ממימד גבוה מאוד – למשל אם היינו לוקחים את כל 99 הסרטים של נטפליקס – יהיה מאוכלס בצורה דלילה מאוד. כל נקודה חדשה שנרצה לחזות עבורה, השכן הכי קרוב לה יהיה כבר די רחוק. וכל שיטה מבוססת שכנים תיכשל במצב זה.</p>
<p>רעיון אחר שמטרתו לטפל בדיוק בבעיה הזאת של קללת המימד: נגדיר מה זו שכונה של תצפית, לא באמצעות איזושהי מטריקת מרחק כפי שעשינו, אלא בהסתכלות על הנתונים עצמם, בצורה אדפטיבית. ננסה לחלק את המרחב לחלקים שבתוכם Y, המשתנה שאנחנו רוצים לאמוד, משתנה כמה שפחות, ההתפלגות שלו כמה שיותר אחידה. כעת, כשתגיע תצפית חדשה נסווג אותה לשכונה שמתאימה לה, שכונה שאנחנו יודעים מה הY שם פחות או יותר, וזו יכולה להיות שכונה גדולה, קטנה, זה יוחלט בצורה אדפטיבית כלומר על-ידי הצצה על Y, מה שלא עשינו עם KNN, שם לא הבטנו בכלל בY.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="decision-trees" class="slide level2 title-slide center">
<h2>Decision Trees</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>עצי החלטה הם דוגמא מצוינת לבחירת מודל בצורה אדפטיבית, על-ידי הצצה אל Y תוך כדי בניית המודל. נראה קודם איך נראה עץ החלטה בפועל, נראה מה הפרמטר הכי חשוב שמשפיע על הביצועים שלו, ורק אחר-כך נשאל איך לבנות עץ החלטה. יש הרבה סוגים של עצי החלטה, זה תחום נרחב, אנחנו נתמקד בגירסה אחת, הגירסה הקלאסית של עצי החלטה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="adaptive-local-methods-trees">Adaptive local methods: Trees</h3>
<ul>
<li><p>The idea: split the space <span class="math inline">\(\cal{X}\)</span> into <em>neighborhoods</em> by recursive partioning</p></li>
<li><p>Each time: pick a region and split it into two (or more) regions</p></li>
<li><p>Can be described using a tree — binary tree if all splits are in two. Titanic example:</p></li>
</ul>
<div class="fragment">
<p><img data-src="images/CART_tree_titanic_survivors.png"></p>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כאמור, במבט על, נרצה לחלק את מרחב הנתונים, מרחב X, לשכונות, וכמו שרשום כאן נעשה זאת בצורה רקורסיבית או אדפטיבית. כל פעם נגיע לאיזור נתון, ונחלק אותו לשניים בצורה שתחלק את Y לשני איזורים ששונים זה מזה כמה שיותר. תיכף ניתן הגדרה מדויקת. נזכיר רק שאם מחלקים לשני איזורים מדובר בעץ בינארי, שראיתם אולי בקורסים אחרים, יש כמובן גירסאות של עצים עם חלוקה ליותר משני ענפים.</p>
<p>אז איך עץ נראה על נתוני הטיטאניק שראינו. השאלה הראשונה מסתבר שמחלקת את המרחב הכי טוב לפי הגדרה שעוד נראה, היא מה מין הנוסע. אם הנוסע ממין נקבה, נראה שאין צורך ביותר שאלות, 36 אחוזים מהמדגם היו נשים והם שרדו בסיכוי 0.73. אם הנוסע ממין זכר לעומת זאת, נראה שצריך לשאול עוד שאלות. השאלה הבאה החשובה ביותר היא מה גיל הנוסע האם הוא מעל 9.5. אם כן, כלומר הגענו ל”שכונה” של נערים ומבוגרים ממין זכר, אין צורך להמשיך יותר, 61% מהמדגם שייכים לשכונה הזאת והם שרדו בסיכוי 0.17. אם לא גדול, כלומר ילד קטן, נשאל עוד שאלה על המשתנה מספר אחים ורק אז נגיע לסוף העץ.</p>
<p>זהו עץ לקלסיפיקציה. מה נחזה בעץ כזה? נחזה את מה שראינו בעלים הסופיים של העץ. כמו בKNN, אם נרצה הסתברויות חזויות, נחזה את ההסתברות לשרוד בכל עלה, שהיא אחוז השורדים בעלה הזה, בשכונה הזאת. אם נרצה קלאס סופי נחזה אולי האם הסיכוי הזה לשרוד בעלה גדול מחצי או לא, כאן למשל עבור נשים הן שרדו בסיכוי 0.73 ולכן נחזה עבור תצפיות חדשות של נשים, שלא ראינו, שישרדו.</p>
<p>עוד מושג חשוב: עומק העץ. מה עומק העץ המקסימלי כאן? 3. כלומר כל תצפית תגיע לסוף העץ ותקבל חיזוי עם מקסימום 3 שאלות.</p>
<p>מה לא ראינו? איך העץ הזה מבצע על נוסעי טיטאניק שלא ראינו במדגם טסט. אולי צריך לשאול פחות שאלות? אולי יותר?</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="tree-for-saheart-classification">Tree for SAHeart (Classification)</h3>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb17" data-code-line-numbers="|1|3-4|5|"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier, plot_tree</span>
<span id="cb17-2"><a href="#cb17-2"></a></span>
<span id="cb17-3"><a href="#cb17-3"></a>tree <span class="op">=</span> DecisionTreeClassifier(max_depth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb17-4"><a href="#cb17-4"></a>tree.fit(SA_Xtr, SA_Ytr)</span>
<span id="cb17-5"><a href="#cb17-5"></a>plot_tree(tree, feature_names<span class="op">=</span>SA_Xtr.columns)</span>
<span id="cb17-6"><a href="#cb17-6"></a>plt.show() </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell fragment" data-execution_count="13">
<div class="cell-output cell-output-display">
<p><img data-src="c10_knn_trees_files/figure-revealjs/cell-14-output-1.png" width="466" height="389"></p>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נראה את המימוש של sklearn על הנתונים של חולי לב מדרום אפריקה, שמזכיר מאוד כל מימוש שראינו עד כה.</p>
<p>אני מייבא את הקלאס DecisionTreeClassifier, אני מאתחל אותו, ונשים לב שאני מבקש max_depth שווה ל2, כלומר לכל היותר נשאל שתי שאלות על כל פציינט כדי להגיע לחיזוי. גידול העץ עצמו נעשה עם המתודה fit, ועוד לא דיברנו על איך.</p>
<p>באוביקט tree קיים העץ ואני משתמש כאן במתודה plot_tree כדי לצייר אותו.</p>
<p>מה העץ שלנו אומר?</p>
<p>קודם כל הוא מחלק את המדגם לפציינטים בני למעלה מ50 ולפציינטים מתחת גיל 50. שאלה שניה עבור הפציינטים המבוגרים יותר היא מידת השימוש בטבק כלומר עישון. אם הפציינט מעשן מעל כמות מסויימת הגענו לעלה סופי, יש בו 95 פציינטים במדגם, שמתוכם 65 חלו במחלת לב, כלומר סיכוי של כשני שליש.</p>
<p>בצד האחר של העץ, עבור פציינטים צעירים יותר, השאלה היא לגבי ציון בשאלון אישיות שנועד לבחון אם אתה type A. טייפ A זה טיפוס לחוץ, קשה, הישגי. אם אתה ברמה נמוכה במדד הזה, אתה שייך לאיזור או שכונה סופיים שם הסיכוי לחלות במחלת לב קטן יחסית, ואם אתה ברמה גבוהה במדד הזה, גילינו תת-איזור שכזה עם 14 פציינטים, עם סיכוי גבוה מאוד לחלות, למעלה מ70 אחוז.</p>
<p>שימו-לב עוד לשני דברים: כמה העץ קל לפירוש, לא צריך להיות מדען נתונים כדי להבין את הלוגיקה שבאלגוריתם הזה מה שמסביר הרבה מהפופולריות שלו. וגם, מדובר באלגוריתם שמאוד קל לממש. גם אם העץ נבנה בפייתון, בסופו של דבר בכל שפת מחשב אפשר לממש אותו למשל עם פרוצדורות if else. זה שתי שאלות על תצפית ונותנים לה חיזוי, פשוט מאוד.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>ntr <span class="op">=</span> SA_Xtr.shape[<span class="dv">0</span>]</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>nte <span class="op">=</span> SA_Xte.shape[<span class="dv">0</span>]</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>tr_err <span class="op">=</span> []</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>te_err <span class="op">=</span> []</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>ds <span class="op">=</span> [<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">7</span>, <span class="dv">10</span>, <span class="dv">15</span>]</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> depth <span class="kw">in</span> ds:</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    tree <span class="op">=</span> DecisionTreeClassifier(max_depth <span class="op">=</span> depth)</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>    tree.fit(SA_Xtr, SA_Ytr)</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    yhat_tr <span class="op">=</span> tree.predict(SA_Xtr) <span class="op">&gt;</span> <span class="fl">0.5</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> tree.predict(SA_Xte) <span class="op">&gt;</span> <span class="fl">0.5</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>    tr_err.append(np.<span class="bu">sum</span>(yhat_tr <span class="op">!=</span> SA_Ytr) <span class="op">/</span> ntr)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>    te_err.append(np.<span class="bu">sum</span>(yhat <span class="op">!=</span> SA_Yte) <span class="op">/</span> nte)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="15">
<div class="cell-output cell-output-display">
<p><img data-src="c10_knn_trees_files/figure-revealjs/cell-16-output-1.png" width="367" height="376"></p>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אבל עדיין לא ענינו על איך בוחרים את הפרמטר העיקרי כאן של max_depth, נעשה תרגיל דומה למה שעשינו עבור ערכים שונים של K עם KNN. כאן אנחנו משתמשים בערכים שונים מ2 עד 15, מאמנים על הטריין, חוזים על הטסט, ושואלים מהי שגיאת החיזוי, על הטריין ועל הטסט.</p>
<p>התקבל דפוס שמזכיר מאוד את מה שראינו בKNN: עבור מדגם הלמידה עוד ועוד שאלות לא יכולות להזיק, בסוף נהיה נורא נורא ספציפיים, ונחזה עבור כל תצפית בדיוק את עצמה ונגיע ל0 אחוז שגיאת חיזוי. אבל זה לא מה שמעניין אותנו, מה שמעניין יותר הוא מדגם הטסט ושוב אנחנו רואים שעץ שטוח מדי הוא פשטני מדי, לא שואלים מספיק שאלות. ואילו עץ עמוק מדי הוא ספציפי מדי למדגם הטריין, קורה מה שעוד נכנה כoverfitting, ומקבלים גם כן שגיאה גדולה. איפשהו באמצע כאן בעומק 3 שאלות מתקבלת התוצאה הטובה ביותר.</p>
<p>עוד חשוב להדגיש שהעקומה שהתקבלה לא חלקה, כי אנחנו מאוד תלויים בחלוקה ספציפית של הנתונים לטריין ולטסט. סביר להניח שאם נמצע את העקומה הזאת על כמה חלוקות, כל פעם נחלק אחרת, נקבל עקומה מעט יותר חלקה עם תשובה ברורה יותר, עבור איזה עומק מגיעה שגיאת החיזוי של הטסט למינימום, על פני הרבה חלוקות.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="tree-for-netflix-regression">Tree for Netflix (Regression)</h3>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeRegressor</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>tree <span class="op">=</span> DecisionTreeRegressor(max_depth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>tree.fit(NE_Xtr, NE_Ytr)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>plot_tree(tree, feature_names<span class="op">=</span>NE_Xtr.columns)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img data-src="c10_knn_trees_files/figure-revealjs/cell-17-output-1.png" width="763" height="463"></p>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>עץ החלטה הוא כאמור גם עבור רגרסיה, למשל על הנתונים של נטפליקס. כאן אני עושה זאת עם הקלאס DecisionTreeRegressor, גם כן עם max_depth 2, ומתקבל העץ הבא:</p>
<p>שאלה ראשונה שנשאל כדי לחזות את הציון של איזו מין שוטרת היא האם אהבת או לא את סוויט הום אלבמה. אם כן נשאל האם אהבת גם את מה נשים רוצות, קומדיה רומנטית עם מל גיבסון והלן האנט. אם ענית כן לשתי השאלות נחזה שתאהבי מאוד את איזו מין שוטרת עם ציון 4.29. שכונה אחרת היא מי שתענה שלא אהבה את סוויט הום אלבמה, ולא אהבה את אישה יפה, עבורה נחזה ציון נמוך יחסית של 3.11.</p>
<p>נשים לב לשני דברים חשובים כאן: אחד שבאמת נראה שהמודל חילק את המרחב לארבע שכונות די זרות, הוא חוזה ציון שונה לחלוטין לכל אחת. הדבר השני הוא שהחיזוי לכל קבוצה כזאת ברגרסיה, הוא מספר אחד ויחיד, לכל מי שהגיע לעלה הזה, לדוגמא 3.11. זה נותן לכם איזשהו רמז למה מודל של עץ הוא בכל זאת מאוד לא גמיש ועל דרכים לשפר אותו.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>ntr <span class="op">=</span> NE_Xtr.shape[<span class="dv">0</span>]</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>nte <span class="op">=</span> NE_Xte.shape[<span class="dv">0</span>]</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>tr_err <span class="op">=</span> []</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>te_err <span class="op">=</span> []</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>ds <span class="op">=</span> [<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">7</span>, <span class="dv">10</span>, <span class="dv">15</span>]</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> depth <span class="kw">in</span> ds:</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>    tree <span class="op">=</span> DecisionTreeRegressor(max_depth <span class="op">=</span> depth)</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>    tree.fit(NE_Xtr, NE_Ytr)</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>    yhat_tr <span class="op">=</span> tree.predict(NE_Xtr)</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> tree.predict(NE_Xte)</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>    tr_err.append(np.sqrt(np.<span class="bu">sum</span>((yhat_tr <span class="op">-</span> NE_Ytr)<span class="op">**</span><span class="dv">2</span>) <span class="op">/</span> ntr))</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>    te_err.append(np.sqrt(np.<span class="bu">sum</span>((yhat <span class="op">-</span> NE_Yte)<span class="op">**</span><span class="dv">2</span>) <span class="op">/</span> nte))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="18">
<div class="cell-output cell-output-display">
<p><img data-src="c10_knn_trees_files/figure-revealjs/cell-19-output-1.png" width="367" height="376"></p>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כשאנחנו עושים את התרגיל של בחירת עומקים שונים וציור הטריין והטסט error עבורם אנחנו מקבלים את הדפוס המוכר, נשים לב רק שכאן הטעות היא הRMSE. בכל מקרה עבור מדגם הטסט הזה הגענו לRMSE הכי נמוך של 0.85 בערך. אם תיזכרו בתוצאה של רגרסיה ליניארית עבור חלוקה זו לטריין וטסט, זה קצת יותר גבוה, לא נראה ששיפרנו בהרבה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="rectangular-regions">Rectangular Regions</h3>

<img data-src="images/recursive_partitioning.png" class="r-stretch"><aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>מילה אחרונה על העץ שלנו. נשים לב שכל תצפית בסופו של דבר שייכת לאיזור אחד בלבד, כלומר הם זרים זה לזה, וכל המרחב “מתכסה”. יותר מזה, אם נשרטט את המרחב של X כמו בדוגמה כאן שיש רק שני משתנים X1 וX2, נראה שאיזורי החלוקה הם מלבניים. לדוגמא אם X1 קטן מ1 נחזה איזושהי כמות בטא1, המשמעות היא שמשמאל ל-1 אנחנו כבר החלטנו, נוצר מלבן. ואת האיזור שהגענו אליו מימין ל1 נחלק אולי למלבנים נוספים. בתלת מימד האיזורים יהיו כמובן, תיבות. לחלוקה כזאת אנחנו קוראים partition.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="building-a-cart" class="slide level2 title-slide center">
<h2>Building a CART</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נראה כעת איך נבנה עץ לרגרסיה. הדרך שבה נבנה עץ לקלאסיפיקציה מאוד דומה, נגיד גם על זה כמה מילים.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="defining-a-decision-tree-algorithm">Defining a decision tree algorithm</h3>
<p>There are three main aspects to designing a decision tree algorithm for classification or regression:</p>
<ol type="1">
<li>How do we choose a split at each node of the tree?</li>
<li>How do we decide when to stop splitting?</li>
<li>How do we fit a value <span class="math inline">\(\hat{y}\)</span> for each terminal node (<em>leaf</em>)?</li>
</ol>
<div class="fragment">
<p>Some well known decision tree algorithms:</p>
<ul>
<li><p>ID3, C4.5, C5.0: for classification only, invented in the CS/machine learning community</p></li>
<li><p>Classification and regression trees (CART): invented in the statistics community</p></li>
<li><p>We are going to mostly describe CART, which is the basis for modern methods we discuss later</p></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>מה עושה בעצם העץ? הוא עושה חלוקה של המרחב של X לשכונות או איזורים זרים, בכל איזור ואיזור Y מתפלג כמה שפחות. זה הפלט שהיינו רוצים לקבל מאלגוריתם שבונה עץ.</p>
<p>אז הגדרנו כבר רעיון כללי ונשאר לנו לברר כמה פרטים ספציפיים:</p>
<p>שאלה ראשונה, איך תתבצע החלוקה לשניים בכל צומת. שאלה אחרת היא מתי מפסיקים. בדוגמאות שלנו תמיד הגדרנו לעץ עומק מקסימלי אבל יכולות להיות דרכים אחרות, אולי איזשהו קריטריון שמסתכל על הדאטא עצמו ולא פרמטר קשוח. ועל השאלה השלישית ענינו גם כן, מה יהיה הערך החזוי עבור תצפית שמגיעה לעלה, אבל רמזנו שיכולות להיות אולי תשובות חכמות יותר.</p>
<p>שלוש ההחלטות האלה מגדירות סוגים שונים של עצים, אני עושה כאן ניים דרופינג לכמה מהם. העץ הקלאסי שגם ממומש בsklearn הוא CART, ראשי תיבות של classification and regression tree, ואותו נלמד כעת.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="cart-for-regression-splitting-process">CART for regression: splitting process</h3>
<div>
<ul>
<li class="fragment"><p>Criterion: Minimize RSS on training.</p></li>
<li class="fragment"><p>Given set of <span class="math inline">\(r\)</span> observations in current node, define for a variable <span class="math inline">\(j\)</span> and possible split point <span class="math inline">\(s\)</span>: <span class="math display">\[L(j,s) = \{i\leq r: x_{ij} \leq s\}\;,\;\; R(j,s) = \{i\leq r: x_{ij} &gt; s\}\]</span> <span class="math display">\[\bar{y}_L =\frac{\sum_{i \in L(j,s)} y_i}{|L(j,s)|}\;,\; \bar{y}_R=\frac{\sum_{i \in R(j,s)} y_i}{|R(j,s)|}\]</span> <span class="math display">\[RSS(j,s) = \sum_{i \in L(j,s)} (y_i - \bar{y}_L)^2 + \sum_{i \in R(j,s)} (y_i - \bar{y}_R)^2\]</span></p></li>
<li class="fragment"><p>And find the pair <span class="math inline">\(j, s\)</span> which minimize this RSS among all possible pairs — this is the split we do</p></li>
<li class="fragment"><p>Split the node into two according to the chosen split and continue</p></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אז השאלה הראשונה היא: מהו הקריטריון לחלוקה. בעץ רגרסיה CART הקריטריון הזה יהיה הRSS, בדומה לקריטריון ברגרסיה ליניארית שכבר נתקלנו בו. למה הכוונה.</p>
<p>הגענו לצומת מסוים בעץ (להדגים) ויש לנו קבוצה מסוימת של תצפיות שאנחנו רוצים לחלק. הצעת חלוקה מסוימת אומרת להסתכל על משתנה j ועל ערך מסוים של המשתנה הזה s. נשים את כל התצפיות שקטנות במשתנה הזה מS בLeft, שכונה שמאלית, ואת כל התצפיות שגדולות במשתנה הזה מS בRight, שכונה ימנית. כאן אנחנו מציצים בY ובודקים מה הממוצע שלו בשכונה השמאלית, ובשכונה הימנית. נרצה שכל שכונה תהיה הומוגנית כמה שיותר, כלומר קרובה לממוצע שלה כמה שיותר, לכן הקריטריון להביא למינימום הוא סכום הRSS של שתי השכונות, סכום השגיאות הריבועיות של התצפיות מהממוצע שלהן בשכונת שמאל, ועוד סכום השגיאות הריבועיות של התצפיות מהממוצע שלהן, בשכונה הימנית.</p>
<p>עכשיו זאת הצעת חלוקה אחת. כדי למצוא את החלוקה הטובה ביותר בנקודה שהגענו אליה, נצטרך לעבור על כל המשתנים האפשריים, ובכל משתנה על כל הערכים שאפשר לחלק בהם. כלומר בכל צומת האלגוריתם שלנו בזמן אימון עושה די הרבה, צריך לעבור על כל הזוגות האפשריים של j, s. הזוג שיביא למינימום את הRSS הוא הזוג הנבחר.</p>
<p>כעת נעשה את הפיצול, ונמשיך בצורה רקורסיבית בכל אחד משני הצמתים שיצרנו. לדוגמא בדאטא של נטפליקס, האלגוריתם הביט בכל 14 הסרטים, ובכל סרט בכל ציון, ומצא שהחלוקה שתביא למינימום את הRSS, כלומר היא מחלקת לשתי קבוצות ההומוגניות ביותר של אנשים שאוהבים את איזו מין שוטרת, ואנשים שלא אוהבים את איזו מין שוטרת – היא החלוקה אם נתת ציונים גבוהים או נמוכים לסרט סוויט הום אלבמה.</p>
<p>נשים לב עוד, שאחרי החלוקה התצפיות בכל קבוצה כבר לא משפיעות יותר על החלוקה בקבוצה האחרת. זהו. אין להן יותר השפעה, לא נחזור אחורה בעץ הקלאסי לראות אולי היתה יכולה להיות חלוקה טובה יותר. כך שמדובר באלגוריתם greedy, חמדן.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="cart-for-regression-stopping-criteria">CART for regression: stopping criteria</h3>
<ul>
<li>Why limit tree size?</li>
</ul>
<div>
<ul>
<li class="fragment"><p>Overfitting, computation,…</p></li>
<li class="fragment"><p>In the examples above: <em>max_depth</em> of tree</p></li>
<li class="fragment"><p>Other options: size of nodes not too small, improvement in RSS not too small,…</p></li>
<li class="fragment"><p>Interesting approach of CART: grow a very big tree and <em>prune</em> it to smaller tree using test set performance (actually cross-validation, which we have not yet discussed)</p></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>ההחלטה השניה ברשימה שלנו היתה מתי להחליט שדי, אפשר לעצור לגדל את העץ. למה בכלל להפסיק לגדל את העץ? למה לא לתת לו לגדול ולגדול?</p>
<p>ראינו בנתונים למה לא, בדרך כלל העץ יעשה אוברפיטינג למדגם הלמידה, והחיזוי שלו יהיה באיכות נמוכה על נתונים שלא ראה. סיבה אחרת יכולה להיות חישובית, האימון וגם אחר כך החיזוי ייקחו יותר זמן ככל שנאפשר עצים עמוקים יותר.</p>
<p>מכל מקום, ראינו דרך אחת להחליט, והיא פרמטר גלובלי של max_depth מקסימום עומק לעץ. בצורה כזאת נקבל עצים שהם balanced, כל התצפיות יעברו דרך אותו מספר שאלות בטרם יקבלו חיזוי.</p>
<p>דרך אחרת יכולה להיות בכל צומת וצומת בעץ לשאול האם שווה להמשיך, כלומר להחליט בצורה מקומית. אפשר לחשוב גם כאן על עוד פרמטר כמו מספר מינימלי של תצפיות בעלה, לדוגמא 10. אני לא רוצה לעשות עצים שבסוף מגיעים להחלטה על פחות מ10 תצפיות. אפשר לחשוב על להביט בקריטריון RSS למשל, ולראות שהוא משתפר מעל איזשהו ערך סף. אבל שימו לב מה אמרתי, האם הוא משתפר מעבר לאיזשהו סף, לא משתפר באופן כללי כי מה תמיד מובטח לנו, כמו ברגרסיה ליניארית? הRSS על מדגם הלמידה עם עוד שאלות, או עוד משתנים, יכול רק להשתפר. אז נקפיד לקבוע איזשהו ערך שרק אם הוא משתפר יותר ממנו שווה להמשיך לפצל. בכל מקרה בדרך זאת יכולים להיווצר עצים לא מאוזנים כמו העץ של הטיטאניק שראינו. אם הנוסע ממין נקבה ראינו שאין צורך לשאול יותר שאלות, ואם הוא ממין זכר שאלנו עוד שאלות.</p>
<p>בCART יש רעיון נוסף, והוא לגדל את העץ כמה שיותר, ואז בשלב נוסף לבצע לו קטימה או pruning. לא ניכנס לעומק הpruning, אבל בגדול מדובר עכשיו להסתכל שוב על כל הצמתים של העץ ולהסתכל האם ההפחתה שקיבלנו בRSS הייתה שווה את זה, כשאנחנו נותנים עוד איזשהו עונש של מורכבות, complexity על מספר העלים הסופיים במודל. ניקח את העץ הקטום שמביא למינימום את הקריטריון החדש הזה אחרי התחשבות בעונש הזה על מספר גדול מדי של איזורים.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="cart-for-regression-fits-at-leaves">CART for regression: fits at leaves</h3>
<ul>
<li><p>Similar to OLS, we want to estimate <span class="math inline">\(\hat{y}(x) \approx E(y|x)\)</span></p></li>
<li><p>We interpret the splitting as finding <em>homogeneous areas</em> with similar <span class="math inline">\(y\)</span> values in our data, hence hopefully similar <span class="math inline">\(E(y|x).\)</span></p></li>
<li><p>Consequently, given a leaf (terminal node) with set of observations <span class="math inline">\(Q \subseteq \{1,\dots,n\}\)</span>, we estimate: <span class="math display">\[\hat{y} = \bar{y}_Q = \frac{\sum_{i \in Q} y_i}{|Q|}\]</span></p></li>
</ul>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>ההחלטה השלישית והאחרונה ברשימה שלנו היתה מה בסופו של דבר אנחנו חוזים. ראינו כבר שבעץ רגרסיה נחזה את הממוצע. אבל זאת לא החלטה שרירותית, כמו ברגרסיה ליניארית אנחנו בעצם ממדלים את התוחלת המותנית של Y אחרי שראינו את X.</p>
<p>ואם Y משתנה כמה שפחות כי העלה שלנו מאוד הומוגני, התוחלת הזאת היא קבועה פחות או יותר.</p>
<p>ואנחנו יודעים שבכל עלה ועלה, האומד הכי טוב תחת הפסד ריבועי כמו שלנו לתוחלת, הוא ממוצע המדגם שהגיע לעלה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="cart-and-others-for-classification">CART and others for classification</h3>
<ul>
<li><p>Various splitting criteria: Gini, information gain, log-likelihood, all give similar trees</p></li>
<li><p>Not a good idea: using misclassification rate as splitting criterion</p></li>
<li><p>Stopping criteria: similar ideas to regression</p></li>
<li><p>Fits at leaves: usually empirical % of classes (or majority if need hard classification)</p></li>
</ul>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אז איך בונים עץ לקלסיפיקציה?</p>
<p>יש הרבה אפשרויות לקריטריונים של חלוקה, כאן הם ייקראו אולי מדדים לimpurity, עד כמה שתי השכונות השמאלית והימנית הן pure או טהורות, כל התצפיות מקבלות בהן אותו קלאס. יש מדדים שונים שלא נעבור עליהם, כפי שראיתם המדד הדיפולטיבי בsklearn הוא כרגע הג’יני.</p>
<p>גם מבחינת קריטריון עצירה אין הרבה שינוי מעץ לרגרסיה, ראינו שגם כאן אפשר להגדיר פרמטר גלובלי של max_depth, ואפשר גם להחליט לוקלאית כמו מינימום מספר תצפיות לעלה.</p>
<p>וכשמגיעים לעלה, כמו שראינו, אם רוצים סיווג קשיח חוזים פשוט את הרוב –ושימו לב שכאן קל מאוד להכליל להרבה קלאסים. אם רוצים הסתברות אפשר להתאים את אחוז התצפיות שהן קלאס “1”, ואז יש לזה גם פרשנות יפה, זה בדיוק התוחלת המותנית של Y בהינתן X כי Y הוא משתנה ברנולי שמקבל 0 או 1, והתוחלת שלו היא ההסתברות עצמה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="closing-remarks" class="slide level2 title-slide center">
<h2>Closing Remarks</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נסיים את הדיון בעצים במספר יתרונות וחסרונות שלהם.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="important-properties-of-trees">Important properties of trees</h3>
<h4 id="categoraical-features">1. categoraical features</h4>
<ul>
<li>Real life data often includes categorical features that have many values but are important for prediction, like:
<ol type="1">
<li>City of residence</li>
<li>University/department</li>
<li>Customer class</li>
</ol></li>
</ul>
<div class="fragment">
<ul>
<li><p>CART always does binary splits. For a categorical variable with <span class="math inline">\(K\)</span> values <span class="math inline">\({\cal G} = \{g_1,\dots,g_K\}\)</span> it divides <span class="math inline">\(\cal G\)</span> into two groups <span class="math inline">\(\cal G_1, \cal G_2\)</span> so that: <span class="math display">\[L(j) = \{i : x_{ij} \in \cal G_1\}\;,\;\;R(j) = \{i : x_{ij} \in \cal G_2\}.\]</span></p></li>
<li><p>C4.5/C5.0 do multi-way non-binary splits</p></li>
<li><p>Presents interesting computational and statistical challenges</p></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>עצים טובים מאוד כשיש בנתונים משתנים קטגוריאליים, שיש בהם הרבה קטגוריות אבל הם לא מספרים, לדוגמא העיר שבה גר פציינט או סוג ההשכלה שלו, איזה תואר למד. זה בניגוד לשיטות שלמדנו עד עכשיו כמו רגרסיה או KNN, שלא טבעי להן לקבל משתנים קטגוריאליים.</p>
<p>לגבי עצים, אנחנו יכולים רק לעשות רק פיצול בינארי. אנחנו לא יכולים לפצל משתנה קטגוריאלי לפי איזשהו סף, אבל אנחנו כן יכולים לחלק אותו לשתי קבוצות של קטגוריות G1 ו-G2. כל תצפית שיש לה קטגוריה ששייכת לG1 תלך ימינה, וכל תצפית שיש לה קטגוריה ששייכת לG2 תלך שמאלה.</p>
<p>יש אלגוריתמים אחרים למשל שמחלקים את הצומת ל3 ענפים אם יש 3 קטגוריות כמו C5, שלא דיברנו עליו.</p>
<p>מה לא סיפרתי לכם? בעיקר איך העץ מחלק לשתי חלוקות של קטגוריות, הרי אם יעבור על כל החלוקות האפשריות של שתי קבוצות של קטגוריות זה יהיה סדר גודל של 2 בחזקת K קטגוריות, וזה צריך לעשות בכל צומת וצומת. אז זה באמת לא מה שCART עושה, מי שרוצה יכול לקרוא עוד על זה בספרים מתאימים, באופן כללי משתנים קטגוריאליים ואיך להתמודד איתם זה נושא מרתק סטטיסטית.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="important-properties-of-trees-1">Important properties of trees:</h3>
<h4 id="missing-data">2. missing data</h4>
<ul>
<li><p>Many methods struggle dealing with missing data, trees have nice solutions</p></li>
<li><p>Solution 1 (CART): in addition to the split I want to do, find similar <em>surrogate splits</em> on other variables, and if I don’t see <span class="math inline">\(x_{ij}\)</span> I can use surrogate split on <span class="math inline">\(x_{ik}\)</span></p></li>
<li><p>Solution 2 (C4.5): if I want to split on feature <span class="math inline">\(j\)</span> and I don’t know <span class="math inline">\(x_{ij}\)</span>, send observation <span class="math inline">\(i\)</span> both left and right</p></li>
</ul>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>יתרון חשוב נוסף לעצים הוא כמה טבעי להזין להם משתנים עם ערכים חסרים. כבר אמרנו שבקורס הזה לא ניכנס לעובי הקורה של תצפיות חסרות, אבל בשביל הרבה מדעני נתונים תצפיות חסרות הן מציאות כאובה שיש להתמודד איתה. ועצים מתמודדים איתה ללא קושי.</p>
<p>יש כל מיני אסטרטגיות של עצים לטפל במשתנים עם ערכים חסרים, CART למשל, בכל פיצול לא מחשב רק את הפיצול הטוב ביותר, אלא גם את הבאים אחריו, פיצולים שנקראים surrogate. באופן זה אם המשתנה הטוב ביותר לחלק על פיו הוא משתנה שיש לו גם ערכים חסרים, ותגיע לחיזוי תצפית עם ערך חסר במשתנה הזה, עדיין היא תוכל להתמיין ימינה או שמאלה בהתאם למשתנים אחרים בהם אין לה ערכים חסרים.</p>
<p>דרך אחרת של עץ מסוג C4.5, היא לשלוח במורד העץ תצפית עם ערך חסר בפיצול שלנו, גם ימינה וגם שמאלה. ואז כמובן האלגוריתם צריך להתמודד עם מצב שבו אותה תצפית הגיעה לעלים שונים, אבל לא ניכנס לזה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="summary-decision-trees">Summary: Decision Trees</h3>
<p>Advantages:</p>
<ol type="1">
<li>Intuitive and appealing: divide the space into <em>flexible</em> neighborhoods</li>
<li>Flexible: categorical variables, missing data, regression or classification, big or small,…</li>
<li>Big trees are a very rich class of models: can describe well many true models for <span class="math inline">\(E(y|x)\)</span>.</li>
</ol>
<p>Disadvantages:</p>
<ol type="1">
<li>Intuitive appeal is misleading: very unstable and high variance</li>
<li>Not a good prediction model: a single tree is usually not competitive!</li>
</ol>
<div class="fragment">
<p>Conclusions and next steps:</p>
<ol type="1">
<li>We do not really want to use trees as our prediction models</li>
<li>Can we take advantage of their good properties and mitigate the problems?</li>
</ol>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נסכם עצים. מהם היתרונות?</p>
<p>קודם כל התוצר עצמו של האלגוריתם מאוד אינטואיטיבי, כל לקוח יכול להבין אותו, מדובר בתרשים זרימה, אוסף של שאלות שבסופן מתקבלת תשובה.</p>
<p>מבחינת דאטא סיינס עץ גמיש מאוד, מתאים לנתונים בפרקטיקה, נתונים עם משתנים קטגוריאליים, נתונים חסרים, נורא בקלות אפשר לעבור עם אותה פרדיגמה בין קלאסיפיקציה לרגרסיה. אימון וחיזוי על עץ גם נחשבים למהירים מאוד, כך שהוא מהיר יחסית לנתונים גדולים.</p>
<p>לא פחות חשוב מזה, אם תיזכרו ברגרסיה ליניארית או לוגיסטית, אלה מודלים פרמטריים, שמניחים יחס בין מרחב X לY מאוד נוקשה, יחס ליניארי. עץ לא נשאר בטווח הליניארי של יחסים, הוא יכול למדל יחסים מאוד לא ליניאריים אם הוא עמוק מספיק. אם תחשבו על עץ עם max_depth 10 למשל, לכמה שכונות הוא מחלק את הנתונים שלנו? 2 בחזקת 10, כלומר כאלף שכונות שונות, מה שיכול לתת מודל עשיר למדי.</p>
<p>מה בכל זאת בעייתי בעץ?</p>
<p>קודם כל, מבנה העץ אולי אינטואיטיבי, אבל עץ הוא גם נורא נוקשה, וסובל משונות גבוהה. הכוונה לתופעה שאם אשנה כמה תצפיות, אעביר אותן ממדגם הלמידה למדגם הטסט למשל, אני הרבה פעמים אראה שינוי גדול בעץ שנוצר, יכול להיות שזה לא ישנה בהרבה את טיב האמידה אבל לקוח שיביט בעץ יראה תרשים זרימה שונה לגמרי. אתם מוזמנים לנסות את זה בעצמכם על הנתונים שלנו, לעשות חלוקות קצת אחרות של הדאטא ולראות שעלולים להתקבל עצים שונים לחלוטין, לא משנה כמה העצים שראינו היום היו אינטואיטיביים והם היו.</p>
<p>בעיה חמורה יותר היא שעץ הוא פשוט לא מודל חיזוי טוב. בפועל, אנחנו רואים בהשוואה למתודות אחרות, שאם שגיאת החיזוי על נתונים שהמודל לא ראה היא מה שמעניין אותנו, נדיר שעץ יהיה המודל הטוב ביותר. הסיבה נעוצה בכך שלמרות כל מה שאמרנו עץ אחד מגיע ממרחב עצום של עצים שאנחנו מחפשים בו בצורה גרידית, ובגלל זה מקבלים מודל אחד כנראה לא אופטימלי, עם שונות גבוהה מאוד.</p>
<p>ואז נשאלת השאלה למה בכלל למדנו על עצים אם ככה?!</p>
<p>אנחנו נראה שעץ בודד הוא לא מודל טוב אבל כסאב-רוטינה, כמודל אחד מתוך אוסף של מודלים או יער, עץ הוא מודל מצוין. בחלק הבא ננסה לשמור על היתרונות של העץ ונראה איך להתמודד עם החסרונות שלו, בעיקר השונות הגבוהה, באמצעות מיצוע או קומבינציה, של מספר עצים.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>

<img src="../Intro2DS_logo_white.jpg" class="slide-logo r-stretch"><div class="footer footer-default">
<p><a href="https://intro2ds2023.github.io/mooc/" target="_blank">Intro to Data Science</a></p>
</div>
</section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../libs/revealjs/plugin/search/search.js"></script>
  <script src="../libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'smaller': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': true,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        text: function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>