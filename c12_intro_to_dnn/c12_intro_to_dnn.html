<!DOCTYPE html>
<html lang="en"><head>
<script src="../libs/clipboard/clipboard.min.js"></script>
<script src="../libs/quarto-html/tabby.min.js"></script>
<script src="../libs/quarto-html/popper.min.js"></script>
<script src="../libs/quarto-html/tippy.umd.min.js"></script>
<link href="../libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="../libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.2.280">

  <title>Demystifying Neural Networks</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
      }
    pre.numberSource { margin-left: 3em;  padding-left: 4px; }
    div.sourceCode
      { color: #24292e;  }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #24292e; } /* Normal */
    code span.al { color: #ff5555; font-weight: bold; } /* Alert */
    code span.an { color: #6a737d; } /* Annotation */
    code span.at { color: #d73a49; } /* Attribute */
    code span.bn { color: #005cc5; } /* BaseN */
    code span.bu { color: #d73a49; } /* BuiltIn */
    code span.cf { color: #d73a49; } /* ControlFlow */
    code span.ch { color: #032f62; } /* Char */
    code span.cn { color: #005cc5; } /* Constant */
    code span.co { color: #6a737d; } /* Comment */
    code span.cv { color: #6a737d; } /* CommentVar */
    code span.do { color: #6a737d; } /* Documentation */
    code span.dt { color: #d73a49; } /* DataType */
    code span.dv { color: #005cc5; } /* DecVal */
    code span.er { color: #ff5555; text-decoration: underline; } /* Error */
    code span.ex { color: #d73a49; font-weight: bold; } /* Extension */
    code span.fl { color: #005cc5; } /* Float */
    code span.fu { color: #6f42c1; } /* Function */
    code span.im { color: #032f62; } /* Import */
    code span.in { color: #6a737d; } /* Information */
    code span.kw { color: #d73a49; } /* Keyword */
    code span.op { color: #24292e; } /* Operator */
    code span.ot { color: #6f42c1; } /* Other */
    code span.pp { color: #d73a49; } /* Preprocessor */
    code span.re { color: #6a737d; } /* RegionMarker */
    code span.sc { color: #005cc5; } /* SpecialChar */
    code span.ss { color: #032f62; } /* SpecialString */
    code span.st { color: #032f62; } /* String */
    code span.va { color: #e36209; } /* Variable */
    code span.vs { color: #032f62; } /* VerbatimString */
    code span.wa { color: #ff5555; } /* Warning */
  </style>
  <link rel="stylesheet" href="../libs/revealjs/dist/theme/quarto.css" id="theme">
  <link rel="stylesheet" href="../slides_quarto.css">
  <link href="../libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-captioned.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-captioned) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-captioned.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-captioned .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-captioned .callout-caption  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-captioned.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-captioned.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-caption {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-caption {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-caption {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-captioned .callout-body > .callout-content > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-captioned .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-captioned) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-caption {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-caption {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-caption {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-caption {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-caption {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  
    <link rel="icon" href="../Intro2DS_logo.jpg" type="image/jpg"> 
    <link rel="shortcut icon" href="../Intro2DS_logo.jpg" type="image/jpg">
    <link href="http://fonts.googleapis.com/css?family=Lato:400,700" rel="stylesheet" type="text/css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script></head>
  
  
  

<body class="quarto-light">
  <div class="reveal">
    <div class="slides">


<section id="section" class="slide level2 logo-slide">
<h2></h2>
</section>
<section id="demystifying-neural-networks" class="slide level2 title-slide center">
<h2>Demystifying Neural Networks</h2>
<h3 id="intro-to-data-science---class-12">Intro to Data Science - Class 12</h3>
<h3 id="giora-simchoni">Giora Simchoni</h3>
<h4 id="gsimchonigmail.com-and-add-intro2ds-in-subject"><code>gsimchoni@gmail.com</code> and add <code>#intro2ds</code> in subject</h4>
<h3 id="stat.-and-or-department-tau">Stat. and OR Department, TAU</h3>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>מי לא שמע על רשתות נוירונים? רשתות נוירונים עומדות בבסיס מה שרבים מכנים מהפכת האינטליגנציה המלאכותית, הAI. הן עומדות מאחורי כמה ממערכות החיזוי המתקדמות ביותר כגון מכוניות אוטונומיות וצ’טבוטים כגון צ’ט ג’יפיטי של חברת OpenAI.</p>
<p>עם זאת, לרבים המודל של רשתות נוירונים נשמע מרתיע בהתחלה ונטול מוטיבציה. ביחידה זו ננסה להראות שהשד לא כזה נורא. נחזור לרגרסיה לוגיסטית, ונראה כיצד ניתן לממש אותה כרשת נוירונים. מכאן נוסיף שכבה ועוד שכבה עד שלבסוף נגיע לרשת נוירונים מודרנית.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="logistic-regression-with-gradient-descent" class="slide level2 title-slide center">
<h2>Logistic Regression with Gradient Descent</h2>
</section>
<section class="slide level2">

<h3 id="reminder-logistic-regression-i">Reminder: Logistic Regression (I)</h3>
<div>
<ul>
<li class="fragment">Observe <span class="math inline">\(n\)</span> pairs <span class="math inline">\((x_i, y_i)\)</span> <span class="math inline">\((i = 1, \dots, n)\)</span></li>
<li class="fragment"><span class="math inline">\(y_i \in \{0, 1\}\)</span> binary outcomes</li>
<li class="fragment"><span class="math inline">\(x_i \in \mathbb{R}^q\)</span> numeric predictors</li>
<li class="fragment">Model: <span class="math inline">\(Y_i|X_i \sim Bernoulli(p_i)\)</span>, so: <span class="math inline">\(E(Y_i|X_i = x_i)=P(Y_i = 1|X_i = x_i) = p_i\)</span></li>
<li class="fragment">Choose some <em>link function</em> <span class="math inline">\(g\)</span> and model <em>this</em> transformation of <span class="math inline">\(E(Y_i|X_i = x_i)\)</span></li>
<li class="fragment">Typically for this case <span class="math inline">\(g\)</span> is the logit function: <span class="math inline">\(g(E(Y_i|X_i = x_i)) = \text{logit}(p_i) = \log(\frac{p_i}{1-p_i})=x_i'\beta\)</span></li>
<li class="fragment"><span class="math inline">\(\beta\)</span> a vector of <span class="math inline">\(q\)</span> params</li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>ניזכר במודל הרגרסיה הלוגיסטית.</p>
<p>אנו צופים בN זוגות של X ו-Y. Y הוא בינארי, לדוגמא 0 או 1. וX הוא וקטור של q משתנים מסבירים.</p>
<p>כעת נמדל את Y בהינתן X כמשתנה ברנולי עם הסתברות p.&nbsp;ומאחר שהתוחלת של משתנה ברנולי עם הסתברות p היא p עצמו זה מה שאנחנו בסופו של דבר ממדלים. הבעיה היא שהסתברות היא כמות בין 0 ל1.</p>
<p>נבחר איזו פונקצית לינק ג’י לתוחלת, לאותה הסתברות, במקרה שלנו הלוג’יט, שהיא לוג יחס הסיכויים, ואת הפונקציה הזאת נמדל באמצעות מודל ליניארי רגיל.</p>
<p>בטא הוא וקטור של q מקדמים, ואותו אנחנו רוצים למצוא.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="reminder-logistic-regression-ii">Reminder: Logistic Regression (II)</h3>
<ul>
<li>And so we can write: <span class="math inline">\(E(Y_i|X_i = x_i)= P(Y_i=1|X_i = x_i;\beta) = p_i = g^{-1}(x_i\beta) = \frac{1}{1+e^{-x_i\beta}}\)</span></li>
</ul>
<div>
<ul>
<li class="fragment">Once we get our estimate <span class="math inline">\(\hat\beta\)</span>:</li>
</ul>
<ol type="1">
<li class="fragment">We could “explain” <span class="math inline">\(Y_i\)</span>, the size and direction of each component of <span class="math inline">\(\hat\beta\)</span> indicating the contribution of that predictor to the <em>log-odds</em> of <span class="math inline">\(Y_i\)</span> being <span class="math inline">\(1\)</span></li>
<li class="fragment">We could “predict” probability of new observation <span class="math inline">\(x_i\)</span> having <span class="math inline">\(Y_i=1\)</span> by fitting a probability <span class="math inline">\(\hat p_i=\frac{1}{1+e^{-x_i\hat\beta}}\)</span>, where typically if <span class="math inline">\(\hat p_i &gt; 0.5\)</span>, or <span class="math inline">\(x_i\hat\beta &gt; 0\)</span>, we predict <span class="math inline">\(\hat{Y}_i=1\)</span></li>
</ol>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>איך מוקטור המקדמים נחזור לקבל הסתברות? באמצעות הפונקציה ההופכית g inverse.</p>
<p>כאשר נשיג אומדן לוקטור המקדמים שלנו בטא האט,</p>
<ol type="1">
<li><p>נוכל להסביר את Y, או יותר נכון להסביר את הסיכוי שY יהיה 1. הכיוון והגודל של כל רכיב בוקטור המקדמים יגידו לנו מהי התרומה של המשתנה המתאים ללוגריתם של יחס הסיכויים של Y.</p></li>
<li><p>נוכל לחזות עבור תצפית חדשה את ההסתברות שמשתנה הY שלה הוא 1. יש לנו נוסחה לזה, נכפול את הנתונים X בוקטור המקדמים הנאמד בטא האט, ונחשב על זה את הפונקציה ההופכית של g, g inverse. אם נרצה חיזוי סופי נצטרך להשוות את ההסתברות הנחזית p_hat לאיזשהו סף קאטאוף, לדוגמא חצי. אם p_hat גדול מחצי נחזה שY יהיה 1, אחרת נחזה 0.</p></li>
</ol>
<p>עד כאן ראינו ברגרסיה לוגיסטית.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="maximum-likelihood">Maximum Likelihood</h3>
<div>
<ul>
<li class="fragment"><p>Under the standard Maximum Likelihood approach we assume <span class="math inline">\(Y_i\)</span> are also <em>independent</em> and so their joint “likelihood” is:<br>
<span class="math inline">\(L(\beta|X, y) = \prod_{i = 1}^n{P(Y_i|X;\beta)} = \prod_{i = 1}^n{P(Y_i = 1|X;\beta)^{y_i}P(Y_i = 0|X;\beta)^{1-y_i}}\)</span></p></li>
<li class="fragment"><p>But what is <span class="math inline">\(P(Y_i = 1|X;\beta)\)</span>?<br>
<span class="math inline">\(L(\beta|X, y) = \prod_{i = 1}^n[g^{-1}(x_i\beta)]^{y_i}[1- g^{-1}(x_i\beta)]^{1-y_i}\)</span></p></li>
<li class="fragment"><p>The <span class="math inline">\(\hat\beta\)</span> we choose is the vector maximizing <span class="math inline">\(L(\beta|X, y)\)</span></p></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בואו נראה איך אנחנו מוצאים אומד לוקטור המקדמים בטא.</p>
<p>הגישה הסטנדרטית היא למקסם פונקציה בשם הנראות. פונקציה זו מסומנת בדרך כלל ב-L גדולה, היא פונקציה של בטא בהינתן הנתונים X ו-Y. בהנחת אי-תלות בין התצפיות מדובר במכפלת ההסתברויות לקבל כל תצפית ותצפית, שבמקרה שלנו מקבלת צורה יפה שכזאת: אם Y שווה לאחת נכתוב את ההסתברות בחזקת Y, אם Y שווה אפס נכתוב את ההסתברות בחזקת 1 פחות Y.</p>
<p>ומהי אותה הסתברות לפי המודל? הפונקציה ההופכית של G או אחת פחות הפונקציה ההופכית של G.</p>
<p>הוקטור בטא האט הוא הוקטור שימקסם את הנראות ולכן נקרא אומד נראות מקסימלית, או MLE.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="maximum-likelihood-ii">Maximum Likelihood (II)</h3>
<div>
<ul>
<li class="fragment"><p>Take the log-likelihood which is easier to differentiate:<br>
<span class="math inline">\(l(\beta|X, y)=\sum_{i=1}^n\ln{P(Y_i|X;\beta)} =\)</span> <span class="math inline">\(\sum_{i=1}^n y_i\ln[g^{-1}(x_i\beta)] + (1-y_i)\ln[1- g^{-1}(x_i\beta)] =\)</span></p></li>
<li class="fragment"><p>This looks Ok but let us improve a bit just for easier differentiation:<br>
<span class="math inline">\(\sum_{i=1}^n \ln[1- g^{-1}(x_i\beta)] + y_i\ln[\frac{g^{-1}(x_i\beta)}{1- g^{-1}(x_i\beta)}]=\)</span> <span class="math inline">\(\sum_{i=1}^n -\ln[1+ e^{x_i\beta}] + y_ix_i\beta\)</span></p></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>פונקצית הנראות כפי שהוא מנוסחת כרגע היא קשה למיקסום. נהוג לעבוד עם לוג הנראות, כלומר עם סכום הלוגריתמים של ההסתברויות שרשמנו.</p>
<p>נפשט את הפונקציה הזאת אפילו יותר כדי לקבל פונקציה שקל לגזור יותר לפי בטא.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="maximum-likelihood-iii">Maximum Likelihood (III)</h3>
<div>
<ul>
<li class="fragment"><p>Differentiate:<br>
<span class="math inline">\(\frac{\partial l(\beta|X, y)}{\partial \beta_j} = \sum_{i=1}^n-\frac{1}{1+e^{x_i\beta}}e^{x_i\beta}x_{ij} + y_ix_{ij}=\sum_{i=1}^n x_{ij}(y_i-g^{-1}(x_i\beta))\)</span></p></li>
<li class="fragment"><p>Or in vector notation:<br>
<span class="math inline">\(\frac{\partial l(\beta|X, y)}{\partial \beta}=X'(y - g^{-1}(X\beta))\)</span>, where <span class="math inline">\(X\)</span> is the <span class="math inline">\(n \times q\)</span> data matrix.</p></li>
<li class="fragment"><p>We would like to equate this with <span class="math inline">\(\vec0\)</span> and get <span class="math inline">\(\hat\beta\)</span> but there’s no closed solution.</p></li>
<li class="fragment"><p>At which point usually the Newton-Raphson method comes to the rescue.</p></li>
<li class="fragment"><p>But let’s look at simple gradient descent:</p></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נגזור את הפונקציה לפי אלמנט אחד בוקטור בטא, בטא ג’יי.</p>
<p>נכתוב את הנגזרת לפי כל וקטור בטא בכתיב וקטורי, מה שיקל עלינו במימוש.</p>
<p>את הביטוי הזה היינו רוצים להשוות לוקטור האפס ולקבל את האומד לבטא, אבל לא נקבל פתרון סגור.</p>
<p>בשלב זה נעבור לשיטות של אנליזה כמו ניוטון רפסון, פונקצית לוג הנראות היא קמורה ואיננה נחשבת לפונקציה קשה.</p>
<p>אבל אני רוצה שנסתכל על פתרון של מורד הגרדיאנט, gradient descent.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="gradient-descent">Gradient Descent</h3>
<div>
<ul>
<li class="fragment">Instead of maximizing log-likelihood, let’s minimize negative log-likelihood <span class="math inline">\(-l(\beta)\)</span> (NLL)</li>
<li class="fragment">We’ll start with an initial guess <span class="math inline">\(\hat\beta_{t=0}\)</span></li>
<li class="fragment">The partial derivatives vector of <span class="math inline">\(-l(\beta)\)</span> at point <span class="math inline">\(\hat\beta_t\)</span> (a.k.a the <em>gradient</em> <span class="math inline">\(-\nabla l(\hat\beta_t)\)</span>) points to the direction of where <span class="math inline">\(-l(\beta)\)</span> has its steepest descent</li>
<li class="fragment">We’ll go a small <span class="math inline">\(\alpha\)</span> step down that direction: <span class="math inline">\(\hat\beta_{t+1}=\hat\beta_t -\alpha \cdot[-\nabla l(\hat\beta_t)]\)</span></li>
<li class="fragment">We do this for <span class="math inline">\(I\)</span> iterations or until some stopping rule indicating <span class="math inline">\(\hat\beta\)</span> has converged</li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>במקום למקסם את לוג הנראות, נעשה מינימיזציה ללוג הנראות השלילית, ה-NLL.</p>
<p>נתחיל בניחוש ראשוני עבור בטא האט בזמן t = 0.</p>
<p>הגרדיאנט, או וקטור הנגזרות החלקיות של הNLL המחושב בנקודה בטא האט, מצביע לכיוון שיפוע הירידה התלולה ביותר בנקודה זו.</p>
<p>נלך צעד קטן בגודל אלפא בכיוון זה. וקטור בטא האט החדש שלנו יהיה בטא האט הקודם פחות צעד אלפא בכיוון וקטור הגרדיאנט של פונקצית הלוג-נראות השלילית.</p>
<p>נעשה את זה במשך מספר איטרציות עד להתכנסות למינימום מקומי, במקרים מסוימים כגון המקרה שלפנינו אנחנו יכולים לדעת שמדובר בנקודת מינימום גלובלית.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h4 id="lets-see-that-it-works">Let’s see that it works ! 😀</h4>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>q <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.random.normal(size <span class="op">=</span> n <span class="op">*</span> q).reshape((n, q))</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>beta <span class="op">=</span> [<span class="fl">1.0</span>, <span class="fl">2.0</span>]</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>np.dot(X, beta)))</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.random.binomial(<span class="dv">1</span>, p, size <span class="op">=</span> n)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-note callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>See it in python!</p>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בואו נראה כיצד גרדיאנט דיסנט יעבוד בפייתון. בקוד שלפניכם אנחנו מדמים מצב אידיאלי לרגרסיה לוגיסטית עם שני משתנים, וללא חותך. N יהיה שווה 1000 תצפיות ו-q יהיה שווה ל2, כלומר שני משתנים, לכן ב-X יהיו 1000 שורות על שתי עמודות. וקטור המקדמים האמיתי בטא באורך 2 יהיה פשוט 1, 2.</p>
<p>וקטור ההסתברויות האמיתיות p מחושב לפי פונקצית ה-G ההופכית שלנו.</p>
<p>לבסוף Y נדגם מהתפלגות ברנולי להיות 0 או 1, עם ההסתברויות שחישבנו.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="youve-already-been-neural-network-ing" class="slide level2 title-slide center">
<h2>You’ve already been Neural Network-ing!</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אבל מה הקשר בין רגרסיה לוגיסטית לרשתות נוירונים? כעת נראה שרגרסיה לוגיסטית היא רשת נוירונים פשוטה למדי.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="call-it-a-neural-network">Call it a Neural Network</h3>
<div>
<ol type="1">
<li class="fragment">Call our <span class="math inline">\(-l(\beta)\)</span> “Cross Entropy”</li>
<li class="fragment">Call <span class="math inline">\(g^{-1}(X\beta)\)</span> the “Sigmoid Function”</li>
<li class="fragment">Call computing <span class="math inline">\(\hat p_i\)</span> and <span class="math inline">\(-l(\hat\beta)\)</span> a “Forward Propagation” or “Feed Forward” step</li>
<li class="fragment">Call the differentiation of <span class="math inline">\(-l(\hat\beta)\)</span> a “Backward Propagation” step</li>
<li class="fragment">Call our <span class="math inline">\(\beta\)</span> vector <span class="math inline">\(W_{(q+1)\text{x}1}\)</span>, a weight matrix (add intercept, call it “bias”)</li>
<li class="fragment">Add <em>stochastic</em> gradient descent (SGD)</li>
<li class="fragment">Draw a diagram with circles and arrows, call these “neurons”</li>
</ol>
</div>
<div class="fragment">
<p>And you have a Neural Network*.</p>
</div>
<div class="fragment" style="font-size: 50%;">
<p>*Ok, We’ll add some stuff later</p>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נקרא לפונקצית הנראות השלילית cross entropy.</p>
<p>נקרא לפונקציה ההופכית ל-g שמחשבת לנו את ההסתברות החזויה, פונקצית זיגמויד.</p>
<p>לחישוב ההסתברות החזויה ולוג הנראות נקרא פעפוע לפנים, או forward propagation.</p>
<p>לחישוב הגרדיאנט נקרא פעפוע לאחור, או backward propagation.</p>
<p>נסמן את וקטור המקדמים שלנו כמטריצה W שיש לה עמודה אחת, לפעמים נוסיף גם חותך שנקרא לו bias.</p>
<p>במקום להשתמש בגרדיאנט דיסנט על כל הדאטה נשתמש בגרדיאנט דיסנט סטוכסטי או SGD - תיכף נסביר מה זה.</p>
<p>לבסוף נתאר את המודל שלנו בתור דיאגרמה עם קשתות וצמתים, נקרא להם נוירונים.</p>
<p>ויש לנו רשת נוירונים!</p>
<p>טוב, בהמשך נוסיף עוד כמה אלמנטים.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="cross-entropy">Cross Entropy</h3>
<div>
<ul>
<li class="fragment"><p>For discrete probability distributions <span class="math inline">\(P(X)\)</span> and <span class="math inline">\(Q(X)\)</span> with the same support <span class="math inline">\(x \in \mathcal X\)</span> Cross Entropy could be seen as a metric of the “distance” between distributions:<br>
<span class="math inline">\(H(P, Q) = -E_P[\log(Q)] = -\sum _{x\in {\mathcal{X}}}P(X=x)\log[Q(X=x)]\)</span></p></li>
<li class="fragment"><p>In case <span class="math inline">\(X\)</span> has two categories, and <span class="math inline">\(p_1=P(X=x_1)\)</span>, <span class="math inline">\(p_2=1-p_1\)</span> and same for <span class="math inline">\(q_1,q_2\)</span>:<br>
<span class="math inline">\(H(P, Q) = -[p_1\log(q_1) + (1-p_1)\log(1-q_1)]\)</span></p></li>
<li class="fragment"><p>If we let <span class="math inline">\(p_1=y_i\)</span> and <span class="math inline">\(q_1=\hat p_i=g^{-1}(x_i\hat\beta)\)</span> we get:<br>
<span class="math inline">\(H(y_i, \hat p_i) = -[y_i\log(\hat p_i) + (1-y_i)\log(1-\hat p_i)] =\)</span> <span class="math inline">\(-[y_i\ln[g^{-1}(x_i\hat\beta)] + (1-y_i)\ln[1- g^{-1}(x_i\hat\beta)]]\)</span></p></li>
<li class="fragment"><p>Which is exactly the contribution of the <span class="math inline">\(i\text{th}\)</span> observation to the NLL <span class="math inline">\(-l(\hat\beta)\)</span>.</p></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>ראשית מהי האנטרופיה? אפשר לראות באנטרופיה כמדד למרחק בין שתי התפלגויות.</p>
<p>עבור שתי התפלגויות P ו-Q, אנטרופיה המסומנת בדרך כלל ב-H, היא מינוס התוחלת של לוג ההתפלגות Q לפי התפלגות P.</p>
<p>במקרה שלפנינו למשתנה אקראי X יש שני ערכים אפשריים, והאנטרופיה מקבלת צורה של סכום פשוט של הסתברות לפי התפלגות אחת כפול לוג ההסתברות לפי ההתפלגות האחרת.</p>
<p>אם נחשוב על שתי ההתפלגויות שלנו כפונקצית ההסתברות של Y הבינארי שלנו, ו-Y עצמו, נוכל להוכיח שאנטרופיה היא בדיוק פונקצית לוג-הנראות השלילית שלנו.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="sigmoid-function">Sigmoid Function</h3>
<p>If <span class="math inline">\(g(p)\)</span> is the logit function, its inverse would be the sigmoid function:</p>
<p><span class="math inline">\(g(p) = logit(p) = \log(\frac{p}{1-p}); \space\space g^{-1}(z) = \sigma(z) =\frac{1}{1+e^{-z}}\)</span></p>
<p>So: <span class="math inline">\(g^{-1}(g(p)) = \sigma(logit(p)) = p\)</span></p>

<img data-src="c12_intro_to_dnn_files/figure-revealjs/cell-10-output-1.png" class="r-stretch"><aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>שינוי נוסף שנעשה הוא פשוט לשנות את שם הפונקציה ההופכית של G לפונקצית זיגמויד. פונקצית זיגמויד המסומנת כאן עם האות סיגמא, מקבלת כל קלט בין מינוס לפלוס אינסוף, וממפה אותו בצורה מונוטונית להיות בין 0 ל-1.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="forwardbackward-propagation">Forward/Backward Propagation</h3>
<p>Recall that each iteration of gradient descent included:</p>
<div>
<ol type="1">
<li class="fragment">Forward step: Calculating the NLL loss <span class="math inline">\(-l(\hat\beta)\)</span></li>
<li class="fragment">Backward step: Calculate the gradient <span class="math inline">\(-\nabla l(\hat\beta_t)\)</span></li>
<li class="fragment">Gradient descent: <span class="math inline">\(\hat\beta_{t+1}=\hat\beta_t -\alpha \cdot[-\nabla l(\hat\beta_t)]\)</span></li>
</ol>
</div>
<div class="fragment">
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb2" data-code-line-numbers="|1-3|4-5|6-7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a><span class="co"># forward step</span></span>
<span id="cb2-2"><a href="#cb2-2"></a>p_hat <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>np.dot(X, beta_hat)))</span>
<span id="cb2-3"><a href="#cb2-3"></a>nll <span class="op">=</span> <span class="op">-</span>np.<span class="bu">sum</span>(y <span class="op">*</span> np.log(p_hat) <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> y) <span class="op">*</span> np.log(<span class="dv">1</span> <span class="op">-</span> p_hat))</span>
<span id="cb2-4"><a href="#cb2-4"></a><span class="co"># backward step</span></span>
<span id="cb2-5"><a href="#cb2-5"></a>grad <span class="op">=</span> <span class="op">-</span>np.dot(X.T, (y <span class="op">-</span> p_hat))</span>
<span id="cb2-6"><a href="#cb2-6"></a><span class="co"># descent</span></span>
<span id="cb2-7"><a href="#cb2-7"></a>beta_hat <span class="op">=</span> beta_hat <span class="op">-</span> alpha <span class="op">*</span> grad</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div class="fragment">
<p>Why “Forward”, why “Backward”?…</p>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>מהם הפורוורד והבקוורד פרופוגיישן?</p>
<p>אפשר לומר שכל איטרציה בגרדיאנט דיסנט כללה:</p>
<p>שלב פורוורד - חישוב פונקצית הלוג-נראות והחיזוי p_hat</p>
<p>שלב בקוורד - חישוב הגרדיאנט</p>
<p>גרדיאנט דיסנט - הליכה של צעד בגודל אלפא בכיוון הגרדיאנט</p>
<p>בפייתון מימשנו כל שלב באמצעות שורה אחת או שתיים. פורוורד. בקוורד. גרדיאנט דיסנט.</p>
<p>אבל למה אנחנו קוראים לזה פורוורד או לפנים? למה בקוורד או לאחור?</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="reminder-chain-rule">Reminder: Chain Rule</h3>
<p>In our case differentiating <span class="math inline">\(l(\beta)\)</span> analytically was manageable.</p>
<div>
<ul>
<li class="fragment"><p>As the NN architecture becomes more complex there is need to generalize this, and break down the derivative into (backward) steps.</p></li>
<li class="fragment"><p>Recall that according to the Chain Rule, if <span class="math inline">\(y = y(x) = f(g(h(x)))\)</span> then: <span class="math inline">\(y'(x)=f'(g(h(x)) \cdot g'(h(x)) \cdot h'(x)\)</span></p></li>
<li class="fragment"><p>Or if you prefer, if <span class="math inline">\(z = z(x); \space u = u(z); \space y = y(u)\)</span> then: <span class="math inline">\(\frac{dy}{dx} = \frac{dy}{du} \cdot \frac{du}{dz} \cdot \frac{dz}{dx}\)</span></p></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>במקרה שלנו הגזירה של פונקצית הלוג-נראות השלילית לפי וקטור המקדמים בטא היתה יחסית פשוטה. הגענו לביטוי פשוט גם אם לא לפתרון סגור.</p>
<p>ככל שהארכיטקטורה של רשת הנוירונים תלך ותיעשה מורכבת יותר, נצטרך להכליל את הגזירה הזאת, לצעדים קטנים.</p>
<p>לפי כלל השרשרת, אם Y הוא פונקציה F של פונקציה G של פונקציה H של X - אפשר לרשום את הנגזרת של Y לפי X לפי כלל השרשרת. הנגזרת של Y לפי X היא הנגזרת של F לפי G, כפול הנגזרת של G לפי H, כפול הנגזרת של H לפי X.</p>
<p>אפשר לרשום זאת בכתיב דיפרנציאלי, ובכל מקרה נבחין שיש לפנינו מכפלה לאחור של נגזרות.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<p>Let’s re-write <span class="math inline">\(-l(\beta)\)</span> as a composite function:</p>
<div>
<ul>
<li class="fragment">Multiplying <span class="math inline">\(\beta\)</span> by <span class="math inline">\(x_i\)</span> will be <span class="math inline">\(z_i = z(\beta) = x_i\beta\)</span></li>
<li class="fragment">Applying the sigmoid <span class="math inline">\(g^{-1}\)</span> will be <span class="math inline">\(p_i = g^{-1}(z_i) = \frac{1}{1 + e^{-z_i}}\)</span></li>
<li class="fragment">Calculating the (minus) Cross Entropy will be: <span class="math inline">\(l_i = l(p_i) = y_i\ln(p_i) + (1-y_i)\ln(1 - p_i)\)</span></li>
<li class="fragment">So one element of <span class="math inline">\(-l(\beta)\)</span> will be: <span class="math inline">\(l_i(p_i(z_i(\beta)))\)</span></li>
</ul>
</div>
<div class="fragment">
<p>Hence, Forward.</p>
</div>
<div class="fragment">
<p>Now <span class="math inline">\(-l(\beta)\)</span> is the sum of (minus) cross entropies: <span class="math inline">\(-l(\beta) = -\sum_i l_i(p_i(z_i(\beta)))\)</span></p>
<p>And we could differentiate using the chain rule like so:</p>
<p><span class="math inline">\(-\frac{\partial l(\beta)}{\partial \beta_j} = -\sum_i\frac{\partial l_i}{\partial p_i} \cdot \frac{\partial p_i}{\partial z_i} \cdot \frac{\partial z_i}{\partial \beta_j}\)</span></p>
</div>
<div class="fragment">
<p>Hence, Backward.</p>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כדי שנוכל להשתמש בכלל השרשרת, נרשום את פונקצית הלוג-נראות השלילית שלנו כפונקציה מורכבת של בטא:</p>
<p>ההכפלה של האינפוטים X בבטא תהיה פונקציה Z של בטא.</p>
<p>המעבר של Z בפונקצית זיגמויד או הפונקציה ההופכית של G תיקרא פונקציה P של Z.</p>
<p>החישוב הסופי של האלמנט ה-I בתוך הלוג-נראות השלילית מתוך ההסתברויות החזויות P ייקרא פונקציה L של P.</p>
<p>כלומר אלמנט אחד של פונקצית ההפסד שלנו הוא L של P של Z של בטא. ולכן - קדימה, או פורוורד.</p>
<p>וכעת אפשר להפעיל את כלל השרשרת: הנגזרת של פונקצית ההפסד לפי בטא J כלשהו, היא נגזרת של L לפי P, כפול נגזרת של P לפי Z, כפול נגזרת לפי בטא J. ולכן - אחורה, או בקוורד.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<p>Each of these is simpler to calculate:</p>
<p><span class="math inline">\(\frac{\partial l_i}{\partial p_i}= \frac{y_i - p_i}{p_i(1-p_i)}\)</span></p>
<p><span class="math inline">\(\frac{\partial p_i}{\partial z_i} = p_i(1-p_i)\)</span></p>
<p><span class="math inline">\(\frac{\partial z_i}{\partial \beta_j}=x_{ij}\)</span></p>
<p>And so:</p>
<p><span class="math inline">\(-\frac{\partial l(\beta)}{\partial \beta_j} = - \sum_i \frac{y_i - p_i}{p_i(1-p_i)} \cdot p_i(1-p_i) \cdot x_{ij}\)</span></p>
<p>Which is excatly what we got analytically but now we can write our gradient descent iteration as a list of forward/backward steps.</p>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כל אחת מהנגזרות האלה קלה לחישוב: הנגזרת של L לפי P, הנגזרת של P לפי Z והנגזרת של Z לפי בטא J.</p>
<p>ואם נכפול את הנגזרות האלה זו בזו לפי כלל השרשרת, נקבל בדיוק את הביטוי האנליטי הפשוט לגרדיאנט שקיבלנו לפני כן.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="implementing-nn-in-python">Implementing NN in python</h3>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb3" data-code-line-numbers="|1-6|8-12|14-15|17-21|"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a><span class="kw">def</span> forward(X, y, beta_hat):</span>
<span id="cb3-2"><a href="#cb3-2"></a>  z <span class="op">=</span> np.dot(X, beta_hat)</span>
<span id="cb3-3"><a href="#cb3-3"></a>  p_hat <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>z))</span>
<span id="cb3-4"><a href="#cb3-4"></a>  l <span class="op">=</span> y <span class="op">*</span> np.log(p_hat) <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> y) <span class="op">*</span> np.log(<span class="dv">1</span> <span class="op">-</span> p_hat)</span>
<span id="cb3-5"><a href="#cb3-5"></a>  nll <span class="op">=</span> <span class="op">-</span>np.<span class="bu">sum</span>(l)</span>
<span id="cb3-6"><a href="#cb3-6"></a>  <span class="cf">return</span> p_hat, nll</span>
<span id="cb3-7"><a href="#cb3-7"></a></span>
<span id="cb3-8"><a href="#cb3-8"></a><span class="kw">def</span> backward(X, y, p_hat):</span>
<span id="cb3-9"><a href="#cb3-9"></a>  dldz <span class="op">=</span> y <span class="op">-</span> p_hat</span>
<span id="cb3-10"><a href="#cb3-10"></a>  dzdb <span class="op">=</span> X.T</span>
<span id="cb3-11"><a href="#cb3-11"></a>  grad <span class="op">=</span> <span class="op">-</span>np.dot(dzdb, dldz)</span>
<span id="cb3-12"><a href="#cb3-12"></a>  <span class="cf">return</span> grad</span>
<span id="cb3-13"><a href="#cb3-13"></a></span>
<span id="cb3-14"><a href="#cb3-14"></a><span class="kw">def</span> gradient_descent(alpha, beta_hat, grad):</span>
<span id="cb3-15"><a href="#cb3-15"></a>  <span class="cf">return</span> beta_hat <span class="op">-</span> alpha <span class="op">*</span> grad</span>
<span id="cb3-16"><a href="#cb3-16"></a></span>
<span id="cb3-17"><a href="#cb3-17"></a><span class="kw">def</span> optimize(X, y, alpha, beta_hat):</span>
<span id="cb3-18"><a href="#cb3-18"></a>  p_hat, l <span class="op">=</span> forward(X, y, beta_hat)</span>
<span id="cb3-19"><a href="#cb3-19"></a>  grad <span class="op">=</span> backward(X, y, p_hat)</span>
<span id="cb3-20"><a href="#cb3-20"></a>  beta_hat <span class="op">=</span> gradient_descent(alpha, beta_hat, grad)</span>
<span id="cb3-21"><a href="#cb3-21"></a>  <span class="cf">return</span> l, beta_hat</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כעת נממש את הרגרסיה הלוגיסטית לפי הצעדים שחישבנו באמצעות כמה פונקציות פשוטות:</p>
<p>פונקצית הפורוורד מקבלת את X, Y ואת האומדן הנוכחי לוקטור המקדמים בטא. היא מחשבת שלב אחרי שלב את ההסתברויות החזויות ואת לוג הנראות השלילית: הכפלה של X בבטא האט לתת את Z, זיגמויד על Z לתת את P האט, ולבסוף חישוב הנראות הסופית.</p>
<p>פונקצית הבקוורד תקבל את X ואת ההסתברויות החזויות P האט, ותחשב בשני צעדים לאחור את הנגזרות ותכפיל ביניהן לפי כלל השרשרת להחזיר את הגרדיאנט לפי בטא.</p>
<p>פונקצית הגרדיאנט דיסנט פשוט תקבל את גודל הצעד אלפא, את האומדן הנוכחי לבטא ואת הגרדיאנט, ותחשב אומדן מעודכן לבטא על ידי הליכה בצעד אלפא בכיוון הגרדיאנט.</p>
<p>הפונקציה אופטימייז מהווה איטרציה אחת שכוללת צעד פורוורד, צעד בקוורד וצעד גרדיאנט דיסנט.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> lr_nn(X, y, epochs):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>  beta_hat <span class="op">=</span> np.array([<span class="op">-</span><span class="fl">2.5</span>, <span class="op">-</span><span class="fl">2.5</span>])</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  alpha <span class="op">=</span> <span class="fl">0.001</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    l, beta_hat <span class="op">=</span> optimize(X, y, alpha, beta_hat)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> l, beta_hat</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>לבסוף הפונקציה lr_nn מקבלת את הדאטא X ו-Y ומספר איטרציות לריצה שנקראות איפוקס.</p>
<p>היא מאתחלת את האומדן בטא-האט לאיזשהם ערכים, כאו מינוס 2.5 לשני הרכיבים של הוקטור.</p>
<p>ואז היא מבצעת את מספר האיפוקס המתבקש, כל אחד מאלה הוא בעצם קריאה לפונקציה אופטימייז, שעושה צעד פורווד, צעד בקוורד וגרדיאנט דיסנט.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<p>Adding <em>stochastic</em> gradient descent (SGD) on mini-batches:</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> lr_nn(X, y, epochs):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  beta_hat <span class="op">=</span> np.random.rand(X.shape[<span class="dv">1</span>])</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  alpha <span class="op">=</span> <span class="fl">0.001</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>  batch_size <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>  n <span class="op">=</span> X.shape[<span class="dv">0</span>]</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>  steps <span class="op">=</span> <span class="bu">int</span>(n <span class="op">/</span> batch_size)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'epoch </span><span class="sc">%d</span><span class="st">:'</span> <span class="op">%</span> i)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    permute <span class="op">=</span> np.random.permutation(n)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    X_perm <span class="op">=</span> X[permute, :]</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    y_perm <span class="op">=</span> y[permute]</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(steps):</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>      start <span class="op">=</span> j <span class="op">*</span> batch_size</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>      l, beta_hat <span class="op">=</span> optimize(X_perm[start:start <span class="op">+</span> batch_size, :],</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>                            y_perm[start:start <span class="op">+</span> batch_size],</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>                            alpha, beta_hat)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>      <span class="bu">print</span>(<span class="st">'Trained on </span><span class="sc">%d</span><span class="st">/</span><span class="sc">%d</span><span class="st">, loss = </span><span class="sc">%d</span><span class="st">'</span> <span class="op">%</span> (start <span class="op">+</span> batch_size, n, l))</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> l, beta_hat</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>l, beta_hat <span class="op">=</span> lr_nn(X, y, <span class="dv">50</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-note callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>See it in python!</p>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>רגע לפני שנריץ את הפונקציה, אני בכל זאת רוצה שנשנה דבר קטן אחד. נזכיר שרשתות נוירונים יודעות לרוץ על קבצי נתונים גדולים מאוד.</p>
<p>אחד מהאופנים שבהן הן עושות את זה, הוא שהגרדיאנט לא מחושב בכל איטרציה על כל מסד הנתונים. במקרה שלפנינו לא היתה בעיה לעשות את זה גם אם N היה גדול מאוד. אבל ברגע שהרשת תיעשה מורכבת יותר, חישוב הגרדיאנט בכל איטרציה יגזול מאיתנו זמן וכוח חישוב, אם בכלל יהיה אפשרי.</p>
<p>לכן מקובל ברשתות נוירונים לאמן על באצ’ים אקראיים של דאטא. בכל איפוק נחלק את הדאטא למספר תת-מדגמים אקראיים בגודל batch_size, ונזין אותם אחד אחרי השני לרשת, נחשב את הגרדיאנט ונלך צעד בכיוונו, עד שהרשת תראה בסוף האיפוק את כל הדאטה. באיפוק הבא היא תראה באצ’ים אחרים.</p>
<p>האקראיות הזאת שהכנסנו נקראת stochatstic gradient descent, והיא כאמור עקרון מפתח בהפעלת הרשת על נתונים גדולים באמת.</p>
<p>שימו לב שלא כל פונקצית הפסד ניתן בהכרח לפרק לחישוב על מספר באצ’ים. במקרה שלנו ראינו שהלוג-נראות השלילית היא סכום של אלמנטים על כל התצפיות, ולכן היא מתפרקת בפשטות יחסית למספר סכומים, וניתן להראות שזה מספיק כדי לתקף את השינוי הזה.</p>
<p>בואו נראה את המימוש שלנו בפעולה!</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="put-it-in-a-neural-network-diagram">Put it in a Neural Network Diagram</h3>
<p>Binary Logistic Regression, is in fact a single neuron firing a sigmoid probability-like number between 0 and 1, for each sample:</p>

<img src="images/lr_nn.png" style="width: 80%" class="r-stretch"><aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>מה בין מודל הרגרסיה הלוגיסטית לרשת נוירונים? איפה ה”רשת”? נסמן את האינפוט של הרשת, Q פיצ’רים של X ועוד חותך באמצעות צמתים של רשת.</p>
<p>נמתח קשת בין כל אינפוט אל תוך צומת אחד שנקרא לו נוירון. כל אחת מהקשתות מסמלת פרמטר בוקטור המקדמים שלנו בטא, והנוירון כופל את האינפוטים במקדמים וסוכם אותם. למעשה הנוירון מבצע מכפלה פנימית בין שני הוקטורים.</p>
<p>לאחר מכן הכמות הזאת עוברת אקטיבציה, כאן אקטיבצית זיגמויד, כדי לתת חיזוי סופי לתצפית p_hat ואת פונקצית ההפסד בשלב זה.</p>
<p>וכל זה נקרא צעד פורוורד.</p>
<p>לאחר מכן נלך אחור ברשת ונחשב בכל שלב את הנגזרת כדי לתת הגרדיאנט לכל אחד מהמקדמים בוקטור המשקלות בטא. וזה ייקרא צעד בקוורד. לבסוף נלך צעד אלפא בכיוון הגרדיאנט וחוזר חלילה.</p>
<p>אנחנו רואים שניתן לייצג רגרסיה לוגיסטית כנוירון בודד, ברשת שהיא אינה אלא ייצוג למודל המוכר לנו. את הייצוג הזה יהיה קל להכליל למודלים מורכבים יותר ויותר.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="lr-as-nn-in-keras">LR as NN in <code>Keras</code></h3>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb6" data-code-line-numbers="|1|2|3|5|6-7|8|9|10|"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> Sequential</span>
<span id="cb6-2"><a href="#cb6-2"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> Dense</span>
<span id="cb6-3"><a href="#cb6-3"></a><span class="im">from</span> tensorflow.keras.optimizers <span class="im">import</span> SGD</span>
<span id="cb6-4"><a href="#cb6-4"></a></span>
<span id="cb6-5"><a href="#cb6-5"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb6-6"><a href="#cb6-6"></a>model.add(Dense(<span class="dv">1</span>, input_shape<span class="op">=</span>(X.shape[<span class="dv">1</span>], ),</span>
<span id="cb6-7"><a href="#cb6-7"></a>  activation<span class="op">=</span><span class="st">'sigmoid'</span>, use_bias<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb6-8"><a href="#cb6-8"></a>sgd <span class="op">=</span> SGD(learning_rate<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb6-9"><a href="#cb6-9"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>, optimizer<span class="op">=</span>sgd)</span>
<span id="cb6-10"><a href="#cb6-10"></a>model.fit(X, y, batch_size<span class="op">=</span><span class="dv">100</span>, epochs<span class="op">=</span><span class="dv">50</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-note callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>See it in python!</p>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>מובן שלא נממש בעצמנו רשת נוירונים כל פעם שנצטרך. בקורס זה נשתמש בספריית קראס, שהיא מצוינת למתחילים.</p>
<p>כאן אני מייבא קלאס בשם sequential, קלאס לשכבה dense פשוטה כפי שאנחנו צריכים, וקלאס לגרדיאנט דיסנט סטוכסטי, SGD.</p>
<p>אני מאתחל מודל עם sequential. מוסיף שכבת dense עם נוירון בודד באמצעות הפעולה model.add(), ואקטיבציה sigmoid. נשים לב שאני מבקש מהשכבה לא להשתמש בביאס, הוא החותך.</p>
<p>אני מאתחל קלאס SGD עם איזשהו קצב למידה, זהו האלפא שלנו. מקמפל את המודל באמצעות קריאה לmodel.compile(), שם אני מפרט גם את פונקצית ההפסד שהיא האנטרופיה ואת האופטימייזר שלנו, הוא הSGD.</p>
<p>לבסוף אני מריץ את המודל על הנתונים באמצעות הקריאה לmodel.fit(), לתוכו אני מזין את X ואז Y, ומפרט גם מה גודל הבאץ’ ומספר האיפוקס.</p>
<p>בואו נראה את זה בפעולה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="is-that-it">Is that it?</h3>
<ol type="1">
<li>No 😀</li>
<li><blockquote>
<p>The knee-jerk response from statisticians was “What’s the big deal? A neural network is just another nonlinear model, not too different from many other generalizations of linear models”. While this may be true, neural networks brought a new energy to the field. They could be scaled up and generalized in a variety of ways… and innovative learning algorithms for massive data sets.”</p>
</blockquote></li>
</ol>
<div style="font-size: 50%;">
<p>(<em>Computer Age Statistical Inference</em> by Bradley Efron &amp; Trevor Hastie, p.&nbsp;352)</p>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אז האם זה כל מה שיש בה, ברשת הנוירונים? הכללה של רגרסיה לינארית או לוגיסטית לקשר לא-ליניארי בין X ל-Y?</p>
<p>התשובה הקצרה היא: לא. את התשובה הארוכה יותר אני מביא כאן כציטוט מספר מצוין של שני סטטיסטיקאים גדולים, בראדלי אפרון וטרוור הייסטי:</p>
<p>רשתות נוירונים הזריקו אנרגיה חדשה לתחום. אפשר להכליל אותן במגוון דרכים כפי שנראה ולאמן אותם על מסדי נתונים עצומים.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="add-classes" class="slide level2 title-slide center">
<h2>Add Classes</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>לאמן רשת על שתי מחלקות או קלאסים בלבד זה מעט משעמם. בואו נכליל את הרשת ל-C קלאסים.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="c-neurons-for-c-classes"><span class="math inline">\(C\)</span> Neurons for <span class="math inline">\(C\)</span> Classes</h3>
<div>
<ul>
<li class="fragment">fit a <span class="math inline">\(\beta\)</span> vector for each class (or let’s start talking about <span class="math inline">\(W\)</span>)</li>
<li class="fragment">have <span class="math inline">\(C\)</span> neurons for <span class="math inline">\(C\)</span> classes</li>
<li class="fragment">where the output layer is the <em>Softmax Function</em>, to make sure the fitted <span class="math inline">\(\hat p\)</span> sum up to 1:<br>
<span class="math inline">\(\hat p_{i;c} = \text{softmax}(c,W_{(q+1)\text{x}C}, x_i)=\frac{e^{x_iw_c}}{\sum_{c=1}^{C} e^{x_iw_c}}\)</span><br>
Where <span class="math inline">\(x_i\)</span> is the <span class="math inline">\(i\)</span>th row of <span class="math inline">\(X\)</span> as before and <span class="math inline">\(w_c\)</span> is the <span class="math inline">\(c\)</span>th row of <span class="math inline">\(W^T\)</span> (or <span class="math inline">\(c\)</span>th column of <span class="math inline">\(W\)</span>)</li>
</ul>
</div>
<div class="fragment">
<div class="callout callout-tip callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>This would be equivalent to <em>multinomial logistic regression</em>!</p>
</div>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נתאים וקטור מקדמים בטא לכל אחד מהקלאסים שלנו. נקרא לוקטור כזה כבר W ונדבר על מטריצה של משקלות, עם Q פלוס 1 שורות, ו-C עמודות ל-C קלאסים.</p>
<p>נוסיף בשכבת האאוטפוט C נוירוינים ל-C קלאסים.</p>
<p>כאשר המכפלה הפנימית בכל נוירון כזה תעבור אקטיבציית סופטמקס. סופטמקס היא נוסחה שמטרתה לייצר מ-C נוירונים C הסתברויות שיסתכמו ב-1. הפונקציה לוקחת את האאוטפוט של כל נוירון, מעלה אותו באקספוננט ומחלקת בסך האקספוננטים מכל ה-C נוירונים.</p>
<p>מודל זה, אגב, ניתן לראות כמודל שקול לרגרסיה מולטינומית שהזכרנו, מודל שמכליל רגרסיה לוגיסטית ל-C קלאסים.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<p>So the architecture for 2 classes would be:</p>

<img src="images/lr_nn_2neurons.png" style="width: 80%" class="r-stretch"><aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כעת נוספים לדיאגרמה שלנו שני נוירונים עבור שני קלאסים שמייצרים שתי הסתברויות שמסתכמות ב1, אחרי אקטיבצית סופטמקס.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<p>And in <code>Keras</code> we would do:</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb7" data-code-line-numbers="|3|5-6|8|"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a><span class="im">from</span> tensorflow.keras.utils <span class="im">import</span> to_categorical</span>
<span id="cb7-2"><a href="#cb7-2"></a></span>
<span id="cb7-3"><a href="#cb7-3"></a>y_categorical <span class="op">=</span> to_categorical(y)</span>
<span id="cb7-4"><a href="#cb7-4"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb7-5"><a href="#cb7-5"></a>model.add(Dense(<span class="dv">2</span>, input_shape<span class="op">=</span>(X.shape[<span class="dv">1</span>], ),</span>
<span id="cb7-6"><a href="#cb7-6"></a>  activation<span class="op">=</span><span class="st">'softmax'</span>, use_bias<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb7-7"><a href="#cb7-7"></a>sgd <span class="op">=</span> SGD(learning_rate<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb7-8"><a href="#cb7-8"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'categorical_crossentropy'</span>, optimizer<span class="op">=</span>sgd)</span>
<span id="cb7-9"><a href="#cb7-9"></a>model.fit(X, y_categorical, batch_size<span class="op">=</span><span class="dv">100</span>, epochs<span class="op">=</span><span class="dv">50</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-note callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>See it in python!</p>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בקראס נעשה מספר שינויים קטן: ה-Y שלנו בשביל C קלאסים כבר לא יכול להיות וקטור עם 0 או 1. הוא צריך להיות מטריצה, עם N שורות ו-C עמודות, בכל עמודה יש 0 בכל השורה חוץ מהעמודה המתאימה לקלאס שם יש 1. את כל זה ניתן לבצע עם הפונקציה to_categorical.</p>
<p>בשכבת האאוטפוט שלנו יהיו 2 נוירונים, ולא 1, והאקטיבציה תהיה סופטמקס ולא זיגמויד.</p>
<p>לבסוף בזמן קומפילציה של המודל נפרט פונקצית הפסד בשם categorical_crossentropy ולא binary_crossentropy.</p>
<p>בואו נראה את זה בפעולה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="add-hidden-layers" class="slide level2 title-slide center">
<h2>Add Hidden Layers</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>ראינו שקל להכליל את הרשת להוציא C אאוטפוטים ל-C קלאסים. כעת נראה כמה קל להוסיף עוד שכבות ביניים. אנחנו קוראים לשכבות כאלה נסתרות, או hidden.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="adding-hidden-layers">Adding Hidden Layers</h3>

<img src="images/lr_nn_morelayers.png" style="width: 80%" class="r-stretch"><p>Where <span class="math inline">\(g()\)</span> is some non-linear <em>activation function</em>, e.g.&nbsp;sigmoid (but not often used).</p>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>הדיאגרמה שלנו כבר נראית כמו רשת נוירונים מורכבת:</p>
<p>Q אינפוטים נכנסים לרשת בתוספת לביאס, ומגיעים לשכבת הביניים שבה יש H נוירונים. הנוירונים מבצעים מכפלה פנימית בין האינפוטים לבין כל אחת מהעמודות של מטריצת משקלות W, ומתבצעת איזושהי אקטיבציה לא-ליניארית G. נשים לב שכל קשת ברשת היא פרמטר, היא אלמנט במטריצת משקולות.</p>
<p>H האינפוטים משכבת הביניים בתוספת לביאס, מגיעים אל שכבת האאוטפוט הסופית. שכבה זה מבצעת את המכפלה הפנימית בין האינפוטים לכל אחת מעמודות מטריצת משקלות W השניה, ומתבצעת אקטיבצית סופטמקס להוצאה של הסתברויות בין 0 ל-1.</p>
<p>כל זה צעד פורוורד של הרשת, וכעת מחשבים את הגרדיאנט באמצעות פעפוע לאחור על כל אחד מהפרמטרים במטריצות המשקלות W1 ו-W2, ומתבצע גרדיאנט דיסנט, בדיוק איך שמימשנו עבור הרשת הפשוטה מקודם שם היה לנו נוירון אחד בלבד.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<ul>
<li>Notice we are not in Logistic Regression land anymore</li>
<li>The bias term (intercept) is re-instated</li>
</ul>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">4</span>, input_shape<span class="op">=</span>(X.shape[<span class="dv">1</span>], ), activation<span class="op">=</span><span class="st">'sigmoid'</span>))</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">2</span>, activation<span class="op">=</span><span class="st">'softmax'</span>))</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>sgd <span class="op">=</span> SGD(learning_rate<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'categorical_crossentropy'</span>, optimizer<span class="op">=</span>sgd)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="fragment fade-in">
<div class="callout callout-tip callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>This is the MLP (Multi-Layer Perceptron).</p>
<p>Guess how long it’s been around.</p>
</div>
</div>
</div>
</div>
<div class="fragment fade-in">
<div class="callout callout-tip callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>Even now, the forward step is a simple formula:</p>
<p><span class="math display">\[\hat{p}_{n \times C} = softmax\{[\mathbb{1} \vdots \sigma([\mathbb{1} \vdots X]W^{(1)})]W^{(2)}\}\]</span></p>
</div>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נשים לב שכבר התרחקנו מרגרסיה לוגיסטית מרחק די רב. הרשת שלפנינו, עם מספיק נוירונים בשכבת הביניים, יכולה כבר למדל יחסים לא-ליניאריים מורכבים ביותר בין X ל-Y.</p>
<p>מבחינת קוד בקראס, כל מה שנוסף כאן הוא עוד קריאה לmodel.add שם אנחנו מוסיפים עוד שכבת dense פשוטה עם 4 נוירונים ואיזושהי אקטיבצית זיגמויד.</p>
<p>המודל הזה נקרא multi layer perceptron או MLP, והוא קיים שנים רבות. המימוש הראשון שלו נצפה כבר ב1958 על-ידי מדען בשם פרנק רוזנבלט. אולם לקח שנים והיווצרות נתונים מספיק גדולים ומחשוב יעיל מספיק כדי להביא מודל זה לשימוש הנרחב שאנו רואים כיום.</p>
<p>ואפילו כעת, נשים לב שיש כאן נוסחה לא מאוד מורכבת. ניקח את מטריצת הנתונים X, נוסיף לה עמודה של אחדים, נכפיל במטריצה W1, נעשה על זה איזושהי אקטיבציה למשל זיגמויד, נוסיף שוב עמודת אחדים לחותך, נכפול במטריצת W2 ונבצע שוב אקטיבצית סופטמקס לקבלת הסתברויות.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<p>Call <code>model.summary()</code> and see that you can calculate the number of params yourself:</p>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>model.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> Layer (type)                Output Shape              Param #   </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> dense (Dense)               (None, 4)                 12        </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> dense_1 (Dense)             (None, 2)                 10        </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Total params: 22</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Trainable params: 22</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Non-trainable params: 0</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>המודל שלנו נהפך למורכב יותר ויותר, ואנחנו צריכים לראות כמה פרמטרים הוא כבר כולל.</p>
<p>מומלץ לקרוא לmodel.summary ולנסות לחשב לבד איך הגענו למספר הזה של פרמטרים.</p>
<p>(חישוב ידני על השקף)</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="activation-functions">Activation Functions</h3>
<div class="columns">
<div class="column" style="width:50%;">
<p><span class="math inline">\(g(z)=\tanh(z)=\frac{e^z-e^{-z}}{e^z+e^{-z}}\)</span></p>
<div class="cell" data-execution_count="29">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>plt.clf()</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>plt.plot(X1, (np.exp(X1) <span class="op">-</span> np.exp(<span class="op">-</span>X1)) <span class="op">/</span> (np.exp(X1) <span class="op">+</span> np.exp(<span class="op">-</span>X1)))</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img data-src="c12_intro_to_dnn_files/figure-revealjs/cell-30-output-1.png"></p>
</div>
</div>
</div><div class="column" style="width:50%;">
<p><span class="math inline">\(g(z)=\text{ReLU}(z)=max(z,0)\)</span></p>
<div class="cell" data-execution_count="30">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>plt.clf()</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>plt.plot(X1, np.maximum(X1, <span class="dv">0</span>))</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img data-src="c12_intro_to_dnn_files/figure-revealjs/cell-31-output-1.png"></p>
</div>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בשלב הזה כדאי לומר שכיום אנחנו פחות משתמשים בפונקצית האקטיבציה זיגמויד לשכבות הביניים. שתי פונקציות אקטיבציה לא-ליניאריות נפוצות יותר נמצאות לפנינו: tanh ו-relu.</p>
<p>tanh נמצאת בשימוש נרחב ברשתות לעיבוד שפה, היא לוקחת קלט ממשי כלשהו ודוחסת אותו להיות בין מינוס לפלוס 1.</p>
<p>relu היא למעשה פונקצית ציר, או hinge. היא מאפסת אינפוט שלילי, ומשאירה אינפוט חיובי כפי שהוא.</p>
<p>שתי הפונקציות לא-לינאריות אבל אין להן פרמטרים והגזירה שלהן קלה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="what-about-linear-activations">What about linear activations?</h3>
<p>See HW.</p>
<div class="callout callout-note callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>See it in python!</p>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>האם אנחנו יכולים להשתמש בפונקצית אקטיבציה ליניארית? אם נשתמש בפונקצית אקטיבציה ליניארית, אנחנו נשארים במודל ליניארי! על כך תראו עוד בשיעורי הבית.</p>
<p>בואו נראה כיצד הרשת שלנו עובדת בפייתון.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="add-regularization" class="slide level2 title-slide center">
<h2>Add Regularization</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">

</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="l1l2-regularization">L1/L2 Regularization</h3>
<div>
<ul>
<li class="fragment"><p>You might have noticed neural networks intice you to add more and more params.</p></li>
<li class="fragment"><p>Therefore, NN are infamous for overfitting the training data, and some kind of regularization is a must.</p></li>
<li class="fragment"><p>Instead of minimizing some loss <span class="math inline">\(L\)</span> (e.g.&nbsp;Cross Entropy) we add a penalty to the weights: <span class="math inline">\(\min_W{L(y, f(X; W)] + P(W)}\)</span></p></li>
<li class="fragment"><p>Where <span class="math inline">\(P(W)\)</span> would typically be:</p>
<ul>
<li class="fragment"><span class="math inline">\(P_{L_2}(W)=\lambda \sum_{ijk}(W^{(k)}_{ij})^2\)</span></li>
<li class="fragment"><span class="math inline">\(P_{L_1}(W)=\lambda \sum_{ijk}|W^{(k)}_{ij}|\)</span></li>
<li class="fragment">or both (a.k.a Elastic Net, but not quite): <span class="math inline">\(P_{L1L2}(W) = \lambda_1 \sum_{ijk}(W^{(k)}_{ij})^2 + \lambda_2 \sum_{ijk}|W^{(k)}_{ij}|\)</span></li>
</ul></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כפי שאולי הבחנתם, זה קל מאוד להוסיף עוד ועוד שכבות ברשת נוירונים ולכן עוד ועוד פרמטרים. רשתות נוירונים ידועות לשמצה ביכולת שלהן לבצע אוברפיטינג לנתונים, ולכן חייבים לבצע איזושהי רגולריזציה על מרחב הפרמטרים.</p>
<p>רגולריזציה יכולה להתבצע למשל באמצעות הוספת איזושהי פונקצית עונש, או פנלטי, על הפרמטרים של המודל, שתתווסף לפונקצית ההפסד. צורה כזו אולי מוכרת לכם ממודלים לרגרסיה ליניארית כמו רידג’ או לאסו.</p>
<p>הפנאלטי יכול להיות איזשהו עונש על נורמת L2 של וקטור או מטריצת המקדמים. כאן העונש מתבצע באמצעות פרמטר למדא. ככל שלמדא יהיה גדול יותר העונש על פרמטרים גדולים מדי יהיה גדול יותר והמודל לא ירשה לעצמו להתאים פרמטרים גדולים מדי, הוא יהיה צנוע יותר.</p>
<p>עונשים אחרים יכולים להיות על נורמת L1 או על שילוב של שני אלה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<p>L1/L2 Regularization in <code>Keras</code>:</p>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb25" data-code-line-numbers="|5-6|8|"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> regularizers</span>
<span id="cb25-2"><a href="#cb25-2"></a></span>
<span id="cb25-3"><a href="#cb25-3"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb25-4"><a href="#cb25-4"></a>model.add(Dense(<span class="dv">4</span>, input_shape<span class="op">=</span>(X.shape[<span class="dv">1</span>], ), activation<span class="op">=</span><span class="st">'relu'</span>,</span>
<span id="cb25-5"><a href="#cb25-5"></a>  kernel_regularizer<span class="op">=</span>regularizers.l1(<span class="fl">0.01</span>),</span>
<span id="cb25-6"><a href="#cb25-6"></a>  bias_regularizer<span class="op">=</span>regularizers.l2(<span class="fl">0.01</span>)))</span>
<span id="cb25-7"><a href="#cb25-7"></a>model.add(Dense(<span class="dv">2</span>, activation<span class="op">=</span><span class="st">'softmax'</span>,</span>
<span id="cb25-8"><a href="#cb25-8"></a>  kernel_regularizer<span class="op">=</span>regularizers.l1_l2(l1<span class="op">=</span><span class="fl">0.01</span>, l2<span class="op">=</span><span class="fl">0.01</span>)))</span>
<span id="cb25-9"><a href="#cb25-9"></a>sgd <span class="op">=</span> SGD(learning_rate<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb25-10"><a href="#cb25-10"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'categorical_crossentropy'</span>, optimizer<span class="op">=</span>sgd)</span>
<span id="cb25-11"><a href="#cb25-11"></a>model.fit(X, y_categorical, batch_size<span class="op">=</span><span class="dv">100</span>, epochs<span class="op">=</span><span class="dv">50</span>, verbose<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בקראס ניתן להוסיף רגולריזציה על המשקולות בכל שכבה ושכבה. כאן אנחנו מדגימים את כל אחד מהסוגים שדיברנו עליהם.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="dropout">Dropout</h3>
<div>
<ul>
<li class="fragment"><p>How to take neurons with a grain of salt?</p></li>
<li class="fragment"><p>During each epoch, individual neurons are either “dropped out” of the net with probability <span class="math inline">\(1-p\)</span> (i.e.&nbsp;their weight is zero) or kept with probability <span class="math inline">\(p\)</span>, so that a reduced network is left.</p></li>
</ul>
</div>
<div class="fragment">
<p><img data-src="images/dropout.png" style="width:40.0%"></p>
</div>
<div class="fragment">
<div class="callout callout-important callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>During prediction no Dropout is performed, but neurons output is scaled by <span class="math inline">\(p\)</span> to make it identical to their expected outputs at training time.</p>
</div>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>רגולריזציה יכולה להיות גם לא קשורה הישר לפונקצית ההפסד, היא יכולה להיות גם אלגוריתמית. לדוגמא: דרופאאוט.</p>
<p>כאשר אנחנו מאמנים רשת עם מנגנון דרופאאוט, אנחנו למעשה מכבים נוירונים בשכבה באופן אקראי בכל אפוק או איטרציה. בסיכוי מסוים P אנחנו פשוט מאפסים את האאוטפוט שלהם, ומכאן השם drop out.</p>
<p>בזמן חיזוי על דאטאסט חדש, כל הנוירונים פעילים, והאאוטפוט שלהם מוכפל בP</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<p>Why does it work?</p>
<div>
<ul>
<li class="fragment"><p>You could look at Dropout as an ensemble of neural networks! Each neuron can either count or not at each training step, so after 1K training steps you have virtually trained 1K slightly different models out of <span class="math inline">\(2^N\)</span> possible (where <span class="math inline">\(N\)</span> is no. of neurons).</p></li>
<li class="fragment"><p>Another explanation uses numerical analysis terms: with each epoch we “break” to randomly look at “close” solutions to the current optimal solution, this is increases our chances of reaching a global optimum</p></li>
<li class="fragment"><p>Dropout in <code>Keras</code> (the <code>rate</code> parameter is the “fraction of the input units to drop”):</p></li>
</ul>
</div>
<div class="fragment">
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb26" data-code-line-numbers="|5|"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> Dropout</span>
<span id="cb26-2"><a href="#cb26-2"></a></span>
<span id="cb26-3"><a href="#cb26-3"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb26-4"><a href="#cb26-4"></a>model.add(Dense(<span class="dv">4</span>, input_shape<span class="op">=</span>(X.shape[<span class="dv">1</span>], ), activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb26-5"><a href="#cb26-5"></a>model.add(Dropout(<span class="fl">0.2</span>))</span>
<span id="cb26-6"><a href="#cb26-6"></a>model.add(Dense(<span class="dv">2</span>, activation<span class="op">=</span><span class="st">'softmax'</span>))</span>
<span id="cb26-7"><a href="#cb26-7"></a>sgd <span class="op">=</span> SGD(learning_rate<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb26-8"><a href="#cb26-8"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'categorical_crossentropy'</span>, optimizer<span class="op">=</span>sgd)</span>
<span id="cb26-9"><a href="#cb26-9"></a>model.fit(X, y_categorical, batch_size<span class="op">=</span><span class="dv">100</span>, epochs<span class="op">=</span><span class="dv">50</span>, verbose<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>למה דרופאאוט עובד?</p>
<p>אפשר לחשוב על דרופאאוט כאימון על אנסמבל של רשתות בדומה למודל רנדום פורסטס שאנחנו מכירים. בכל איטרציה המודל רואה רשת בארכיטקטורה אחרת והצורה הסופית היא מעין ממוצע של הרבה רשתות כאלה.</p>
<p>אפשר גם להסביר את היעילות של דרופאאוט באמצעות מונחים מתחום האנליזה הנומרית. בכל איטרציה אנחנו שוברים כיוון לעבר פתרון שכן בצורה אקראית ובכך גדל הסיכוי שנכסה את מרחב הפרמטרים ונגיע לנקודת אופטימום גלובלית או טובה יותר.</p>
<p>בקראס אנחנו מוסיפים דרופאאוט כך.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="early-stopping">Early Stopping</h3>
<p>Since NN are trained iteratively and are particularly useful on large datasets it is common to monitor the model performance using an additional validation set, or some of the training set. If you see no improvement in the model’s performance (e.g.&nbsp;decrease in loss) for a few epochs - stop training.</p>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb27" data-code-line-numbers="|8|11-12|"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1"></a><span class="im">from</span> tensorflow.keras.callbacks <span class="im">import</span> EarlyStopping</span>
<span id="cb27-2"><a href="#cb27-2"></a></span>
<span id="cb27-3"><a href="#cb27-3"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb27-4"><a href="#cb27-4"></a>model.add(Dense(<span class="dv">4</span>, input_shape<span class="op">=</span>(X.shape[<span class="dv">1</span>], ), activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb27-5"><a href="#cb27-5"></a>model.add(Dropout(<span class="fl">0.2</span>))</span>
<span id="cb27-6"><a href="#cb27-6"></a>model.add(Dense(<span class="dv">2</span>, activation<span class="op">=</span><span class="st">'softmax'</span>))</span>
<span id="cb27-7"><a href="#cb27-7"></a>sgd <span class="op">=</span> SGD(learning_rate<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb27-8"><a href="#cb27-8"></a>callbacks <span class="op">=</span> [EarlyStopping(monitor<span class="op">=</span><span class="st">'val_loss'</span>, patience<span class="op">=</span><span class="dv">5</span>)]</span>
<span id="cb27-9"><a href="#cb27-9"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'categorical_crossentropy'</span>, optimizer<span class="op">=</span>sgd)</span>
<span id="cb27-10"><a href="#cb27-10"></a></span>
<span id="cb27-11"><a href="#cb27-11"></a>model.fit(X, y_categorical, batch_size<span class="op">=</span><span class="dv">100</span>, epochs<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb27-12"><a href="#cb27-12"></a>  validation_split<span class="op">=</span><span class="fl">0.2</span>, callbacks<span class="op">=</span>callbacks)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>רגולריזציה אלגוריתמית נוספת שנמצאת בשימוש נרחב היא early stopping או עצירה מוקדמת. במהלך האימון שמרו בצד עוד סט אקראי קטן של נתונים עליו המודל לא יתאמן, אלא רק יבדוק אחרי כל איטרציה האם יש אכן ירידה בפונקצית ההפסד, הלוס, על דאטה שהמודל לא ראה.</p>
<p>אם אין ירידה במשך כך וכך צעדים, יפסיק המודל להתאמן, כי אנחנו חושדים שבשלב זה הוא רק עושה אוברפיטינג למדגם הלמידה.</p>
<p>בקראס early stopping הוא קריאה או קולבאק. ניתן לאמן את המודל באמצעות קריאה לכמה קולבקס כאלה וגם לכתוב קולבקס בעצמנו. כאן אנחנו מגדירים שearly stopping ינטר את הולידיישן לוס, ואם תוך 5 צעדים אין שיפור בפונקצית ההפסד על תת מדגם זה, יעצור. בקריאה לפיט, אנחנו מבקשים שיחלק בתחילת הריצה את מדגם הלמידה ל-20 אחוז ולידיישן עליו המודל לא יתאמן ו-80 אחוז טריינינג, באמצעות הפרמטר validation_split. וכדי לבצע עצירה מוקדמת אנחנו מזינים את הקולבק בתוך רשימה לארגומנט callbacks.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="keras" class="slide level2 title-slide center">
<h2>Keras</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">

</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="keras-is-an-api">Keras is an API</h3>
<ul>
<li><a href="https://keras.io/">Keras</a> is a high-level API “designed for human beings, not machines” developed by <a href="https://twitter.com/fchollet">François Chollet</a></li>
<li>It sits upon a popular DL backends such as <a href="https://www.tensorflow.org/">Tensorflow</a>, also by Google, and <a href="https://pytorch.org/">PyTorch</a> by Meta</li>
</ul>
<div class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow <span class="im">import</span> keras</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>“ease of use does not come at the cost of reduced flexibility”</li>
<li>Seamless integration with the Pandasverse</li>
</ul>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כעת נרחיב קצת יותר על היכולות של קראס, עם נתונים אמיתיים.</p>
<p>קראס הוא בעצמו API, שנכתב על ידי מהנדס מגוגל בשם פרנסואה שולה. קראס עוטפת תוכנות פופולריות ללמידה עמוקה כמו טנסורפלואו, גם כן נכתבה על ידי מהנדסי גוגל, או פייטורץ’ שמגיעה מחברת מטא.</p>
<p>קראס מאפשרת כפי שראינו להגדיר רשתות מורכבות מבלי להיכנס לברזלים של תהליך האופטימיזציה, ואם רוצים יותר גמישות בארכיטקטורה תמיד אפשר לעבור לכתוב בטנזורפלואו.</p>
<p>קראס מתכתבת באופן ישיר עם החבילות המוכרות שלנו של נאמפיי ופנדאס.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="malaria">Malaria!</h3>
<div>
<ul>
<li class="fragment"><p>The <a href="https://lhncbc.nlm.nih.gov/LHC-research/LHC-projects/image-processing/malaria-datasheet.html">Malaria</a> dataset contains over 27K (processed and segmented) cell images with equal instances of parasitized and uninfected cells, from hundreds of patients in Bangaladesh. The images were taken by a mobile application that runs on a standard Android smartphone attached to a conventional light microscope. The goal is “reduce the burden for microscopists in resource-constrained regions and improve diagnostic accuracy”.</p></li>
<li class="fragment"><p>This dataset is part of the <a href="https://www.tensorflow.org/datasets"><code>tensorflow_dataset</code></a> library which gives you easy access to dozens of varied datasets.</p></li>
<li class="fragment"><p>Here we take only ~10% of the images as a Numpy array and resize them all to 100x100 pixels, for the sake of speed.</p></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נסתכל על מסד נתונים מעניין בשם מלריה. במסד נתונים זה יש כ27 אלף תמונות של תאים, שיכולים להיות נגועים במלריה או לא. נרצה לחזות האם תא נגוע במלריה או לא, כלומר בעית קלסיפיקציה של שני קלאסים. המטרה במודל חיזוי לבעיה כזו היא להטמיע אותו בפלאפונים של רופאים שמטפלים בפציינטים באזורים נחשלים לאבחון מהיר של מלריה. נציין עוד כי הדאטה הוא balanced, כלומר חצי מהתאים נגועים במלריה וחצי לא.</p>
<p>מסד הנתונים הזה נלקח ממאגר עצום של נתונים שמתאימים במיוחד ללמידה עמוקה שנקרא tensorflow datasets. מומלץ ללחוץ על הקישור כאן ולעלעל במגוון הנתונים העשיר שניתן להוריד בשורה או שתיים של קוד אל כל מחברת ולהריץ עליהם מודלים.</p>
<p>כאן נשתמש רק בעשרה אחוזים של הנתונים, כלומר 2500 תמונות, ונאחד אותן לגודל של 100 על 100 פיקסלים. מאוחר יותר נראה ביצועים מרשימים אף יותר באמצעות רשתות מתקדמות יותר, על כל סט התמונות.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow_datasets <span class="im">as</span> tfds</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> skimage.transform <span class="im">import</span> resize</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>malaria, info <span class="op">=</span> tfds.load(<span class="st">'malaria'</span>, split<span class="op">=</span><span class="st">'train'</span>, with_info<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> tfds.show_examples(malaria, info)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="c12_intro_to_dnn_files/figure-revealjs/cell-36-output-1.png" class="r-stretch"><aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בקטע קוד זה אנחנו מייבאים את הספרייה tansorflow datasets, ומורידים את סט הנתונים כאובייקט מיוחד של טנזורפלואו איתו קל לעבוד, ומראים דוגמאות של תאים מתוך המדגם. ניתן לראות שחלק מהתאים מסווגים כparasitized כלומר נגועים במלריה, וחלק כ-uninfected כלומר לא נגועים.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb30" data-code-line-numbers="|16-17|"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb30-2"><a href="#cb30-2"></a></span>
<span id="cb30-3"><a href="#cb30-3"></a>images <span class="op">=</span> []</span>
<span id="cb30-4"><a href="#cb30-4"></a>labels <span class="op">=</span> []</span>
<span id="cb30-5"><a href="#cb30-5"></a><span class="cf">for</span> example <span class="kw">in</span> tfds.as_numpy(malaria):</span>
<span id="cb30-6"><a href="#cb30-6"></a>  images.append(resize(example[<span class="st">'image'</span>], (<span class="dv">100</span>, <span class="dv">100</span>)))</span>
<span id="cb30-7"><a href="#cb30-7"></a>  labels.append(example[<span class="st">'label'</span>])</span>
<span id="cb30-8"><a href="#cb30-8"></a>  <span class="cf">if</span> <span class="bu">len</span>(images) <span class="op">==</span> <span class="dv">2500</span>:</span>
<span id="cb30-9"><a href="#cb30-9"></a>    <span class="cf">break</span></span>
<span id="cb30-10"><a href="#cb30-10"></a>  </span>
<span id="cb30-11"><a href="#cb30-11"></a>X <span class="op">=</span> np.array(images)</span>
<span id="cb30-12"><a href="#cb30-12"></a>y <span class="op">=</span> np.array(labels)</span>
<span id="cb30-13"><a href="#cb30-13"></a></span>
<span id="cb30-14"><a href="#cb30-14"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.20</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb30-15"><a href="#cb30-15"></a></span>
<span id="cb30-16"><a href="#cb30-16"></a>X_train <span class="op">=</span> X_train.flatten().reshape((X_train.shape[<span class="dv">0</span>], <span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb30-17"><a href="#cb30-17"></a>X_test <span class="op">=</span> X_test.flatten().reshape((X_test.shape[<span class="dv">0</span>], <span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb30-18"><a href="#cb30-18"></a></span>
<span id="cb30-19"><a href="#cb30-19"></a><span class="bu">print</span>(X_train.shape)</span>
<span id="cb30-20"><a href="#cb30-20"></a><span class="bu">print</span>(X_test.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(2000, 30000)
(500, 30000)</code></pre>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בקטע קוד זה אנחנו הופכים כל תמונה ותמונה להיות מערך של נאמפיי, ועוצרים ב-2500 תמונות. לאחר מכאן אנחנו מחלקים את X ו-Y, התמונות והסיווגים שלהן ל80 אחוז מדגם למידה ו20 אחוז מדגם טסט.</p>
<p>עוד נלמד על תמונות וייצוגן. כרגע מדובר במערך תלת מימדי בגודל 100 על 100 פיקסלים, על 3 שכבות צבע: אדום, ירוק וכחול, או RGB. מודל הMLP שלנו לא יודע להתמודד עם נתונים שאינם טבלאיים ולכן יש צורך לשטח אותם, ונקבל בסופו של דבר מטריצת X_train עם 2000 שורות ו-30 אלף עמודות שמייצגות שרשור של 30 אלף פיקסלים: 100 כפול 100 כפול 3.</p>
<p>במדגם הטסט יש לנו 500 תמונות עם צורה דומה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<div class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> LogisticRegression(penalty<span class="op">=</span><span class="st">'none'</span>, max_iter<span class="op">=</span><span class="dv">1000</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> lr.fit(X_train, y_train)</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>test_acc <span class="op">=</span> lr.score(X_test, y_test)</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Test accuracy for LR: </span><span class="sc">{</span>test_acc<span class="sc">:.3f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Test accuracy for LR: 0.650</code></pre>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כאן אנחנו מבצעים רגרסיה לוגיסטית באמצעות sklearn. המימוש בsklearn יעיל כך שאין לו בעיה להתמודד אפילו עם 30 אלף משתנים שיש כאן. בחיזוי על מדגם הטסט לעומת זאת, כשאנו מבקשים את הscore אנחנו מקבלים את אחוז הדיוק הכללי על הטסט, הaccuracy, והוא די מאכזב. אמנם אין ספק שמודל הרגרסיה הלוגיסטית שהוא מודל ליניארי למד משהו, והדיוק גבוה בהרבה מדיוק אקראי של 50 אחוז, אך דיוק של בין 60 ל-70 אחוזים איננו מרשים.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h4 id="the-sequential-api">The <code>Sequential</code> API</h4>
<div class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow <span class="im">import</span> keras</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> Sequential</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> Dense, Dropout</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">300</span>, input_shape<span class="op">=</span>(<span class="dv">30000</span>,), activation<span class="op">=</span><span class="st">'relu'</span>, name<span class="op">=</span><span class="st">'my_dense_layer'</span>))</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">100</span>, activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">50</span>, activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">'sigmoid'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Alternatively we could:</p>
<div class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential([</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>  Dense(<span class="dv">300</span>, input_shape<span class="op">=</span>(<span class="dv">30000</span>,), activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>  Dense(<span class="dv">100</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>  Dense(<span class="dv">50</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>  Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">'sigmoid'</span>)</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בקראס נאמן רשת עמוקה עם 3 שכבות ביניים: שכבה עם 300 נוירונים, שכבה עם 100 נוירונים ושכבה עם 50 נוירונים. לכל אחת מהשכבות אקטיבצית רלו, ולבסוף נוספת שכבת האאוטפוט עם נוירון בודד עם אקטיבצית זיגמויד שתפקידו להחזיר לנו בסוף כמות בין 0 ל-1, בה אפשר לראות כמעין הסתברות שהתא נגוע במלריה.</p>
<p>ניתן כפי שנראה כאן לכתוב את הרשת כרשימה משורשרת של שכבות, ובהמשך נראה דרכים נוספות להגדיר רשתות מורכבות יותר.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<p>Make sure you get these numbers:</p>
<div class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>model.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_1"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> Layer (type)                Output Shape              Param #   </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> my_dense_layer (Dense)      (None, 300)               9000300   </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> dense_2 (Dense)             (None, 100)               30100     </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> dense_3 (Dense)             (None, 50)                5050      </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> dense_4 (Dense)             (None, 1)                 51        </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                                                                 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=================================================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Total params: 9,035,501</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Trainable params: 9,035,501</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Non-trainable params: 0</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>_________________________________________________________________</code></pre>
</div>
</div>
<div class="callout callout-tip callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>Are you at all worried?</p>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בואו נראה שוב שאנחנו מבינים כמה פרמטרים יש במודל שלנו, ומאיפה הגיעו המספרים תחת model.summary.</p>
<p>(חישוב ידני)</p>
<p>האם אתם מודאגים? 9 מיליון פרמטרים ברשת שלנו, ועוד לא דיברנו על בעיות אחרות מעצם הגדרתה, והאם מתאים להתייחס לתמונות כמו כאן, כאוסף של פיקסלים בלי תלות ברורה ביניהם.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<p>Access layers and their weights:</p>
<div class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>model.layers</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>[&lt;keras.layers.core.dense.Dense at 0x1c8cb9c22b0&gt;,
 &lt;keras.layers.core.dense.Dense at 0x1c88bc27940&gt;,
 &lt;keras.layers.core.dense.Dense at 0x1c99f1de190&gt;,
 &lt;keras.layers.core.dense.Dense at 0x1c8a5f61a90&gt;]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>model.layers[<span class="dv">0</span>].name</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>'my_dense_layer'</code></pre>
</div>
</div>
<div class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>W1, b1 <span class="op">=</span> model.get_layer(<span class="st">'my_dense_layer'</span>).get_weights()</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(W1.shape)</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>W1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(30000, 300)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>array([[-1.13830371e-02,  7.78465346e-03, -7.35715777e-03, ...,
         1.00976881e-03,  1.46864448e-03,  4.35163453e-03],
       [ 7.89240003e-04,  1.02443825e-02, -5.73266298e-03, ...,
        -1.20754922e-02,  3.28857452e-03, -7.43750343e-03],
       [-8.24765582e-03,  4.23339009e-03, -5.44310827e-03, ...,
         1.01240575e-02,  1.36107337e-02,  6.78374618e-03],
       ...,
       [-1.30265011e-02,  1.36442874e-02,  2.33473815e-03, ...,
         1.07872337e-02,  7.84278661e-03,  8.28148052e-03],
       [-9.09785647e-03,  9.59079154e-03, -3.70273832e-03, ...,
         1.32227857e-02, -2.93281302e-03,  3.47271189e-03],
       [ 6.11092709e-03, -8.58651847e-03, -9.20949504e-03, ...,
         8.77743214e-03,  7.99531117e-05,  8.66886787e-03]], dtype=float32)</code></pre>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כבר כעת הרשת מאותחלת בפרמטרים אקראיים, וניתן לגשת אל השכבות עצמן ואל המשקלות שלהן.</p>
<p>באמצעות model.layers ניתן לגשת לרשימה של שכבות, לכל אחת מהן שם, לדוגמא לשכבה הראשונה קוראים my_dense_layer כי ככה הגדרנו.</p>
<p>אם נבקש את השכבה הזאת באמצעות הפונקציה get_layer, ועל השכבה נבקש get_weights, נקבל את מטריצת המשקולות של השכבה ואת וקטור הביאס שלה. כאן אנחנו מדפיסים את מטריצת המשקולות W ואת הגודל שלה לצורך הדגמה ולודא שהבנו.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<p>Compiling your model:</p>
<div class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"binary_crossentropy"</span>,</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>  optimizer<span class="op">=</span><span class="st">"adam"</span>,</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>  metrics<span class="op">=</span>[<span class="st">"accuracy"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="fragment fade-in">
<p>For more initialization schemes, losses, metrics and optimizers:</p>
<ul>
<li><a href="https://keras.io/api/layers/initializers/">https://keras.io/api/layers/initializers/</a></li>
<li><a href="https://keras.io/api/losses/">https://keras.io/api/losses/</a></li>
<li><a href="https://keras.io/api/optimizers/">https://keras.io/api/optimizers/</a></li>
<li><a href="https://keras.io/api/metrics/">https://keras.io/api/metrics/</a></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>הקומפילציה של המודל נעשית כרגיל. כאן אנחנו משתמשים בפונקצית הפסד שמתאימה לבעית קלסיפיקציה בינארית כפי שראינו binary_crossentropy.</p>
<p>בנוסף, הפעם אנחנו משתמשים באופטימייזר מעט שונה אך פופולרי שנקרא אדם.</p>
<p>באמצעות הארגומנט metrics נבקש גם מהרשת לדווח לנו בכל איטרציה רשימה של מטריקות נוספות לבחירתנו. כאן אנחנו מבקשים שבצד הלוס הרגיל של הרשת יודפס גם הדיוק, הaccuracy.</p>
<p>לפני שנריץ מומלץ ללחוץ על הלינקים השונים שמופיעים כאן כדי להתרשם ממגוון האתחולים, פונקציות ההפסד, האופטימייזרים והמטריקות שלקראס יש להציע. לכל אחד מאלה ניתן גם לרשום פונקציה שמתאימה לצרכים הספציפיים של הרשת שלנו, וזאת מבלי לכתוב בטנזורפלואו שהוא מעט מורכב יותר לשימוש.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<p>Fitting the model:</p>
<div class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.callbacks <span class="im">import</span> EarlyStopping</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>callbacks <span class="op">=</span> [EarlyStopping(monitor<span class="op">=</span><span class="st">'val_loss'</span>, patience<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a>  restore_best_weights<span class="op">=</span><span class="va">True</span>)]</span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(X_train, y_train,</span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a>  batch_size<span class="op">=</span><span class="dv">100</span>, epochs<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a>  validation_split<span class="op">=</span><span class="fl">0.1</span>, callbacks<span class="op">=</span>callbacks, verbose<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כעת נריץ את המודל עם early stopping שמנטר 10 אחוז מדגם ולידיישן. אם לא יראה שיפור בפונקצית ההפסד על מדגם זה במשך 5 צעדים הלמידה תיעצר. כאן אנחנו גם מבקשים מקראס לשמור את סט המשקולות שמתאים לאיטרציה עם ההפסד הנמוך ביותר שראינו עד כה.</p>
<p>דבר נוסף שאנו עושים זה להחזיר את הקריאה לmodel.fit לתוך אוביקט שנקרא history.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<p>See later the <code>history</code> object’s many fields.</p>
<div class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(history.history).plot(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="c12_intro_to_dnn_files/figure-revealjs/cell-48-output-1.png" class="r-stretch"><aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>לאחר הריצה מומלץ לעטוף את האוביקט history כדאטה פריים של פנדאס ולהדפיס את הלוס לאורך האיטרציות ואולי עוד מטריקות כמו accuracy, על מדגם הטריין ועל מדגם הולידיישן. לראות שהאימון נראה טוב ואין אילו אנומליות שלא צפינו.</p>
<p>כאן ניתן לראות שההפסד, הלוס יורד על מדגם הלמידה ומדגם הולידיישן, וכאשר אין שיפור על מדגם הולידיישן במשך 5 צעדים מופסקת הלמידה. ניתן לראות גם את הaccuracy על שני המדגמים. היא עולה עד גבול מסוים, ובכל מקרה איננה מרשימה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<p>Evaluate on test set:</p>
<div class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>test_loss, test_acc <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Test accuracy for NN: </span><span class="sc">{</span>test_acc<span class="sc">:.3f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Test accuracy for NN: 0.628</code></pre>
</div>
</div>
<div class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb66" data-code-line-numbers="|3|5|"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb66-2"><a href="#cb66-2"></a></span>
<span id="cb66-3"><a href="#cb66-3"></a>y_pred <span class="op">=</span> (model.predict(X_test, verbose<span class="op">=</span><span class="dv">0</span>) <span class="op">&gt;</span> <span class="fl">0.5</span>).astype(<span class="bu">int</span>).reshape(y_test.shape)</span>
<span id="cb66-4"><a href="#cb66-4"></a>pd.DataFrame(</span>
<span id="cb66-5"><a href="#cb66-5"></a>  confusion_matrix(y_test, y_pred), </span>
<span id="cb66-6"><a href="#cb66-6"></a>  index<span class="op">=</span>[<span class="st">'true:yes'</span>, <span class="st">'true:no'</span>], </span>
<span id="cb66-7"><a href="#cb66-7"></a>  columns<span class="op">=</span>[<span class="st">'pred:yes'</span>, <span class="st">'pred:no'</span>]</span>
<span id="cb66-8"><a href="#cb66-8"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>pred:yes</th>
      <th>pred:no</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>true:yes</th>
      <td>145</td>
      <td>117</td>
    </tr>
    <tr>
      <th>true:no</th>
      <td>69</td>
      <td>169</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="callout callout-note callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>It’s OK to be underwhelmed.</p>
</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כדי לראות כיצד המודל ביצע על מדגם הטסט שלנו, ניתן להריץ אותו על X_test ו-y_test באמצעות קריאה לevaluate. כפי שניתן לראות אחוז הדיוק של הרשת על תמונות המלריה הוא לא הרבה יותר טוב מאחוז הדיוק של רגרסיה לוגיסטית, ובריצות מסוימות יכול להיות גם נמוך יותר.</p>
<p>ניתן גם לקרוא לmodel.predict, כדי לקבל את הציונים בין 0 ל-1 החזויים בעצמם. את הציונים האלה ניתן להשוות לאיזשהו סף קטאוף כדי לדעת בדיוק אילו תצפיות של תאים נחזות כ1 כלומר יש להן מלריה, ואילו 0. על הוקטור הזה ניתן להפעיל את הפונקציה confusion_matrix המוכרת לנו מsklearn כדי לראות בדיוק איך הגענו לאחוז הדיוק הנוכחי.</p>
<p>שוב נעיר שאחוז הדיוק איננו מרשים וזה בסדר להכיר בכך. בשיעור הבא נלמד על ארכיטקטורה של למידה עמוקה שמתאימה הרבה יותר לנתונים של תמונות, ושם נראה אחוז דיוק מרשים הרבה יותר.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<p>Tuning params:</p>
<div class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb67" data-code-line-numbers="|5|"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> InputLayer</span>
<span id="cb67-2"><a href="#cb67-2"></a><span class="im">from</span> tensorflow.keras.optimizers <span class="im">import</span> SGD</span>
<span id="cb67-3"><a href="#cb67-3"></a><span class="im">from</span> scikeras.wrappers <span class="im">import</span> KerasClassifier</span>
<span id="cb67-4"><a href="#cb67-4"></a></span>
<span id="cb67-5"><a href="#cb67-5"></a><span class="kw">def</span> malaria_model(n_hidden, n_neurons, lrt):</span>
<span id="cb67-6"><a href="#cb67-6"></a>  model <span class="op">=</span> Sequential()</span>
<span id="cb67-7"><a href="#cb67-7"></a>  model.add(InputLayer(input_shape<span class="op">=</span>(<span class="dv">30000</span>, )))</span>
<span id="cb67-8"><a href="#cb67-8"></a>  <span class="cf">for</span> layer <span class="kw">in</span> <span class="bu">range</span>(n_hidden):</span>
<span id="cb67-9"><a href="#cb67-9"></a>    model.add(Dense(n_neurons, activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb67-10"><a href="#cb67-10"></a>  model.add(Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">'sigmoid'</span>))</span>
<span id="cb67-11"><a href="#cb67-11"></a>  model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"binary_crossentropy"</span>,</span>
<span id="cb67-12"><a href="#cb67-12"></a>    optimizer<span class="op">=</span>SGD(learning_rate<span class="op">=</span>lrt),</span>
<span id="cb67-13"><a href="#cb67-13"></a>    metrics<span class="op">=</span>[<span class="st">"accuracy"</span>])</span>
<span id="cb67-14"><a href="#cb67-14"></a>  <span class="cf">return</span> model</span>
<span id="cb67-15"><a href="#cb67-15"></a></span>
<span id="cb67-16"><a href="#cb67-16"></a>keras_clf <span class="op">=</span> KerasClassifier(model<span class="op">=</span>malaria_model, n_hidden<span class="op">=</span><span class="dv">1</span>, n_neurons<span class="op">=</span><span class="dv">30</span>, lrt<span class="op">=</span><span class="fl">3e-3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כבר בשלב זה ודאי הבחנתם כמה החלטות אנחנו צריכים לעשות, כמה היפר-פרמטרים עלינו לכוון. כמה שכבות, כמה נוירונים בכל שכבה, מהו קצב הלמידה, באילו פונקציות אקטיבציה להשתמש ובאילו שיטות רגולריזציה.</p>
<p>מומלץ להשתמש בשיטות קיימות לבצע כוונון או טיונינג של פרמטרים. כאן אנחנו משתמשים בספריה שנקראת scikeras, ובה יש קלאס שנקרא KerasClassifier. הקלאס הזה יכול לעטוף פונקציה לבניית מודל כמו שלנו, והפונקציה תקבל כארגומנטים מספר היפר-פרמטרים שאנחנו רוצים לכוונן. כאן למשל אנחנו מזינים לפונקציה את הפרמטרים מספר שכבות, מספר נוירונים בהנחה שיהיה זהה בכל שכבה, וקצב למידה, learning_rate.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<div class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb68" data-code-line-numbers="|4-8|10-13|"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> reciprocal</span>
<span id="cb68-2"><a href="#cb68-2"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> RandomizedSearchCV</span>
<span id="cb68-3"><a href="#cb68-3"></a></span>
<span id="cb68-4"><a href="#cb68-4"></a>params <span class="op">=</span> {</span>
<span id="cb68-5"><a href="#cb68-5"></a>  <span class="st">'n_hidden'</span>: [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>],</span>
<span id="cb68-6"><a href="#cb68-6"></a>  <span class="st">'n_neurons'</span>: np.arange(<span class="dv">1</span>, <span class="dv">100</span>),</span>
<span id="cb68-7"><a href="#cb68-7"></a>  <span class="st">'lrt'</span>: reciprocal(<span class="fl">3e-4</span>, <span class="fl">3e-2</span>)</span>
<span id="cb68-8"><a href="#cb68-8"></a>}</span>
<span id="cb68-9"><a href="#cb68-9"></a></span>
<span id="cb68-10"><a href="#cb68-10"></a>rnd_search_cv <span class="op">=</span> RandomizedSearchCV(keras_clf, params, cv<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb68-11"><a href="#cb68-11"></a>  n_iter<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb68-12"><a href="#cb68-12"></a>rnd_search_cv.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb68-13"><a href="#cb68-13"></a>  validation_split<span class="op">=</span><span class="fl">0.1</span>, callbacks<span class="op">=</span>callbacks)</span>
<span id="cb68-14"><a href="#cb68-14"></a></span>
<span id="cb68-15"><a href="#cb68-15"></a><span class="bu">print</span>(<span class="ss">f'Best test accuracy: </span><span class="sc">{</span>rnd_search_cv<span class="sc">.</span>best_score_<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb68-16"><a href="#cb68-16"></a><span class="bu">print</span>(<span class="ss">f'Best params: </span><span class="sc">{</span>rnd_search_cv<span class="sc">.</span>best_params_<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="52">
<div class="cell-output cell-output-stdout">
<pre><code>Best test accuracy: 0.69
Best params: {'lrt': 0.0004918307063493132, 'n_hidden': 3, 'n_neurons': 17}</code></pre>
</div>
</div>
<p>See also sklearn’s <a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV"><code>GridSearchCV()</code></a> and <a href="https://keras.io/keras_tuner/">KerasTuner</a> for a more robust solution.</p>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כעת ניתן לעטוף את אוביקט הקראס קלסיפייר שלנו בקלאס אחר מsklearn לביצוע חיפוש רנדומלי במרחב הפרמטרים שהזנו, RandomizedSearchCV.</p>
<p>קלאס זה יקבל מילון עם האפשרויות לכל פרמטר, כאן הוא נקרא params.</p>
<p>לאחר מכן נגדיר איך אנחנו רוצים שירוצו כל המודלים האלה. כאן אנחנו מגדירים שאנחנו רוצים 10 איטרציות שבכל אחת נגריל סט של פרמטרים מהמרחב שהגדרנו. נריץ כל מודל על פני חמישה פולדים של דאטה בפרוצדורה שלcross validation.</p>
<p>לבסוף נדפיס את סט הפרמטרים שהביאו לתוצאה הטובה ביותר בממוצע על פני חמשת הפולדים, וזה יהיה הסט בוא נשתמש בריצה על כל מדגם הנתונים לפני חיזוי סופי על הטסט סט.</p>
<p>אנחנו רואים שגם סט הנתונים הטוב ביותר לא הביא לחיזוי על מדגם טסט טוב בהרבה ממה שראינו, כאן הגענו ל69 אחוזים accuracy. לעוד פתרונות מומלץ להסתכל על ספרית KerasTuner שנותנת עוד אפשרויות לכוונון היפר-פרמרטרים.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<p>Saving and restoring a model:</p>
<div class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>model.save(<span class="st">'malaria.h5'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then:</p>
<div class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> keras.models.load_model(<span class="st">'malaria.h5'</span>)</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>model.predict(X_test[:<span class="dv">3</span>], verbose<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>array([[0.43842962],
       [0.81921285],
       [0.3252244 ]], dtype=float32)</code></pre>
</div>
</div>
<p>The HDF5 model saves the model’s architecture and hyperparameters, and all weights matrices and biases.</p>
<p>Also see the <code>ModelCheckPoint()</code> callback.</p>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>לפני שנסיים ודאי הבחנתם שמודלים של רשתות נוירונים יכולים לקחת זמן לא מועט לאימון. המודלים הסופיים עצמם יכולים להיות גם די כבדים, כאן ראינו מודל די פשוט אך הוא עדיין מסתכם ב9 מיליון פרמטרים שיש לשמור בזיכרון אם רוצים להריץ את המודל בסביבת פרודקשן, לדוגמא באתר באינטרנט על תמונות נכנסות.</p>
<p>מודלים פשוטים של קראס באים עם מתודה נוחה לשמירת המודל על הדיסק ולהעלאתו: save ו-load_model. כאן אנחנו שומרים מודל לדיסק בתור קובץ מסוג HDF5, וכשאנחנו מעלים אותו שוב עם פונקצית load_model הוא מוכן לחיזוי ואפילו המשך אימון.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="few-excellent-books">Few Excellent Books</h3>
<div class="columns">
<div class="column" style="width:50%;">
<p><img src="images/geron_cover.png" style="width: 70%"></p>
</div><div class="column" style="width:50%;">
<p><img src="images/chollet_cover.png" style="width: 70%"></p>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נסיים בהמלצות לספרים מצוינים בנושא, שניהם משתמשים בקראס לאימון רשתות, ואחד מהם נכתב אפילו בידי המחבר של קראס, פרנסואה שולה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<p><img src="../Intro2DS_logo_white.jpg" class="slide-logo"></p>
<div class="footer footer-default">
<p><a href="https://intro2ds2023.github.io/mooc/" target="_blank">Intro to Data Science</a></p>
</div>
</section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../libs/revealjs/plugin/search/search.js"></script>
  <script src="../libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'smaller': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': true,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        target: function(trigger) {
          return trigger.previousElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto-reveal',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>