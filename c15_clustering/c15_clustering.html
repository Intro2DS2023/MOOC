<!DOCTYPE html>
<html lang="en"><head>
<script src="../libs/clipboard/clipboard.min.js"></script>
<script src="../libs/quarto-html/tabby.min.js"></script>
<script src="../libs/quarto-html/popper.min.js"></script>
<script src="../libs/quarto-html/tippy.umd.min.js"></script>
<link href="../libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="../libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.3.433">

  <title>Unsupervised Learning: Cluster Analysis</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
      }
    pre.numberSource { margin-left: 3em;  padding-left: 4px; }
    div.sourceCode
      { color: #24292e;  }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #24292e; } /* Normal */
    code span.al { color: #ff5555; font-weight: bold; } /* Alert */
    code span.an { color: #6a737d; } /* Annotation */
    code span.at { color: #d73a49; } /* Attribute */
    code span.bn { color: #005cc5; } /* BaseN */
    code span.bu { color: #d73a49; } /* BuiltIn */
    code span.cf { color: #d73a49; } /* ControlFlow */
    code span.ch { color: #032f62; } /* Char */
    code span.cn { color: #005cc5; } /* Constant */
    code span.co { color: #6a737d; } /* Comment */
    code span.cv { color: #6a737d; } /* CommentVar */
    code span.do { color: #6a737d; } /* Documentation */
    code span.dt { color: #d73a49; } /* DataType */
    code span.dv { color: #005cc5; } /* DecVal */
    code span.er { color: #ff5555; text-decoration: underline; } /* Error */
    code span.ex { color: #d73a49; font-weight: bold; } /* Extension */
    code span.fl { color: #005cc5; } /* Float */
    code span.fu { color: #6f42c1; } /* Function */
    code span.im { color: #032f62; } /* Import */
    code span.in { color: #6a737d; } /* Information */
    code span.kw { color: #d73a49; } /* Keyword */
    code span.op { color: #24292e; } /* Operator */
    code span.ot { color: #6f42c1; } /* Other */
    code span.pp { color: #d73a49; } /* Preprocessor */
    code span.re { color: #6a737d; } /* RegionMarker */
    code span.sc { color: #005cc5; } /* SpecialChar */
    code span.ss { color: #032f62; } /* SpecialString */
    code span.st { color: #032f62; } /* String */
    code span.va { color: #e36209; } /* Variable */
    code span.vs { color: #032f62; } /* VerbatimString */
    code span.wa { color: #ff5555; } /* Warning */
  </style>
  <link rel="stylesheet" href="../libs/revealjs/dist/theme/quarto.css">
  <link rel="stylesheet" href="../slides_quarto.css">
  <link href="../libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  
    <link rel="icon" href="../Intro2DS_logo.jpg" type="image/jpg"> 
    <link rel="shortcut icon" href="../Intro2DS_logo.jpg" type="image/jpg">
    <link href="https://fonts.googleapis.com/css?family=Lato:400,700" rel="stylesheet" type="text/css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script></head>
  
  
  

<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="section" class="slide level2 logo-slide">
    <h2></h2>
    </section>
<section id="introduction-to-data-science" class="slide level2 title-slide center">
<h2>Introduction to Data Science</h2>
<h3 id="unsupervised-learning-cluster-analysis---class-15">Unsupervised Learning: Cluster Analysis - Class 15</h3>
<h3 id="giora-simchoni">Giora Simchoni</h3>
<h4 id="gsimchonigmail.com-and-add-intro2ds-in-subject"><code>gsimchoni@gmail.com</code> and add <code>#intro2ds</code> in subject</h4>
<h3 id="stat.-and-or-department-tau">Stat. and OR Department, TAU</h3>
<aside class="notes">
<div style="direction:rtl; font-size:16px">

</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="intro.-to-unsupervised-learning" class="slide level2 title-slide center">
<h2>Intro. to Unsupervised Learning</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נקדיש יחידה אחת ללמידה מסוג שונה. למידה בלתי מפוקחת, או unsupervised learning. מאחר שזה נושא חדש, בואו נדבר קצת על מה זה unsupervised learning ומה שונה ממנה לעומת הלמידה שעסקנו בה עד כה, שמסתבר שאפשר לקרוא לה supervised learning, כלומר למידה כן מפוקחת.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="from-supervised-to-unsupervised">From Supervised to Unsupervised</h3>
<ul>
<li><p>Recall: each observation is made of a vector <span class="math inline">\(x \in \mathcal{X}\)</span> (for example <span class="math inline">\(x \in \mathbb{R}^p\)</span>) and a scalar <span class="math inline">\(y\)</span></p></li>
<li><p>Our goal is to build a model of the relationship between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>: <span class="math display">\[y \approx f(x)\]</span></p></li>
<li><p>IID assumption: each pair <span class="math inline">\((x_i, y_i)\)</span> is drawn indepednently from some distribution <span class="math inline">\(P_{x,y}\)</span></p></li>
<li><p>A modeling approach takes <span class="math inline">\((X, y)\)</span> as input and outputs a <em>prediction model</em> <span class="math inline">\(\hat{f}(x)\)</span></p></li>
<li><p>In prediction: we get a new value <span class="math inline">\(x_0\)</span> and predict <span class="math inline">\(\hat{y}_0 = \hat{f}(x_0)\)</span>.</p></li>
<li><p>How good is our prediction? We typically define a loss function <span class="math inline">\(L(y,\hat{y})\)</span> and the quality of the model is <span class="math inline">\(\mathbb{E}_{x_0,y_0}(L(y_0, \hat{y}_0))\)</span></p></li>
</ul>
<div class="fragment">
<p>What if there is no <span class="math inline">\(y\)</span>?</p>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בלמידה מסוג supervised, יש לנו וקטור X של p משתנים, וסקלאר Y. המטרה היא למדל את Y כפונקציה f של X. אנחנו מניחים שזוגות התצפיות X, Y שלנו מגיעים בלתי תלויים מאיזושהי התפלגות משותפת Pxy, ובונים מודל לחיזוי באמצעות נתוני מדגם הלמידה X, Y, מודל שנקרא f_hat. כשתגיע תצפית חדשה לחיזוי X0 נפעיל עליה את המודל הנלמד f_hat וזה יהיה החיזוי שלנו עבורה. ואיך אנחנו מכמתים את הביצועים של המודל שלנו? באידאל באמצעות איזושהי פונקצית הפסד L בין תצפיות Y האמיתיות והחזויות, כשאנחנו לוקחים תוחלת על תצפיות שהמודל לא ראה. בפועל אנחנו לא יודעים את ההתפלגות של התצפיות שהמודל לא ראה ואנחנו לוקחים את הממוצע האמפירי על מדגם הטסט.</p>
<p>נשאלת השאלה, מה אם אין Y, המשתנה התלוי לחיזוי?</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="unsupervised-learning">Unsupervised Learning</h3>
<ul>
<li><p>Now: each observation is made of a vector <span class="math inline">\(x \in \mathcal{X}\)</span> (for example <span class="math inline">\(x \in \mathbb{R}^p\)</span>)</p></li>
<li><p>IID assumption: each observation <span class="math inline">\(x_i\)</span> is drawn indepednently from some distribution <span class="math inline">\(P_{x}\)</span></p></li>
<li><p>Our goal is to <em>learn</em> distrubution <span class="math inline">\(P_{x}\)</span> (or properties of it)</p></li>
<li><p>“without a supervisor”</p></li>
</ul>
<div>
<ul>
<li class="fragment">Example: Clustering = Finding modes of <span class="math inline">\(P_{x}\)</span> with high density
<ul>
<li class="fragment">If we do find them, maybe <span class="math inline">\(P_{x}\)</span> can be represented by a mixture of simpler densities?</li>
</ul></li>
<li class="fragment">This isn’t new, is it?</li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בלמידה לא מפוקחת יש לנו רק וקטור של משתנים X ממימד p.&nbsp;אנחנו עדיין מניחים שהתצפיות מגיעות בלתי תלויות מאיזו התפלגות לא-ידועה Px, והמטרה שלנו היא לא לאמוד איזושהי פונקציה או קשר אלא ממש את ההתפלגות הזאת, או תכונות שלה.</p>
<p>לדוגמא, ניתוח אשכולות או קלאסטרינג – היינו רוצים ללמוד איזורים בהתפלגות עם צפיפות גבוהה, או השכיחים של P_x. אם נמצא שP_x מתחלקת בבירור לכמה איזורים כאלה למשל, אולי ניתן לייצג אותה בעזרתם, ואז זה יפשט אותה, במקום להיות למשל פונקציה מורכבת בהרבה מימדים נוכל לחלק אותה לצירוף של כמה פונקציות פשוטות יותר.</p>
<p>אבל זה לא ממש חדש נכון? למצוא שכיחים בפונקצית התפלגות, כבר עשינו את זה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="kde-as-unsupervised-learning">KDE as unsupervised learning</h3>
<div class="cell" data-execution_count="1">
<div class="cell-output cell-output-display">
<p><img data-src="c15_clustering_files/figure-revealjs/cell-2-output-1.png" width="524" height="449"></p>
</div>
</div>
<div class="fragment">
<p>Will typically work for <span class="math inline">\(p \le 3\)</span>, above that: “curse of dimensionality”</p>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>זה בדיוק מה שעשינו עם kernel density estimation או KDE, שבו קיבלנו מדגם של נתונים מX שהוא משתנה רציף, וכדי ממש לאמוד את פונקצית הצפיפות שלו עשינו מעין החלקה להיסטוגרמה שלו עם KDE. לדוגמא כאן אפשר לראות שKDE עונה בדיוק על המטרה שלנו בקלאסטרינג, הוא מוצא שאפשר לייצג את פונקצית ההתפלגות של X בעצם בעזרת צירוף של שלוש פונקציות פשוטות נאמר נורמליות, לכל אחת שכיח משלה. בפועל זה נראה שX מורכס משלוש קבוצות או אשכולות שונים, והתובנה הזאת יכולה להיות בעלת ערך לחוקר.</p>
<p>דיברנו על KDE עבור משתנה אחד. ניתן לחשוב על החלקה כזאת בדו-מימד, ואולי בתלת-מימד. מעבר לזה KDE כבר לא כל-כך מעשי בגלל קללת המימד שדיברנו עליה בהקשר של KNN ושיטות מבוססות שכנים. כדי להעריך נכון את הצפיפות על פני מרחב ממימד גבוה צריך הרבה מאוד תצפיות, ולכן הגישה הזאת של לאמוד את Px עבור יותר משניים-שלושה משתנים היא פשוט אל פרקטית, ואנחנו עוברים לתחום של clustering.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="cluster-analysis">Cluster Analysis</h3>
<p>Group a set of observations into subsets, clusters, s.t. those within each cluster are more closely related to one another than observations assigned to different clusters</p>
<div class="fragment">
<p>What for?</p>
<ul>
<li>EDA, Feature Engineering: interesting groups in the data</li>
<li>Segmentation: customers, products, distribution centers location, software</li>
<li>Hierarchy: diseases, evolution</li>
<li>Deduplication</li>
<li>Anomaly Detection</li>
</ul>
</div>
<div class="fragment">
<p>Many, many algorithms:</p>
<ul>
<li>Partition clustering: K-means</li>
<li>Hierarchical clustering: Agglomerative</li>
<li>Density-based clustering: DBSCAN</li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אז בואו נדבר בקלאסטרינג לא על צפיפות כמושג הסתברותי אלא כמושג אינטואיטיבי: אנחנו רוצים למצוא קלאסטרים, קבוצות, איזורים או גושים בדאטא שבהם התצפיות מאוד צפופות וקרובות אחת לשניה, לעומת הקרבה ביניהן לתצפיות בקלאסטרים אחרים.</p>
<p>למה שנרצה לעשות את זה? הנה רשימה חלקית:</p>
<p>קודם כל ראינו שקלאסטרינג משמש אותו באקספלורטורי דאטא אנליסיס, איזושהי אנליזה רכה לנתונים שמסייעת להבין אותם, למצוא קבוצות מעניינות בדאטא. את הקבוצות האלה או ההשתייכות לקבוצות האלה אפשר לנצל אחר-כך כפיצ’רים מעניינים בבניית מודלים לחיזוי.</p>
<p>מטרה אחת אפשר לתאר בגדול כסגמנטציה: אתר שמנסה לחלק את הגולשים שלו לכמה טיפוסים, כמה פרופילים. למשל כדי להקצות לכל פרופיל איש מכירות אחר שהפרופיל הזה יהיה המומחיות שלו. או אתר עם המון מוצרים כמו אמזון שרוצה לחסוך בעבודה הקשה של הרבה מומחים לאלקטרוניקה שהתפקיד שלהם הוא להגיד שפלאפון אייפון 5 ופלאפון אנדרואיד שייכים לאותה קטגוריה או מוצר, אולי אפשר לעשות את זה אוטומטית עם קלאסטרינג על פיצ’רים שמראים שאותם אנשים קונים את שני הפריטים האלה או שהם עשויים מאותם חומרים ועולים סכום דומה של כסף. אפשר לחשוב על חברת פיצה שנכנסת לעיר חדשה ושואלת את עצמה איפה למקום שלושה מרכזי הפצה שהיא מתכננת להקים, הכי משתלם למקם אותם באיזורים שונים שבכל אחד ה”צפיפות” בביקוש לפיצה יהיה גבוה. גם בתוכנה אנחנו עושים קלאסטרינג, במיוחד לתוכנות גדולות ומסורבלות שנוצרו לפני שנים ולאט לאט התפתחו ונוצר צורך לפרק אותן לכמה מודולים, גם בשביל יעילות וגם כדי לחלק את האחריות של אנשי התוכנה להמשיך לפתח ולעשות מיינטננס לכל מודול בנפרד.</p>
<p>בביולוגיה נהוג להשתמש הרבה בקלאסטרינג, למשל להסתכל על פיצ’רים של מחלות כמו תסמינים ולקבץ אותן לסוגים שונים, או לבנות היררכיה של מחלות, עץ.</p>
<p>דוגמא אחרת יכולות להיות דידופליקציה, אם נחזור לאתר שמוכר הרבה פריטים, וכל מוכר נותן כותרת אחרת לפריט שלו, הרבה פעמים לא מדובר במוצר שונה אלא אותו מוצר בדיוק וצריך למחוק במערכות מוצרים חדשים לכאורה שהמערכת כבר אמורה להכיר, דופליקיישנז. דוגמא אחרונה כאן היא זיהוי תצפיות חריגות או אאוטליירז, או בשם המקובל anomaly detection. אם כל האייפונים התקבצו לקלאסטר מסוים ואייפון מסוים לא שייך לקלאסטר, יכול להיות שהוא אנומליה. יכול להיות שבכלל לא מדובר באייפון, למשל הפריט הוא רק כיסוי לאייפון, שהמוכר החליט להכניס לקטגוריה של אייפונים כדי להגדיל את החשיפה שלו.</p>
<p>ויש המון סוגים של אלגוריתמים לקלאסטרינג. יש אלגוריתמים מסוג partition שמבוססים על חלוקה של המרחב לאיזורים שונים זה מזה ככל שניתן וצפופים בתוכם, דוגמא לזה אפשר לראות את KMeans. הרבה אלגוריתמים הם היררכיים, שזה אומר שהם מנסים ליצור חלוקה לקלאסטרים ממצב שכל תצפית היא קלאסטר בפני עצמה, ואנחנו לאט לאט מאחדים זוגות של תצפיות קרובות אחת לשניה, ועד למצב שהדאטא נמצא בקלאסטר אחד גדול. זהו אגלומורטיב קלאסטרינג. אלגוריתמים אחרים באמת חוזרים לרעיון שצריך לאמוד את הצפיפות הטבעית של הדאטא, לא להניח מראש כמה קלאסטרים יש בו ולא להניח שכל התצפיות מתחלקות אליהם, דוגמא לזה הוא הDBSCAN. נעסוק היום בKMeans וב-DBSCAN כמייצגים של המשפחות האלה וגם כי הם סופר-פופולריים בתעשייה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="example-microarray-clustering">Example: Microarray Clustering</h3>

<img data-src="images/microarray_clustering.png" class="r-stretch"><p><a href="https://hastie.su.domains/ElemStatLearn/">source</a></p>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>דוגמא לה ניתן להשיג מקלאסטרינג מבחינת אקספלורטורי דאטא אנליסיס או EDA.</p>
<p>יש כאן בעמודות כמה עשרות דגימות של תאים של גידולי סרטן מסוגים שונים כמו סרטן השחלה או סרטן השד. ובשורות כ6800 גנים ורמת הביטוי שלהם בדגימה. ככל שצבע הגן ירוק יותר כך הוא “בא יותר לביטוי” בדגימה הזאת. התבצע קלאסטרינג מהסוג ההיררכי שדיברנו עליו, גם על השורות וגם על העמודות, כך שזוג שורות קרובות הונחו אחת ליד השניה וגם כל זוג עמודות, ואפשר לראות איך הצעד הזה מחלק יפה גם למשפחות של סוגי סרטן בעמודות וגם למשפחות של גנים שונים שקשורים או לא קשורים לסוגים שונים של סרטן.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="unsupervised-learning-main-drawback">Unsupervised Learning Main Drawback</h3>
<ul>
<li><p>Unless there is “ground truth”, no clear measure of success (as opposed to <span class="math inline">\(\mathbb{E}_{x_0,y_0}(L(y_0, \hat{y}_0))\)</span>)</p></li>
<li><p>Many times involves scrutinizing results and interpretation</p></li>
<li><p>Not for the faint of heart</p></li>
</ul>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>מילה אחרונה של אזהרה בכל הנוגע לתחום של unsupervised learning. אין בלמידה לא-מפוקחת קריטריון ברור להצלחה, בניגוד ללמידה מפוקחת שם יש לנו את ה”מפקח” את Y ואת הלוס L, שלאורם אנחנו מכווננים את המודל שלנו, אנחנו מודדים את עצמנו.</p>
<p>הרבה פעמים כמו בדוגמא בשקף הקודם ההצלחה של מודל קלאסטרינג מערבת הרבה בחינה ידנית ושיפוט של הלקוח הסופי. הרבה בערך. ברור שלפעמים יש ground truth, ואנחנו מצפים מהקלאסטרים להיות בחפיפה עם קבוצות ידועות באוכלוסיה או בהתפלגות. ברור גם שפתרון קלאסטרינג על אותם נתונים שהצליח למצוא קבוצות יותר צפופות בתוכן ויותר רחוקות אחת מהשניה - הוא פתרון טוב יותר.</p>
<p>אבל בשורה התחתונה יש הרבה יותר מקום לפרשנות, אין קריטריון מנצח - וכדאי להיות מוכנים מנטלית לזה כשניגשים לפרויקט קלאסטרינג.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="k-means-clustering" class="slide level2 title-slide center">
<h2>K-means Clustering</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נדבר כעת על אלגוריתם KMeans, אולי המוכר ביותר בתחום, וגם יעיל יחסית ועובד טוב עם נתונים ממימד גבוה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="how-to-evaluate-a-partition">How to evaluate a partition?</h3>
<ul>
<li><p>Assume <span class="math inline">\(K\)</span> clusters are given</p></li>
<li><p><span class="math inline">\(C(i) = k\)</span> is some function assigning cluster <span class="math inline">\(k \in \{1, \dots, K\}\)</span> to observation <span class="math inline">\(i \in \{1, \dots, n\}\)</span></p></li>
<li><p><span class="math inline">\(d(x_i, x_j)\)</span> is a distance metric for pair <span class="math inline">\(i, j\)</span>, e.g.&nbsp;Euclidean</p></li>
<li><p>We wish to minimize the extent to which observations assigned to the same cluster tend to be close to one another</p></li>
</ul>
<div>
<ul>
<li class="fragment"><p>The “within cluster” scatter/loss: <span class="math display">\[W(C) = \frac{1}{2}\sum_{k = 1}^K \sum_{C(i) = k} \sum_{C(j) = k} d(x_i, x_j)\]</span></p></li>
<li class="fragment"><p>equivalent to maximizing <span class="math inline">\(B(C) = \frac{1}{2}\sum_{k = 1}^K \sum_{C(i) = k} \sum_{C(j) \neq k} d(x_i, x_j)\)</span></p></li>
<li class="fragment"><p>Can we go over all possible <span class="math inline">\(C(i)\)</span> to find the global minimum?</p></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נניח שיש לנו חלוקה נתונה. paritition. איך אנחנו עושים איבליואציה של חלוקה כזאת על הנתונים שלנו.</p>
<p>נניח שאנחנו יודעים כבר את מספר הקלאסטרים בדאטא ומסמנים אותו בK, ונניח שיש לנו כבר כלל חלוקה C שמתאים לכל תצפית i בנתונים את הקלאסטר k שמתאים לה, מ1 עד K גדול.</p>
<p>נניח כעת שצפיפות של נתונים או עד כמה זוג תצפיות קרובות אחת לשניה נמדוד באמצעות איזושהי מטריקת מרחק d, לדוגמא נתחיל עם מרחק אוקלידי.</p>
<p>ואנחנו רוצים לבטא באמצעות איזושהי מטריקה את האינטואיציה שלנו שתצפיות באותו קלאסטר צריכות להיות צפופות ורחוקות מתצפיות בקלאסטרים אחרים.</p>
<p>הרבה אלגוריתמים מסתכלים על המטריקה הבאה, הפיזור within cluster שנסמן בW(C), והוא סכום על כל זוגות התצפיות ששייכות לקלאסטר k של המרחקים ביניהן, וסכום על כל הקלאסטרים, מוכפל פי חצי כי אנחנו סופרים כל זוג ככה פעמיים.</p>
<p>מאחר שהפיזור בין כל זוגות התצפיות בלי קשר לחלוקה לקלאסטרים נשאר זהה, אפשר להראות שלעשות מינימום לקריטריון שלנו אקוויולנטי ללעשות מקסימום לכמות המשלימה של between clusters סקאטר או לוס: סכום המרחקים בין כל זוגות התצפיות שנמצאות בקלאסטרים שונים. הרי סכום הכמות הזאת והכמות שלנו W(C) מסתכמם בפיזור כללי נאמר T(C).</p>
<p>אז יש לנו מטריקה לעשות לה מינימום. אבל אפילו עם K נתון, נאמר שאנחנו רוצים לחלק את הדאטא ל4 קלאסטרים. האם אנחנו יכולים לעבור על כל החלוקות C(i) האפשריות כדי להגיע למינימום גלובלי? ברור שלא. יש לזה נוסחה שלא מופיעה כאן, אפשר לחשב למשל שלעבור על כל האפשרויות של חלוקת 20 תצפיות ל5 קלאסטרים אנחנו כבר מדברים על כמעט 750 מיליארד אפשרויות!</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="road-to-k-means">Road to K-means</h3>
<ul>
<li><p>Euclidean distance: <span class="math inline">\(d(x_i, x_j) = \sum_{m=1}^p (x_{im} - x_{jm})^2 = ||x_i - x_j||^2\)</span></p></li>
<li><p>Can show that: <span class="math inline">\(W(C) = \frac{1}{2}\sum_{k = 1}^K \sum_{C(i) = k} \sum_{C(j) = k} ||x_i - x_j||^2 = \sum_{k = 1}^K n_k \sum_{C(i) = k} ||x_i - \bar{x}_k||^2\)</span></p></li>
<li><p><span class="math inline">\(\bar{x}_k \in \mathbb{R}^p\)</span> being the mean in cluster <span class="math inline">\(k\)</span>, and <span class="math inline">\(n_k\)</span> number of observations in cluster <span class="math inline">\(k\)</span></p></li>
</ul>
<div>
<ul>
<li class="fragment"><p>But for any set of observations <span class="math inline">\(S\)</span>, which <span class="math inline">\(m\)</span> would minimize <span class="math inline">\(\sum_{i \in S} ||x_i - m||^2\)</span>?</p></li>
<li class="fragment"><p>Thus, the final goal of K-means: <span class="math display">\[\min\limits_{C, m_1, \dots, m_K} \sum_{k = 1}^K n_k \sum_{C(i) = k} ||x_i - m_k||^2\]</span></p></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אז Kmeans קודם כל מצמצם אותנו למרחק אוקלידי בלבד.</p>
<p>תחת מרחק אוקלידי, אפשר להראות שאפשר לרשום את הקריטריון שלנו בצורה פשוטה יותר: בכל קלאסטר סכום המרחקים מהתצפיות אל ממוצע הקלאסטר, להכפיל במספר התצפיות בקלאסטר n_k, ולסכום על כל הקלאסטרים.</p>
<p>אבל אנחנו יודעים כבר שאם נסתכל על קריטריון דומה, ונשאל מה הנקודה שמביאים למינימום את סכום המרחקים המרובעים ממנה – נגיע לממוצע המדגם.</p>
<p>לכן נהוג לרשום את הקריטריון של Kmeans בצורה כוללת יותר: למצוא את החלוקה ואת הנקודות של קלאסטרים שיביאו למינימום את סכום המרחקים המרובעים בתוך כל קלאסטר, על פני כל הקלאסטרים. צורת הרישום הזאת מסייעת לנסח את האלגוריתם של Kmeans.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="k-means">K-means</h3>
<ol start="0" type="1">
<li><p>Start with initial guess for <span class="math inline">\(m_1, \dots, m_K\)</span></p></li>
<li><p>Assign each observation to the closest cluster mean. That is: <span class="math display">\[C(i) = \arg\min\limits_{k = 1\dots K} ||x_i - m_k||^2\]</span></p></li>
<li><p>Update means <span class="math inline">\(m_1, \dots, m_K\)</span>. That is the centroids: <span class="math display">\[m_k = \frac{\sum_{C(i) = k}x_i}{n_k}\]</span></p></li>
<li><p>Repeat 1 and 2 until <span class="math inline">\(C(i)\)</span> doesn’t change</p></li>
</ol>
<div>
<ul>
<li class="fragment"><p>Convergence is guaranteed (steps 1 and 2 can only reduce <span class="math inline">\(W(C)\)</span>)</p></li>
<li class="fragment"><p>Global optimum is NOT guaranteed</p></li>
<li class="fragment"><p>Can try many different initial starting points</p></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אז מהו האלגוריתם של Kmeans?</p>
<p>K נתון, ואנחנו מתחילים עם איזשהו ניחוש התחלתי עבור הממוצעים m1 עד mk.</p>
<p>כעת החלוקה C(i) של כל תצפית תהיה לפי הקלאסטר שהממוצע שלו הוא הקרוב אליה ביותר.</p>
<p>לאחר החלוקה נעדכן את הממוצעים, בכל קלאסטר ניקח את הממוצע של התצפיות ששייכות אליו.</p>
<p>ונחזור על צעדים 1 ו2 עד שהחלוקה לא משתנה או עד איזשהו קריטריון התכנסות, למשל אפשר לחשב את הלוס שלנו W(C) ולראות שהוא לא משתנה יותר מדי.</p>
<p>מה הבעיה הראשונה באלגוריתם? אמנם התכנסות מובטחת, הצעדים שלנו יכולים רק להפחית את W(C), או לא לשנות אותו. אבל אין הבטחה למינימום גלובלי ואנחנו מאוד תלויים בבחירה הראשונית של הממוצעים שיכולה להיות אקראית.</p>
<p>נהוג לכן בהרבה מימושים לבצע מספר פעמים Kmeans כל פעם מנקודת התחלה אקראית אחרת ולבחור את הפתרון עם הלוס המינימלי.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="k-means-demo-initial-guess">K-means Demo: Initial Guess</h3>
<div class="cell" data-execution_count="3">
<div class="cell-output cell-output-display">
<p><img data-src="c15_clustering_files/figure-revealjs/cell-4-output-1.png" width="376" height="411"></p>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בדוגמא שלפנינו ברור שיש 4 קלאסטרים, ואנחנו מתחילים עם 4 נקודות אקראיות כממוצעים, מאוד לא מתאימות לחלוקה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="k-means-demo-iteration-1">K-means Demo: Iteration 1</h3>
<div class="cell" data-execution_count="4">
<div class="cell-output cell-output-display">
<p><img data-src="c15_clustering_files/figure-revealjs/cell-5-output-1.png" width="781" height="411"></p>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בצעד 1 אנחנו מחלקים כל תצפית לקלאסטר עם הממוצע הכי קרוב אליה במרחק אוקלידי, כאן זה אומר לצבוע אותן ב4 צבעים שונים.</p>
<p>בצעד 2 אנחנו מעדכנים את הממוצעים, וכבר ניתן לראות איך כל ממוצע מייצג כבר איזור הרבה יותר צפוף באופן טבעי.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="k-means-demo-iteration-2">K-means Demo: Iteration 2</h3>
<div class="cell" data-execution_count="5">
<div class="cell-output cell-output-display">
<p><img data-src="c15_clustering_files/figure-revealjs/cell-6-output-1.png" width="781" height="411"></p>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>ושוב אנחנו מחלקים את התצפיות לפי הקרבה שלהן לממוצע החדש.</p>
<p>ושוב אנחנו מעדכנים את הממוצעים. כאן הם כבר זזים ממש מעט.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="k-means-demo-iteration-3">K-means Demo: Iteration 3</h3>
<div class="cell" data-execution_count="6">
<div class="cell-output cell-output-display">
<p><img data-src="c15_clustering_files/figure-revealjs/cell-7-output-1.png" width="781" height="411"></p>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>באיטרציה השלישית כבר בקושי אפשר לראות הבדל, הקלאסטרים כבר ברורים מאוד.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="k-means-on-netflix">K-means on Netflix</h3>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> kmeans.fit(NE_Xtr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>What did we get?</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(kmeans.cluster_centers_.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell fragment" data-execution_count="9">
<div class="cell-output cell-output-stdout">
<pre><code>(2, 14)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(kmeans.labels_[:<span class="dv">10</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell fragment" data-execution_count="10">
<div class="cell-output cell-output-stdout">
<pre><code>[1 0 0 1 1 1 0 0 0 1]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>kmeans<span class="sc">.</span>inertia_<span class="sc">:.2f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell fragment" data-execution_count="11">
<div class="cell-output cell-output-stdout">
<pre><code>68827.01</code></pre>
</div>
</div>
<p>Can easily “predict”:</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>test_labels <span class="op">=</span> kmeans.predict(NE_Xte)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>test_labels[:<span class="dv">10</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell fragment" data-execution_count="12">
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>array([0, 1, 0, 0, 1, 0, 1, 0, 0, 0])</code></pre>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נראה עכשיו איך מבצעים Kmeans על הנתונים של נטפליקס.</p>
<p>כאן אני עושה import מתוך מודול קלאסטר לקלאס Kmeans. אני מאתחל אותו ומבקש 2 קלאסטרים על הצופים שלנו שדירגו סרטים מ1 עד 5. כשאני קורא לfit על הטריינינג דאטא אז רץ האלגוריתם. מה קיבלנו?</p>
<p>בשדה cluster_centers קיבלנו את הממוצעים עצמם. בעצם מדובר במטריצה עם 2 שורות ו14 עמודות, כי ביקשנו שני קלאסטרים ויש לנו 14 סרטים בדאטא, כל ממוצע הוא וקטור באורך 14.</p>
<p>בשדה לייבלז יש את האינדיקטור שמתאר כל תצפית האם היא שייכת לקלאסטר הראשון או השני, או יותר אם היינו מבקשים יותר קלאסטרים.</p>
<p>בשדה inertia יש את קריטריון הW(C) שלנו.</p>
<p>ובאלגוריתם Kmeans באופן טבעי אפשר לחזות במרכאות לאיזה קלאסטר שייכת תצפית שלא ראינו ממדגם הטסט. אני אומר לחזות במרכאות כי זה בעצם יותר לשייך אותה. תצפית שלא ראינו שייכת לקלאסטר עם הממוצע הקרוב ביותר אליה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="k-means-on-netflix-the-centroids">K-means on Netflix: the Centroids</h3>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>pd.DataFrame({<span class="st">'title'</span>: kmeans.feature_names_in_,</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">'mean_score'</span>: NE_Xtr.mean(axis <span class="op">=</span> <span class="dv">0</span>),</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'m_1'</span>: kmeans.cluster_centers_[<span class="dv">0</span>],</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'m_2'</span>: kmeans.cluster_centers_[<span class="dv">1</span>]}).set_index(<span class="st">'title'</span>).head(<span class="dv">8</span>).<span class="bu">round</span>(<span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mean_score</th>
<th data-quarto-table-cell-role="th">m_1</th>
<th data-quarto-table-cell-role="th">m_2</th>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">title</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">Independence Day</td>
<td>4.14</td>
<td>4.48</td>
<td>3.78</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">The Patriot</td>
<td>4.11</td>
<td>4.46</td>
<td>3.72</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">The Day After Tomorrow</td>
<td>3.70</td>
<td>4.15</td>
<td>3.20</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Pirates of the Caribbean</td>
<td>4.35</td>
<td>4.57</td>
<td>4.11</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Pretty Woman</td>
<td>4.08</td>
<td>4.39</td>
<td>3.73</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Forrest Gump</td>
<td>4.51</td>
<td>4.67</td>
<td>4.34</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">The Green Mile</td>
<td>4.46</td>
<td>4.69</td>
<td>4.20</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Con Air</td>
<td>3.72</td>
<td>4.13</td>
<td>3.27</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>עכשיו כפי שאמרנו קשה לדעת עם Kmeans במיוחד אם הדאטא ממימד גבוה אם הגענו לפתרון “איכותי” ומה משמעות הקלאסטרים, בלי דרכים יצירתיות לנסות להבין את זה, בצורה קצת ידנית.</p>
<p>כאן אני לוקח את שמונת הסרטים הראשונים, מדפיס את ממוצע הדירוגים שלהם, ולידם את ממוצע הקלאסטר הראשון ואת ממוצע הקלאסטר השני.</p>
<p>דבר ראשון שאני שם לב אליו זה שהציון הממוצע של כל סרט נמצא בין שני הקלאסטרים (להדגים). דבר שני הוא שבכל הסרטים הממוצע של הקלאסטר הראשון גבוה יותר מממוצע הקלאסטר השני. זה מזכיר לכם משהו? זה מזכיר מאוד את הPC הראשון של הנתונים האלה, שאמרנו שבעצם מדרג את כל הצופים על-פי כמה הם מסכימים עם הדירוג הכללי שהוא די גבוה, כלומר כמה הם נוטים לצאת ציונים גבוהים לעומת לתת ציונים נמוכים לכל הסרטים.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="k-means-on-netflix-discrete-first-pc">K-means on Netflix: “discrete” first PC!</h3>
<div class="cell" data-execution_count="14">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>X_centered <span class="op">=</span> NE_Xtr <span class="op">-</span> NE_Xtr.mean(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>pca.fit(X_centered)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> pca.transform(X_centered)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>c_dict <span class="op">=</span> {<span class="dv">0</span>:<span class="st">'Cluster1'</span>, <span class="dv">1</span>:<span class="st">'Cluster2'</span>, <span class="dv">2</span>:<span class="st">'Cluster3'</span>, <span class="dv">3</span>:<span class="st">'Cluster4'</span>}</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>clusters <span class="op">=</span> np.vectorize(c_dict.get)(kmeans.labels_)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> sns.jointplot(x<span class="op">=</span>T[:, <span class="dv">0</span>], y<span class="op">=</span>T[:, <span class="dv">1</span>], hue<span class="op">=</span>clusters, height<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>ax.set_axis_labels(<span class="st">'PC1: Popular Vote'</span>, <span class="st">'PC2: Romance vs. Action'</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img data-src="c15_clustering_files/figure-revealjs/cell-15-output-1.png" width="487" height="489"></p>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אפשר לראות את זה אם נצבע את כל הצופים בשני צבעים שונים על-פי ההשתייכות שלהם לקלאסטרים, במרחב ההטלה שמצאנו בPCA, כשאנחנו עושים תרשים פיזור של PC1 מול PC2 שכבר ראינו.</p>
<p>בקלאסטר אחד יש את הצופים שנוטים לתת ציונים גבוהים, ובקלאסטר שני צופים שנוטים לתת ציונים נמוכים. במובן מסוים זה נראה כאילו הפתרון של Kmeans הוא איזושהי דיסקרטיזציה של הפתרון PCA, במקום ממשי על פני כל הכיוון של הPC הראשון קיבלנו חלוקה לשתי קטגוריות, גבוה ונמוך. ויש עבודות שמראות שזה כמובן לא מקרי, אפשר לראות Kmeans כדיסקרטיזציה של PCA ומזה לצאת לעוד תובנות.</p>
<p>אם הייתי מבקש שלושה קלאסטרים הייתי מקבל 3 קבוצות בכיוון הPC הראשון, נמוך בינוני, גבוה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="k-means-on-netflix-higher-k">K-means on Netflix: higher <span class="math inline">\(K\)</span></h3>
<div class="cell" data-execution_count="15">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>kmeans.fit(NE_Xtr)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>clusters <span class="op">=</span> np.vectorize(c_dict.get)(kmeans.labels_)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> sns.jointplot(x<span class="op">=</span>T[:, <span class="dv">0</span>], y<span class="op">=</span>T[:, <span class="dv">1</span>], hue<span class="op">=</span>clusters, height<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>ax.set_axis_labels(<span class="st">'PC1: Popular Vote'</span>, <span class="st">'PC2: Romance vs. Action'</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img data-src="c15_clustering_files/figure-revealjs/cell-16-output-1.png" width="487" height="489"></p>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>ורק כשאני מבקש K = 4, אני מקבל ביטוי של הPC השני. עדיין שתי קבוצות גדולות של צופים שנוטים לדרג גבוה או נמוך, והקבוצה השלישית מתחלק על-פי הטעם שלהם בסרטים רומנטיים.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="k-means-issues" class="slide level2 title-slide center">
<h2>K-means Issues</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כל זה מרתק וגם יכול לעבוד בסקאלות די גבוהות של תצפיות ושל משתנים, אבל Kmeans ידוע לשמצה במספר בעיות שיש לו, בואו נראה כמה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="how-to-choose-k">How to choose <span class="math inline">\(K\)</span>?</h3>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>W_C <span class="op">=</span> []</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> K <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>, <span class="dv">20</span>):</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>K)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    kmeans.fit(NE_Xtr)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    W_C.append(kmeans.inertia_)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="17">
<div class="cell-output cell-output-display">
<p><img data-src="c15_clustering_files/figure-revealjs/cell-18-output-1.png" width="536" height="376"></p>
</div>
</div>
<div class="fragment">
<p>The “elbow” method won’t always work, there are others.</p>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בדומה לשיטות שראינו בלמידה supervised יש לנו כאן מעין היפרפרמטר שהשיטה לא לומדת, אנחנו צריכים לתת לה אותו כאינפוט, וזה הK, מספר הקלאסטרים.</p>
<p>והקריטריון של Kmeans בעייתי כי ככל שנגדיל את מספר הקלאסטרים כך הוא יקטן. בקצה אפשר לחשוב על מצב שבו K = N, כל תצפית בקלאסטר משלה, היא גם הממוצע ולכן סכום המרחקים מהממוצע יהיה 0. נהוג לכן לבצע Kmeans עבור K שונים על מדגם למידה, ולנסות לראות בשיטת המרפק או האלבואו איפה יש ירידה חדה בקריטריון ככה שנראה שעברנו איזשהו סף של חלוקה טבעית, וזה הK שנבחר.</p>
<p>הבעיה שכמו בנתונים שלפנינו השיטה הזאת לא תמיד תעבוד, לא ברור מה הK המתאים לנתונים האלה מהקריטריון, והיא גם ידנית. יש שיטות אחרות עם קריטריונים מחוכמים יותר. יש גם פתרונות שמשווים את הקריטריון של החלוקה שלנו לקריטריון המושג עם חלוקה אקראית או חלוקה שמניחה שהדאטא מתפלג בצורה אחיד על פני המרחב, ואז בוחרים בK שמביא להפרש הגדול ביותר, הK שמביא להפתעה הגדולה ביותר לעומת חלוקה אקראית. מי שרוצה לקרוא עוד יכול לקרוא על הgap sttaistic.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="should-you-always-standardize">Should you always standardize?</h3>
<p>As with KNN, K-means would be higly influenced by a feature with high variance.</p>
<p>But what if <em>that</em> feature is important for clustering?</p>
<div class="cell" data-execution_count="18">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">30</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>m1 <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>m2 <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>sig <span class="op">=</span> np.eye(<span class="dv">2</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.RandomState(<span class="dv">4</span>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>X1 <span class="op">=</span> rng.multivariate_normal(mean<span class="op">=</span>[<span class="op">-</span>m1, m2], cov<span class="op">=</span>sig, size<span class="op">=</span>n)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>X2 <span class="op">=</span> rng.multivariate_normal(mean<span class="op">=</span>[m1, m2], cov<span class="op">=</span>sig, size<span class="op">=</span>n)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.concatenate([X1, X2], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">0</span>).fit(X)</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(nrows<span class="op">=</span><span class="dv">1</span>, ncols<span class="op">=</span><span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].scatter(X[:, <span class="dv">0</span>], X[:, <span class="dv">1</span>], c<span class="op">=</span>kmeans.labels_, cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlim((<span class="op">-</span><span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylim((<span class="op">-</span><span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'K-means without standardizing'</span>)</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>X_stan <span class="op">=</span> StandardScaler().fit_transform(X)</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>kmeans_stan <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">0</span>).fit(X_stan)</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].scatter(X_stan[:, <span class="dv">0</span>], X_stan[:, <span class="dv">1</span>], c<span class="op">=</span><span class="dv">1</span><span class="op">-</span>kmeans_stan.labels_, cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlim((<span class="op">-</span><span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylim((<span class="op">-</span><span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'K-means with standardizing'</span>)</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell fragment" data-execution_count="18">
<div class="cell-output cell-output-display">
<p><img data-src="c15_clustering_files/figure-revealjs/cell-19-output-1.png" width="796" height="431"></p>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>עניין אחר בKmeans הוא שבהגדרה מדובר במרחק אוקלידי. אי אפשר פשוט להשתמש בKmeans עם מרחק אחר. וזה אומר שבדומה לKNN הוא מושפע מאוד מתצפיות חריגות וממשתנים בסקאלות רחבות מאוד, הם ישפיעו הרבה יותר על הפתרון. אז בעקרון ההמלצה היא לעשות סטנדרטיזציה לנתונים, אבל חשוב להזכיר להביט בנתונים כמה שניתן, יכולים להיות מקרים קיצוניים שבהם הסטנדרטיזציה הזאת עלולה להזיק לאיכות הפתרון.</p>
<p>כאן למשל די ברור שיש לנו שני קלאסטרים בדאטא הצהוב והסגול כי ככה הם גם נוצרו. אבל הם נבדלים זה מזה הודות למשתנה שבציר הX, הם לא נבדלים זה מזה בכלל במשתנה שבציר הY. אבל למשתנה בציר הX יש פיזור גבוה הרבה יותר, ואכן, לאחר סטנדרטיזציה כדי שלמשתנים יהיה פיזור דומה, החלקה לשני קלאסטרים שהיתה כל כך ברורה מיטשטשטת, וKmeans מוצא פתרון שמתאים פחות לבעיה המקורית, ואין דרך לדעת את זה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="k-means-failures-i">K-means failures (I)</h3>
<p>Prefers separable spherical clusters (Gaussian).</p>
<div class="cell" data-execution_count="19">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_circles</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>X_circles, _ <span class="op">=</span> make_circles(n_samples<span class="op">=</span><span class="dv">500</span>, factor<span class="op">=</span><span class="fl">0.5</span>, noise<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">0</span>).fit(X_circles)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_circles[:, <span class="dv">0</span>], X_circles[:, <span class="dv">1</span>], c<span class="op">=</span>kmeans.labels_)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img data-src="c15_clustering_files/figure-revealjs/cell-20-output-1.png" width="507" height="411"></p>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>Kmeans אוהב דאטא שמחולק ל”גושים” אפשר להראות שהוא דומה מאוד לאלגוריתם שמנסים לחלק את הדאטא לצפיפויות של מספר התפלגויות נורמליות, עם פיזור סימטרי כזה בכל הכיוונים סביב הממוצע.</p>
<p>כשהדאטא נראה כמו כמו הדאטא שלנו, שברור שיש שני קלאסטרים אבל הם לא spherical, הם באים בדפוס הרבה יותר מתוחכמים של טבעות – Kmeans נכשל לחלוטין.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="k-means-failures-ii">K-means failures (II)</h3>
<p>Always specify <span class="math inline">\(K\)</span>.</p>
<div class="cell" data-execution_count="20">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>X_square <span class="op">=</span> np.random.rand(<span class="dv">1000</span>, <span class="dv">2</span>)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">0</span>).fit(X_square)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_square[:, <span class="dv">0</span>], X_square[:, <span class="dv">1</span>], c<span class="op">=</span>kmeans.labels_)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img data-src="c15_clustering_files/figure-revealjs/cell-21-output-1.png" width="496" height="411"></p>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>עניין אחר שתמיד צריך להגיד מהו K, ותמיד נקבל חלוקה לK קלאסטרים, בלי שום מטריקה שתגיד לנו אם החלוקה עושה שכל או לא. כאן לדוגמא יש ריבוע עם המון תצפיות בהתפלגות אחידה וKmeans פשוט מחזיר 3 איזורים איך שבא לא, הוא לא מגיע עם אזהרה שאומרת שאין חלוקה “הגיונית” לשלושה קלאסטרים לדאטא כאן.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="k-means-failures-iii">K-means failures (III)</h3>
<p>No concept of outliers.</p>
<div class="cell" data-execution_count="21">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>centers <span class="op">=</span> np.eye(<span class="dv">2</span>) <span class="op">*</span> <span class="dv">5</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>X_out, _ <span class="op">=</span> make_blobs(n_samples<span class="op">=</span><span class="dv">100</span>, centers<span class="op">=</span>centers, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>X_out <span class="op">=</span> np.concatenate([X_out, np.array([[<span class="dv">10</span>, <span class="dv">10</span>]])], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">0</span>).fit(X_out)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_out[:, <span class="dv">0</span>], X_out[:, <span class="dv">1</span>], c<span class="op">=</span><span class="dv">1</span><span class="op">-</span>kmeans.labels_)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img data-src="c15_clustering_files/figure-revealjs/cell-22-output-1.png" width="495" height="411"></p>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בהמשך לדוגמא הקודמת לכל תצפית גם חייב להיות סיווג בKmeans. אין לו קונספט כזה של outliers, ואם לא מבצעים עוד איזשהו עיבוד פוסט-הוק ולוקחים א הסיווג של כל תצפית כמובן מאליו, אפשר לקבל מצב כמו כאן שהתצפית החריגה שייכת לקבוצה הסגולה למרות שברור שהיא לא.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="k-means-failures-iv">K-means failures (IV)</h3>
<p>Bad with unequal densities, unequal cluster sizes.</p>
<div class="cell" data-execution_count="22">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>X_varied, y <span class="op">=</span> make_blobs(n_samples<span class="op">=</span>[<span class="dv">300</span>, <span class="dv">150</span>, <span class="dv">300</span>], cluster_std<span class="op">=</span>[<span class="fl">1.0</span>, <span class="fl">2.5</span>, <span class="fl">0.5</span>], random_state<span class="op">=</span><span class="dv">170</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">170</span>).fit(X_varied)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_varied[:, <span class="dv">0</span>], X_varied[:, <span class="dv">1</span>], c<span class="op">=</span>kmeans.labels_)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img data-src="c15_clustering_files/figure-revealjs/cell-23-output-1.png" width="498" height="411"></p>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כאן יש דוגמא שמראה גם קלאסטרים בגודל שנה וגם קלאסטרים עם רמת צפיפות שונה, והבעייתיות שבפתרון של Kmeans. בקלאסטר האמצעי יש גם פי 2 פחות תצפיות מהקלאסטרים האחרים וגם הפיזור שלו גדול הרבה יותר. ואפשר לראות איך הקלאסטרים עם הרבה תצפיות וצפופים מושכים אליהם תצפיות שאולי היינו מסווגים כשייכות לקלאסטר הפנימי אם היינו יכולים למדל את כל השלוש כצפיפויות נורמליות, ככה הנתונים נוצרו.</p>
<p>אז יש מספר בעיות עם Kmeans. בואו נראה אלגוריתם מאוחר יותר שמטפל בהרבה מהבעיות האלה, גם הוא מאוד פופולרי בתעשייה, הוא נקרא DBSCAN.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="dbscan" class="slide level2 title-slide center">
<h2>DBSCAN</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>דיביסקאן פירושו Density-Based Spatial Clustering of Applications with Noise, והוא חלק ממשפחה של אלגוריתמים של קלאסטרינג שמחזירים אותנו למושג של צפיפות או התפלגות.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="density-based-clustering">Density Based Clustering</h3>
<ul>
<li><p>Back to premise, data comes from a distribution: <span class="math inline">\(X \sim P_x\)</span></p></li>
<li><p>Estimating <span class="math inline">\(P_x\)</span> is hard</p></li>
<li><p>Find high-density regions through <em>connected components</em></p></li>
</ul>
<div class="fragment">
<ul>
<li>Immediate Pros:
<ul>
<li>No specifying <span class="math inline">\(K\)</span></li>
<li>Outliers</li>
<li>More complex clustering structures</li>
</ul></li>
</ul>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>הבעיה בחזרה לקונספט של התפלגות או צפיפות שהיינו רוצים לאמוד היא שזה גם מחזיר אותנו לקושי לעשות את זה בצורה טובה. וכאן החוקרים שפיתחו את DBSCAN, לקחו השראה מתורת הגרפים שם אנחנו עושים קלאסטרינג על גרף של צמתים בצורה טבעית מאוד, שני צמתים קרובים זה לזה אם יש ביניהם קשת. ואז מתקבל הרבה פעמים מבנה שנקרא connected components, תת גרפים שבהם הצמתים קשורים זה לזה.</p>
<p>היתרונות המיידיים של השיטה הזאת: אין צורך לפרט את K, הוא צומח הישר מהדאטא. אולי יש כאן קומפוננטה אחת, אולי חמש.</p>
<p>יתרון אחר הוא שאם יש תצפיות שלא שייכות לקומפוננטות הגדולות, הן אנומליות, הן אאוטליירז.</p>
<p>לבסוף כפי שתיכף נראה הגישה המאוד א-פרמטרית הזאת מביאה גם לאלגוריתמים שמזהים נכון קלאסטרים עם מבנים מסובכים יותר מ”גושים” של תצפיות, למשל טבעת בתוך טבעת שראינו.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="dbscan-1">DBSCAN</h3>
<p>Density-Based Spatial Clustering of Applications with Noise</p>

<img data-src="images/dbscan_example.png" style="width:70.0%" class="r-stretch"><ul>
<li>3 types of points: core, border, noise</li>
<li>Core points are high-density points (parameters: <span class="math inline">\(\varepsilon\)</span> (radius), <span class="math inline">\(minPts\)</span>)</li>
<li>Connect core points into clusters</li>
<li>Assign border points to clusters</li>
<li>All else: noise</li>
</ul>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אז איך עובד DBSCAN.</p>
<p>דיביסקאן יחלק כל תצפית לאחד משלושה סוגים: core, ליבה, border, גבול, noise, רעש.</p>
<p>תצפיות קור הן תצפיות שנמצאות באיזור צפוף של נתונים. בצורה מדויקת יותר אם נגדיר איזשהו רדיוס של שכונה אפסילון, נשאל האם ברדיוס הזה סביב התצפית יש לפחות מינימום תצפיות, לפי פרמטר אחר שנגדיר מינפוינטס. אם כן נסווג תצפית כזאת כתצפית ליבה.</p>
<p>נחבר את כל תצפיות הקור שנמצאות בשכונה אחת של השכונה לקלאסטרים, וגם התצפיות שנמאות בשכונה שלהן אבל הן לא סווגו כתצפיות ליבה. תצפיות כאלה הן תצפיות בורדר, גבול. לבסוף שאר התצפיות שלא שייכות לקלאסטר הן תצפיות נויז, רעש, אאוטליירז.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="dbscan---abstract">DBSCAN - Abstract</h3>

<img data-src="images/dbscan_algo2.png" class="r-stretch"><p><a href="https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/">Nice visualiztion</a></p>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כל מה שאמרתי עכשיו אפשר לקרוא כאלגוריתם פשוט מהמאמר המקורי (להדגים).</p>
<p>אפשר גם להביט בויזואליזציה נחמדה שממחישה זאת (להדגים).</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="dbscan---actual">DBSCAN - Actual</h3>

<img data-src="images/dbscan_algo1.png" class="r-stretch"><aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כדי לייעל את הפרוצדורה כמו שהמחברים כותבים וכמו שאולי שמתם לב בדמו, האלגוריתם שבאמת נמצא בשימוש הוא קצת יותר מורכב ויש אותו כאן בפסאודו קוד.</p>
<p>אין מה להיבהל מזה, אם תעברו עליו לאט לאט תראו שהוא דווקא די הגיוני. אנחנו עוברים על כל תצפית. אם כבר סיווגנו אותה לקלאסטר נמשיך לתצפית הבאה. אם לא – צריך לסווג אותה. נסתכל על כל השכנים שלה, כלומר כל התצפיות שנמצאות במרחק עד אפסילון ממנה, נניח שזה כבר חושב עבורנו. אם מספר התצפיות לא עובר את פרמטר מינפוינטס התצפית כרגע רעש ועוברים לתצפית הבאה. אם כן יש מספיק שכנים נתחיל קלאסטר חדש c ונשייך את התצפית אליו, ונרצה לשייך את כל השכנים שלה אליו.</p>
<p>נעבור שכן שכן. אם השכן הוגדר כרעש ברור שצריך להיות מסווג לקלאסטר הנוכחי c.&nbsp;אם הוא כבר סווג לקלאסטר אחר לא נשנה את זה. ואם הוא לא מוגדר אז שוב ברור שהוא שייך לקלאסטר הנוכחי, אבל גם נבדוק את השכנים שלו. אם יש לו מעט אפשר להמשיך לשכן הבא, אבל אם יש לו הרבה אפשר פשוט להוסיף אותם לרשימת השכנים ולתת לחיפוש להמשיך לפעפע ברשימת השכנים החדשה.</p>
<p>באופן כזה עוברים על כל התצפיות כפי שראינו בדמו, כל פעם מתחילים קלאסטר חדש אם צריך וממצים אותו לעומק עד שנגמר החיפוש.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="dbscan-on-netflix">DBSCAN on Netflix</h3>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> DBSCAN</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>dbscan <span class="op">=</span> DBSCAN(eps<span class="op">=</span><span class="fl">1.0</span>, min_samples<span class="op">=</span><span class="dv">10</span>, metric<span class="op">=</span><span class="st">'euclidean'</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> dbscan.fit(NE_Xtr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>What did we get?</p>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(dbscan.core_sample_indices_.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell fragment" data-execution_count="24">
<div class="cell-output cell-output-stdout">
<pre><code>(305,)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(dbscan.labels_[:<span class="dv">10</span>])</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>clusters, counts <span class="op">=</span> np.unique(dbscan.labels_, return_counts<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> <span class="bu">dict</span>(<span class="bu">zip</span>(clusters, counts))</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(d)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'no. of noise points: </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">sum</span>(dbscan.labels_ <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>)<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell fragment" data-execution_count="25">
<div class="cell-output cell-output-stdout">
<pre><code>[-1 -1 -1 -1 -1 -1  0 -1  0 -1]
{-1: 7390, 0: 494, 1: 109, 2: 7}
no. of noise points: 7390</code></pre>
</div>
</div>
<p>No concept of prediction!</p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>test_labels <span class="op">=</span> dbscan.predict(NE_Xte)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell fragment" data-execution_count="26">
<div class="cell-output cell-output-error">
<pre><code>AttributeError: 'DBSCAN' object has no attribute 'predict'</code></pre>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כשמבצעים dbscan צריך לייבא את הקלאסטר המתאים, ולאתחל אותו עם איזשהו אפסילון רדיוס השכונה, ופרמטר מינפוינטס, כאן הוא נקרא min_samples ואפשר לראות שביקשתי 10 כלומר תצפית תהיה קור אם ברדיוס “1” ממנה יש לפחות 10 תצפיות אחרות. בדיביסקאן ניתן כמובן להחליף לכל מטריקת מרחק, כאן אוקלידית.</p>
<p>מה מקבלים כשמריצים fit על הנתונים של נטפליקס?</p>
<p>האינדקסים של נקודות הליבה בשדה core_sample_indices, כאן התקבלו כ300 מתוך 8000 נקודות במדגם הלמידה.</p>
<p>בשדה labels מופיע הקלאס של כל תצפית, כאשר אם היא לא שייכת לאף קלאסטר היא מקבלת מינוס 1. כאן אפשר לראות שכמעט כל התצפיות לא סיווג לקלאסטר, שבעת אלפים מתוך שמונת אלפים. נמצאו באופן טבעי על-ידי האלגוריתם רק עוד מספר קטן של קלאסטרים, הכי גדול בהם עם כמה מאות תצפיות. בריצות עם פרמטרים קצת אחרים תקבלו תוצאות די דומות.</p>
<p>אבל נקודה חשובה, האלגוריתם dbscan ללא איזה עיבוד פוסט הוק לא נותן לכם עוד מידע על הקלאסטרים שגילה כמו מרכז המסה שלהם נניח, כמו שלkmeans יש את הממוצע. לכן לא ניתן לסווג תצפיות חדשות בצורה טבעית ואין מתודה predict לאוביקט שמתקבל מdbscan, תקבלו שגיאה.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="dbscan-on-netflix-weak-relation-to-pca">DBSCAN on Netflix: Weak relation to PCA?</h3>
<div class="cell" data-execution_count="27">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>X_centered <span class="op">=</span> NE_Xtr <span class="op">-</span> NE_Xtr.mean(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>pca.fit(X_centered)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> pca.transform(X_centered)</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>c_dict <span class="op">=</span> {<span class="op">-</span><span class="dv">1</span>: <span class="st">'Noise'</span>, <span class="dv">0</span>:<span class="st">'Cluster1'</span>, <span class="dv">1</span>:<span class="st">'Cluster2'</span>, <span class="dv">2</span>:<span class="st">'Cluster3'</span>, <span class="dv">3</span>:<span class="st">'Cluster4'</span>}</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>clusters <span class="op">=</span> np.vectorize(c_dict.get)(dbscan.labels_)</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> sns.jointplot(x<span class="op">=</span>T[:, <span class="dv">0</span>], y<span class="op">=</span>T[:, <span class="dv">1</span>], hue<span class="op">=</span>clusters, height<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>ax.set_axis_labels(<span class="st">'PC1: Popular Vote'</span>, <span class="st">'PC2: Romance vs. Action'</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img data-src="c15_clustering_files/figure-revealjs/cell-28-output-1.png" width="487" height="489"></p>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>ושוב קשה בקלאסטרינג באופן כללי להבין למה קיבלנו את החלוקה שקיבלנו, האם היא עושה שכל, במיוחד כשהמימד גבוה. אז אני שוב צובע את התצפיות כאן לפי קלאסטר במרחב במימד שאני כן יודע לצייר, המרחב שנוצר בPCA עם שני הPC הראשונים. הקלאסטר היחיד שעושה שכל זה הקלאסטר הכתום שאכן מתלכד עם ה”דיעה” של PCA שיש קבוצה של צופים שפשוט נותנים ציונים גבוהים לכל הסרטים. לא הצלחתי למצוא קלאסטרים מעניינים אחרים.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="dbscan-on-k-means-failures" class="slide level2 title-slide center">
<h2>DBSCAN on K-means Failures</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>בואו נחזור לדוגמאות שלנו של מצבים מאתגרים ונראה במה הועיל DBSCAN.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="dbscan-on-k-means-failures-i">DBSCAN on K-means Failures (I)</h3>
<div class="cell" data-execution_count="28">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>dbscan <span class="op">=</span> DBSCAN(eps<span class="op">=</span><span class="fl">0.2</span>).fit(X_circles)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_circles[:, <span class="dv">0</span>], X_circles[:, <span class="dv">1</span>], c<span class="op">=</span>dbscan.labels_)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img data-src="c15_clustering_files/figure-revealjs/cell-29-output-1.png" width="507" height="411"></p>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אז במבנה הטבעות שלנו dbscan מוצא את פתרון ללא קושי, אין לפרוצדורה ביאס דווקא לגושים או כדורים בדאטא, ככל שהקלאסטרים מובחנים טוב יותר ככה יהיה לו קל יותר למצוא אותם, זה פחות קשור למבנה עצמו שלהם.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="dbscan-on-k-means-failures-ii">DBSCAN on K-means Failures (II)</h3>
<div class="cell" data-execution_count="29">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>dbscan <span class="op">=</span> DBSCAN(eps<span class="op">=</span><span class="fl">0.2</span>).fit(X_square)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_square[:, <span class="dv">0</span>], X_square[:, <span class="dv">1</span>], c<span class="op">=</span>dbscan.labels_)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img data-src="c15_clustering_files/figure-revealjs/cell-30-output-1.png" width="496" height="411"></p>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>על הדאטא בהתפלגות אחידה על הריבוע שלנו dbscan גם כאן מוצא שאין צורך ביותר מקלאסטר אחד באופו טבעי.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="dbscan-on-k-means-failures-iii">DBSCAN on K-means Failures (III)</h3>
<div class="cell" data-execution_count="30">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>dbscan <span class="op">=</span> DBSCAN(eps<span class="op">=</span><span class="fl">1.2</span>).fit(X_out)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_out[:, <span class="dv">0</span>], X_out[:, <span class="dv">1</span>], c<span class="op">=</span>dbscan.labels_)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img data-src="c15_clustering_files/figure-revealjs/cell-31-output-1.png" width="495" height="411"></p>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>ועל הדאטא שבו יש שני קלאסטרים מובחנים מאוד זה מזה ותצפית אאוטלייר שבבירור לא שייכת לאף אחד מהם, dbscan אכן מגדיר אותה כנקודת רעש, הוא לא רואה חובה לסווג כל תצפית ותצפית.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="dbscan-on-k-means-failures-iv">DBSCAN on K-means Failures (IV)</h3>
<div class="cell" data-execution_count="31">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>dbscan <span class="op">=</span> DBSCAN(eps<span class="op">=</span><span class="fl">0.9</span>).fit(X_varied)</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_varied[:, <span class="dv">0</span>], X_varied[:, <span class="dv">1</span>], c<span class="op">=</span>dbscan.labels_)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img data-src="c15_clustering_files/figure-revealjs/cell-32-output-1.png" width="498" height="411"></p>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>איפה שdbscan לא הועיל, זה למשל האתגר של קלאסטרים עם צפיפויות שונות שעדיין קרובים זה לזה. עם צפיפות כל כך נמוכה אנחנו שבפריפריה של הקלאסטר האמצעי dbscan נוטה למצוא הרבה רעש בתצפיות שהן חלק מהקלאסטר וצריך עוד קצת מאמץ בבחירת הפרמטרים שלו כדי שיגיע לסיווג שאנחנו יודעים שהוא נכון.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<table>
<colgroup>
<col style="width: 45%">
<col style="width: 30%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Pros</th>
<th>Cons</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>K-means</td>
<td>Faster, Scalable, Simple <br>Related to other methods (PCA, EM, GMM)</td>
<td>Need <span class="math inline">\(K\)</span> <br>Separable spherical clusters <br>No outliers <br>Bad with unequal densities <br>Only Euclidean distance</td>
</tr>
<tr class="even">
<td>DBSCAN</td>
<td>Complex structures <br>No need of <span class="math inline">\(K\)</span> <br>Any distance metric <br>Outliers</td>
<td>Slower <br>Very sensitive to <span class="math inline">\(\varepsilon, minPts\)</span> <br>Bad with unequal densities</td>
</tr>
</tbody>
</table>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>נסכם בהשוואה בין שתי השיטות:</p>
<p>Kmeans הוא אלגוריתם פשוט מאוד וסקלבילי להרבה תצפיות ולהרבה משתנים, יש לו קשר הדוק לאלגוריתמים אחרים כמו PCA, EM, GMM שלא דיברנו עליו.</p>
<p>אבל צריך לפרט מהו הK, יש לו העדפה למבנים של ספירות או גושים בדאטא, אין לו קונספט של אאוטליירז וכל תצפית שייכת לקלאסטר יחיד. קשה לו עם צפיפויות משתנות והוא בנוי על מרחק אוקלידי בילט אין.</p>
<p>DBSCAN יכול להבחין במבנים הרבה יותר מוזרים, הוא “מגלה” לבד את הK הנכון, אפשר להציב בו כל מטריקת מרחק והוא לא חייב לסווג את כל התצפיות לקלאסטרים, יכול גם להכריז על אאוטליירז.</p>
<p>מצד שני DBSCAN הרבה יותר איטי, מעבר על נקודה וחיפוש עמוק ורקורסיבי על כל השכנים שלה, רגיש מאוד לפרמטרים אחרים, האפסילון והמינפוינטס, וגם הוא מוצא קלאסטרים בצפיפות נמוכה כאתגר.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="clustering-after-dimensionality-reduction" class="slide level2 title-slide center">
<h2>Clustering after Dimensionality Reduction</h2>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>הזכרנו ביחידה הזאת את PCA. ואם אתם זוכרים גם כשדיברנו על PCA אזכרנו קלאסטרים, או אשכולות. אמרנו שהרבה פעמים אחרי הורדת מימד מתקבלים קלאסטרים מעניינים בדאטא, אז עכשיו זה הזמן לבדוק האם הורדת מימד באמת יכולה לשפר איכות של קלאסטרינג.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="the-fnist-dataset">The FNIST Dataset</h3>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.datasets <span class="im">import</span> fashion_mnist</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>(X_train, y_train), (X_test, y_test) <span class="op">=</span> fashion_mnist.load_data()</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> X_train.astype(np.float32) <span class="op">/</span> <span class="dv">255</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> X_test.astype(np.float32) <span class="op">/</span> <span class="dv">255</span></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X_train.shape)</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y_train.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(60000, 28, 28)
(60000,)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>y_train[:<span class="dv">10</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>array([9, 0, 0, 3, 0, 2, 7, 2, 5, 5], dtype=uint8)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="34">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">3</span>))</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].imshow(X_train[<span class="dv">0</span>], cmap<span class="op">=</span><span class="st">"binary"</span>)</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].imshow(X_train[<span class="dv">1</span>], cmap<span class="op">=</span><span class="st">"binary"</span>)</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].imshow(X_train[<span class="dv">2</span>], cmap<span class="op">=</span><span class="st">"binary"</span>)</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> axes[<span class="dv">0</span>].axis(<span class="st">'off'</span>)</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> axes[<span class="dv">1</span>].axis(<span class="st">'off'</span>)</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> axes[<span class="dv">2</span>].axis(<span class="st">'off'</span>)</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img data-src="c15_clustering_files/figure-revealjs/cell-35-output-1.png" width="466" height="150"></p>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כדי להדגים את הנושא אני רוצה להציג לכם דאטאסט חדש, הFashion MNIST, או FNIST בקיצור. הדאטא הזה לוקח השראה מדאטא מפורסם אחר שנקרא MNIST ובו יש אלפי תמונות שחור-לבן, כלומר שכבה אחת, של הספרות 0 עד 9 כתובות בכתב יד. כאן במקום ספרות יש לנו 10 סוגים של פריטי לבוש. כמו נעליים, חולצה, שמלה ועוד. יש לנו 60000 תמונות בטריינינג עם 6000 דוגמאות לכל פריט לבוש, ועוד 10000 דוגמאות בטסט סט.</p>
<p>המטרה בד”כ בדאטא כזה היא לבנות מודל קלסיפיקציה לחיזוי תמונות שהמודל לא ראה לאחד מעשרת פריטי הלבוש. כאן דווקא אבצע קלאסטרינג על הדאטא עם Kmeans, ואשתמש בפריטי הלבוש כground truth לראות אם הקלאסטרים קשורים אליהם, כלומר האם, במצב אידאלי, 10 קלאסטרים ייצגו עשרה פריטי לבוש.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="k-means-on-fnist">K-means on FNIST</h3>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>X_train_flat <span class="op">=</span> X_train.reshape((X_train.shape[<span class="dv">0</span>], <span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X_train_flat.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(60000, 784)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>kmeans.fit(X_train_flat)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pd.crosstab(y_train, kmeans.labels_).rename(index<span class="op">=</span>fnist_dict))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>col_0           0     1     2     3     4     5     6     7     8     9
row_0                                                                  
T-shirt/top   201    23  3404     0   593     2   167  1583    27     0
Trouser      5413     3   236     0   156     0    63   129     0     0
Pullover        9    27   115     0   515     1  3519  1787    27     0
Dress        3209     5  1684     0   522     0    49   524     7     0
Coat          154    15   873     0   252     0  3596  1081    29     0
Sandal          1     4     2   480  3766  1444     0    29    13   261
Shirt          62    62  1053     0   774     6  1954  2071    17     1
Sneaker         0     1     0   785   508  4680     0     0     0    26
Bag            28  2201    22    66   494   237   269   228  2449     6
Ankle boot      2     4     2  2926   170   164     1    38     0  2693</code></pre>
</div>
</div>
<div class="fragment">
<p>Metrics for evaluating clustering vs.&nbsp;ground truth: Rand index, Mutual information, V-measure…</p>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>לפני שאני מבצע קלאסטרינג עם Kmeans ברור שהוא לא יכול לעבוד על תמונות שאלה מערכים דו-מימדיים, אז אני משטח 28 על 28 פיקסלים לוקטור ארוך של 784 פיקסלים.</p>
<p>אני מבצע Kmeans ועושה קרוסטאב של הלייבלז שקיבלתי עם הground truth, עם y_train, פריטי הלבוש האמיתיים.</p>
<p>ברור שאין משמעות לסדר הלייבלז 0 עד 9, מעניין רק לראות אם קלאסטרים מסוימים הם אכן מוקדשים כולם או רובם לפריט לבוש ספציפי.</p>
<p>למשל כאן ניתן לראות שמכנסיים אכן מקבלות קלאסטר משלהן, וכן גם נעליים מסוג סניקרז. אבל בגדים עליונים כמו חולצה, מעיל וסוודר מתפזרים להם על פני קלאסטרים שונים.</p>
<p>יש אגב הרבה מטריקות לבדוק את הפתרון של קלאסטרינג כמו אלה שרשומות כאן. למשל האינדקס של ראנד בוחן את אחוז הזוגות של תצפיות מאותו קלאסטר אמיתי כמו חולצה וחולצה, שהסתווגו לאותו קלאסטר כמו 0 ו0.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="recall-pca-might-discover-clusters">Recall: PCA might discover clusters</h3>
<div class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>X_train_flat_centered <span class="op">=</span> X_train_flat <span class="op">-</span> X_train_flat.mean(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>pca.fit(X_train_flat_centered)</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> pca.transform(X_train_flat_centered)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="39">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>clusters <span class="op">=</span> np.vectorize(fnist_dict.get)(y_train)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span>T[:, <span class="dv">0</span>], y<span class="op">=</span>T[:, <span class="dv">1</span>], hue<span class="op">=</span>clusters, s<span class="op">=</span><span class="dv">10</span>, palette<span class="op">=</span><span class="st">'tab10'</span>)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'PC1'</span>)</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'PC2'</span>)</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img data-src="c15_clustering_files/figure-revealjs/cell-40-output-1.png" width="513" height="429"></p>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אז אמרנו שהורדת מימד עשויה לפעמים לגלות קלאסטרים בדאטא. כאן אנחנו עושים PCA עם שני PCs, כלומר מנסים להוריד מימד מ784 פיקסלים ל2 רכיבים בלבד. כשאנחנו צובעים את התצפיות במרחב ההטלה לפי סוגי הלבוש, אנחנו רואים שאכן סוגי לבוש שונים מתמפים קרוב זה לזה. במקרה של מכנסיים בורוד כאן זה מאוד בולט, אולי גם מגפיים. אבל פריטי לבוש אחרים נוטים להתערבב זה בזה, אז לא בטוח כמה Kmeans על המרחב הזה, על מטריצה T יהיה “טוב יותר” במובן שיפריד בין פריטי הלבוש.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="does-it-improve-clustering">Does it improve clustering?</h3>
<div class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>kmeans.fit(T)</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pd.crosstab(y_train, kmeans.labels_).rename(index<span class="op">=</span>fnist_dict))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>col_0           0     1     2     3     4     5     6     7     8     9
row_0                                                                  
T-shirt/top   216    73   371    16  2887     5  1204   205     9  1014
Trouser        26     5    49     3   165     1  1557    47     0  4147
Pullover     2286   216  1393    49   121     6   334  1560    24    11
Dress          31     9   149     1  1363     0  1662    69     0  2716
Coat         2225    88   698    48   773     5   291  1639     3   230
Sandal          0  3661   133    13     1   281    28     8  1874     1
Shirt        1256   251  1314    52   795    14   830  1130    35   323
Sneaker         0  2422     2    13     0   472     0     1  3090     0
Bag           256   164  1151  2481    16  1008   244   287   382    11
Ankle boot      2    61   248  1166     0  3451     6   151   914     1</code></pre>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כשאנחנו עושים Kmeans על מטריצה T, מטריצה עם שני מימדים בלבד, אין ספק שהוא מהיר הרבה יותר, אבל אם תבחנו את הקרוסטאב תראו שלא ממש הועלנו, ואם תחשבו מדדים כמו rand index תראו שאולי אפילו הזקנו קצת.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="increasing-latent-dimension-q">Increasing latent dimension <span class="math inline">\(q\)</span></h3>
<div class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components <span class="op">=</span> <span class="dv">30</span>)</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>pca.fit(X_train_flat_centered)</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> pca.transform(X_train_flat_centered)</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>kmeans.fit(T)</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pd.crosstab(y_train, kmeans.labels_).rename(index<span class="op">=</span>fnist_dict))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>col_0           0     1     2     3     4     5     6     7     8     9
row_0                                                                  
T-shirt/top    31     0   199  3403  1587     2   167    22     0   589
Trouser         0     0  5411   238   129     0    63     3     0   156
Pullover       27     0     9   115  1782     1  3519    29     1   517
Dress           7     0  3200  1685   530     0    49     5     0   524
Coat           29     0   153   874  1073     0  3602    16     0   253
Sandal         13   483     1     2    29  1445     0     4   261  3762
Shirt          17     0    59  1056  2068     7  1955    64     1   773
Sneaker         0   760     0     0     0  4701     0     2    22   515
Bag          2440    65    26    22   231   240   266  2212     6   492
Ankle boot      0  2995     3     2    35   178     1     4  2613   169</code></pre>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>הסבר אחד יכול להיות שהשתמשנו במעט מדי PCs, בכל זאת הדאטא ממימד 784 ואנחנו מורידים אותו ל2 בלבד. אם משתמשים ב10 PCs למשל, אכן מקבלים תוצאה איכותית יותר, כעת גם כפכפים וסנדלים יש להם קלאסטר ברור משלהם.</p>
<p>הסבר אחר יכול להיות שהורדת המימד שPCA עושה, שאמרנו בנפנופי ידיים שהיא “ליניארית” פשוט נוקשה מדי, לא מתוחכמת מספיק כדי להגיע לאיזשהו לייטנט ספייס בדרך לא-ליניארית. נסיים את היחידה בלדבר ולהדגים ממש בהיי לבל, דרך כזאת להורדת מימד.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="autoencoders">Autoencoders</h3>

<img data-src="images/ae.png" class="r-stretch"><ul>
<li>A branch of unsupervised learning: Representation Learning</li>
<li>How do we learn representations useful for downstream tasks (e.g.&nbsp;clustering)</li>
<li>Most basic AE: Encode <span class="math inline">\(x_i \in \mathbb{R}^p\)</span> via <strong>encoder</strong> network <span class="math inline">\(f\)</span> to lower dimension <span class="math inline">\(q\)</span>, decode with <strong>decoder</strong> network <span class="math inline">\(g\)</span> back to dimension <span class="math inline">\(p\)</span>, such that: <span class="math inline">\(x_i \approx g(f(x_i))\)</span></li>
<li><span class="math inline">\(f(x_i) \in \mathbb{R}^q\)</span> hopefully <em>represents</em> the data well</li>
</ul>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>אוטואנקודרים הם ארכיטקטורה מאוד פופולרית של רשתות נוירונים להורדת מימד. באופן כללי משתמשים בהם למה שנקרא representation learning, איך אני לומד ייצוגים, כלומר וקטורים ממימד קטן, לעצמים שלי, באופן שיועיל להמשך למשימות כמו חיזוי, כמו קלאסטרינג. כלומר איך אני הופך אוביקט כמו מילה, כמו תמונה, מסמך לוקטור מספרים, שישפר לי ביצועים במשימות כאלה.</p>
<p>האוטואנקודר הכי פשוט הוא זה שאנחנו רואים כאן: אנחנו לוקחים וקטור של משתנים X ממימד p, ולומדים איזושהי רשת, אנקודר f לממד נמוך יותר q, ואז לומדים רשת אחרת ממימד q בחזרה למימד המקורי p, באופן שישחזר כמה שיותר טוב את הוקטור X המקורי, למשל על-ידי מינימזציה לשגיאה ריבועית. או נרשום זאת כך: שX יהיה כמה שיותר קרוב לG על F של X.</p>
<p>אם הייצוגים הם מה שמעניינים אותנו, הוקטורים ממימד נמוך, ניקח את האאוטפוט של רשת f האנקודר שלנו. הוא יחזיר לנו וקטור ממשי ממימד q לכל תצפית. ואנחנו מקווים שאם שגיאת השחזור הריבועית אכן קטנה, הדחיסה הזאת שווה משהו, הייצוגים הנלמדים אכן לוכדים במימד נמוך איזושהי משמעות בתצפיות. אפשר לחשוב על כל אחד מהאלמנטים בוקטור הייצוג כאיזשהו פיצ’ר מחוכם מאוד שהאוטואנקודר למד.</p>
<p>ובמה זה קשור לPCA? קשור מאוד. נסו לחשוב על ארכיטקטורה של הרשת שתבצע PCA ממש. אולי תתחילו עם PC אחד. מכל מקום אפשר לנסח אוטואנקודרים כהכללה של PCA, והם יכולים למצוא את המרחב הלטנטי המעניין הזה בצורה לא-ליניארית, בגלל שהאנקודר ודיקודר הם רשתות.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="ae-with-keras">AE with Keras</h3>
<div class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb46" data-code-line-numbers="|4-8|9-13|14|15|16|"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> Sequential</span>
<span id="cb46-2"><a href="#cb46-2"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> Dense, Flatten, Reshape</span>
<span id="cb46-3"><a href="#cb46-3"></a></span>
<span id="cb46-4"><a href="#cb46-4"></a>stacked_encoder <span class="op">=</span> Sequential([</span>
<span id="cb46-5"><a href="#cb46-5"></a>    Flatten(input_shape<span class="op">=</span>[<span class="dv">28</span>, <span class="dv">28</span>]),</span>
<span id="cb46-6"><a href="#cb46-6"></a>    Dense(<span class="dv">100</span>, activation<span class="op">=</span><span class="st">"relu"</span>),</span>
<span id="cb46-7"><a href="#cb46-7"></a>    Dense(<span class="dv">30</span>, activation<span class="op">=</span><span class="st">"relu"</span>),</span>
<span id="cb46-8"><a href="#cb46-8"></a>])</span>
<span id="cb46-9"><a href="#cb46-9"></a>stacked_decoder <span class="op">=</span> Sequential([</span>
<span id="cb46-10"><a href="#cb46-10"></a>    Dense(<span class="dv">100</span>, activation<span class="op">=</span><span class="st">"relu"</span>, input_shape<span class="op">=</span>[<span class="dv">30</span>]),</span>
<span id="cb46-11"><a href="#cb46-11"></a>    Dense(<span class="dv">28</span> <span class="op">*</span> <span class="dv">28</span>, activation<span class="op">=</span><span class="st">"sigmoid"</span>), <span class="co"># make output 0-1</span></span>
<span id="cb46-12"><a href="#cb46-12"></a>    Reshape([<span class="dv">28</span>, <span class="dv">28</span>])</span>
<span id="cb46-13"><a href="#cb46-13"></a>])</span>
<span id="cb46-14"><a href="#cb46-14"></a>stacked_ae <span class="op">=</span> Sequential([stacked_encoder, stacked_decoder])</span>
<span id="cb46-15"><a href="#cb46-15"></a>stacked_ae.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'mse'</span>, optimizer<span class="op">=</span><span class="st">'adam'</span>)</span>
<span id="cb46-16"><a href="#cb46-16"></a>history <span class="op">=</span> stacked_ae.fit(X_train, X_train, epochs<span class="op">=</span><span class="dv">20</span>, verbose<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כאן אנחנו רואים מימוש של אוטואנקודר הכי פשוט באמצעות קראס.</p>
<p>הרבה פעמים זה נקרא stacked autoencoder לכן ככה הוא נקרא כאן. כדי להגדיר את האנקודר אני משתמש ברשת שמקבלת את התמונות בגודל 28 על 28, עושה להם השטחה למימד 784 ומוסיפה שתי שכבות עם אקטיבציה רלו.</p>
<p>הדקודר הוא בארכיטקטורה זהה רק בהיפוך: מקבל את הייצוגים ממימד 30, ומוסיף שתי שכבות. השכבה האחרונה ממימד 784 והוא מחזיר אותה לצורת תמונה עם שכבת reshape שאין לה פרמטרים.</p>
<p>כעת האוטואנקודר עצמו הוא שרשור של האנקודר ודיקודר. אני עושה לו קומפליציה עם שגיאה ריבועית כלומר MSE ואיזשהו אופטימייזר, והאינפוט שלו שימו לב הוא X וגם האאוטפוט הוא X! אין כאן הרי y, אנחנו מנסים לקחת X ולבנות זוג רשתות שישחזרו אותו הכי טוב.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="can-it-reconstruct">Can it reconstruct?</h3>
<div class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> show_reconstructions(sae, images, n_images<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>  reconstructions <span class="op">=</span> sae.predict(images[:n_images], verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>  fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(n_images <span class="op">*</span> <span class="fl">1.5</span>, <span class="dv">3</span>))</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> image_index <span class="kw">in</span> <span class="bu">range</span>(n_images):</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>      plt.subplot(<span class="dv">2</span>, n_images, <span class="dv">1</span> <span class="op">+</span> image_index)</span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>      plt.imshow(images[image_index], cmap<span class="op">=</span><span class="st">'binary'</span>)</span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>      plt.axis(<span class="st">'off'</span>)</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>      plt.subplot(<span class="dv">2</span>, n_images, <span class="dv">1</span> <span class="op">+</span> n_images <span class="op">+</span> image_index)</span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a>      plt.imshow(reconstructions[image_index], cmap<span class="op">=</span><span class="st">'binary'</span>)</span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a>      plt.axis(<span class="st">'off'</span>)</span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a>show_reconstructions(stacked_ae, X_test)</span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img data-src="c15_clustering_files/figure-revealjs/cell-44-output-1.png" width="577" height="236"></p>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כאן יש הדגמה שמראה שאכן על תמונות שהרשת לא ראתה היא מצליחה לשחזר לא רע. בשורה העליונה תמונות שהרשת לא ראתה, בשורה התחתונה השחזור שלהן, אחרי שהעברנו אותן באנקודר-ודיקודר הנלמדים. נראה לא רע, כלומר הרשת מצאה רשת לדחוס את התמונות לוקטורים באורך 30 שיש להם מספיק משמעות שנוכל גם לשחזר את התמונות המקוריות מהם.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="does-it-improve-clustering-1">Does it improve clustering?</h3>
<div class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> stacked_encoder.predict(X_train, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(T.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(60000, 30)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>kmeans.fit(T)</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pd.crosstab(y_train, kmeans.labels_).rename(index<span class="op">=</span>fnist_dict))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>col_0           0     1     2     3     4     5     6     7     8     9
row_0                                                                  
T-shirt/top   104    15   598     6  1696     1     1  3396     0   183
Trouser        34     1   461  4921   451     1     0    91     0    40
Pullover     2423    17    87     2  1805     0     0    33     0  1633
Dress          43     2  3598   925   919     1     0   377     0   135
Coat         2039    13   894    27   835     0     0    28     0  2164
Sandal          0    46     1     0   920  1053  2920     0  1054     6
Shirt         801    37   396     5  2285     0     0   850     0  1626
Sneaker         0    33     0     0   254    26  4465     0  1222     0
Bag            98  2200   180     9   955     8    84    15     8  2443
Ankle boot      1    26     1     0   285  2529   181     1  2973     3</code></pre>
</div>
</div>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>כעת כדי להוריד מימד אני מבקש predict על האנקודר בלבד, על הf הנלמד, ואני אכן מקבל מטריצה T של 60 אלף פריטי הלבוש שלי על 30 מימדים בלבד.</p>
<p>אני מבצע Kmeans במרחב הזה ורוצה לראות אם הועלתי. נראה שכן, ברור שיש כאן יותר אפסים, אבל קשה להגיד שזה “מובהק”. המדדים שהזכרנו כמו rand index משתפרים קצת, אבל עדיין ניתן לראות את הבלבול בבגדים עליונים כמו מעיל ושמלה. צריך גם לזכור שעכשיו העלינו את המימד הלטנטי, את q ל30.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<div class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> TSNE</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>T_te <span class="op">=</span> stacked_encoder.predict(X_test, verbose<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>tsne <span class="op">=</span> TSNE(init<span class="op">=</span><span class="st">'pca'</span>, learning_rate<span class="op">=</span><span class="st">'auto'</span>)</span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>X_test_2D <span class="op">=</span> tsne.fit_transform(T_te)</span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a>X_test_2D <span class="op">=</span> (X_test_2D <span class="op">-</span> X_test_2D.<span class="bu">min</span>()) <span class="op">/</span> (X_test_2D.<span class="bu">max</span>() <span class="op">-</span> X_test_2D.<span class="bu">min</span>())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="47">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>clusters <span class="op">=</span> np.vectorize(fnist_dict.get)(y_test)</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span>X_test_2D[:, <span class="dv">0</span>], y<span class="op">=</span>X_test_2D[:, <span class="dv">1</span>], hue<span class="op">=</span>clusters, s<span class="op">=</span><span class="dv">10</span>, palette<span class="op">=</span><span class="st">'tab10'</span>)</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'D1'</span>)</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'D2'</span>)</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><img data-src="images/fnist_dim30_tsne.png" style="width:50.0%"></p>
<aside class="notes">
<div style="direction:rtl; font-size:16px">
<p>ובכל זאת, כשאני מבצע שיטה שלא למדנו כמו TSNE לצייר את פריטי הלבוש שהם עכשיו ממימד 30 על מפה דו-מימדית, אני רואה הפרדה מרשימה בין סוגי הפריטים. ועדיין קשה מאוד להבדיל בתמונות בגודל 28 על 28 פיקסלים בין חולצות באדום שמתפרשות על כל המרחב הקטן הזה, לבין מעילים לדוגמא.</p>
<p>נסיים בטעימה הזאת על אוטואנקודרים כנציג של למידת ייצוגים, representation learning. אני מקווה שזה יגרה אתכם ללמוד עוד על התחום המרתק הזה. כך אנחנו לומדים עם מילים למשל, עם גרפים ועם כל עצם שלא ברור איך הופכים אותו לוקטור ממימד נמוך של פיצ’רים כמותיים, רציפים.</p>
</div>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<p><img src="../Intro2DS_logo_white.jpg" class="slide-logo"></p>
<div class="footer footer-default">
<p><a href="https://intro2ds2023.github.io/mooc/" target="_blank">Intro to Data Science</a></p>
</div>
</section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../libs/revealjs/plugin/search/search.js"></script>
  <script src="../libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'smaller': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': true,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        text: function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>